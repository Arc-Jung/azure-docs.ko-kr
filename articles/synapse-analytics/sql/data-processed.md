---
title: 서버를 사용 하지 않는 SQL 풀로 처리 되는 데이터
description: 이 문서에서는 서버 리스 SQL 풀을 사용 하 여 Azure storage에서 데이터를 쿼리할 때 처리 된 데이터를 계산 하는 방법을 설명 합니다.
services: synapse analytics
author: filippopovic
ms.service: synapse-analytics
ms.topic: conceptual
ms.subservice: sql
ms.date: 11/05/2020
ms.author: fipopovi
ms.reviewer: jrasnick
ms.openlocfilehash: 06eb02aa3dd4d5fc8bd3605dac480d5afa52d5fa
ms.sourcegitcommit: 7cc10b9c3c12c97a2903d01293e42e442f8ac751
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 11/06/2020
ms.locfileid: "93424219"
---
# <a name="data-processed-with-serverless-sql-pool-in-azure-synapse-analytics"></a>Azure Synapse Analytics에서 서버를 사용 하지 않는 SQL 풀로 처리 된 데이터

처리 된 데이터는 쿼리를 실행 하는 동안 시스템에 일시적으로 저장 되는 데이터의 양이 며 다음으로 구성 됩니다.

- 저장소에서 읽은 데이터 양-다음을 포함 합니다.
  - 데이터를 읽는 동안 읽은 데이터의 양
  - 메타 데이터를 읽는 동안 읽은 데이터 양 (Parquet와 같은 메타 데이터가 포함 된 파일 형식의 경우)
- 중간 결과의 데이터 양 – 끝점에 대 한 데이터 전송을 포함 하 여 쿼리를 실행 하는 동안 압축 되지 않은 형식으로 노드 간에 전송 되는 데이터입니다. 
- 저장소에 기록 된 데이터 양 – CETAS를 사용 하 여 결과 집합을 저장소로 내보내는 경우, CETAS의 SELECT 부분에 대해 처리 된 데이터의 양과 기록 된 바이트에 대 한 요금이 청구 됩니다.

저장소에서 파일을 읽으면 매우 최적화 되며 다음이 사용 됩니다.

- 프리페치-읽은 데이터 양에 약간의 오버 헤드를 추가할 수 있습니다. 쿼리가 전체 파일을 읽는 경우 오버 헤드가 발생 하지 않습니다. 상위 N 개 쿼리와 같이 파일이 부분적으로 읽 면 프리페치를 사용 하 여 더 많은 데이터를 읽을 수 있습니다.
- 최적화 된 CSV 파서 – PARSER_VERSION = ' 2.0 '을 사용 하 여 CSV 파일을 읽으면 저장소에서 읽은 양의 데이터가 약간 증가 합니다.  최적화 된 CSV 파서는 동일한 크기의 청크로 파일을 병렬로 읽습니다. 청크는 전체 행을 포함 한다는 보장이 없습니다. 모든 행을 구문 분석 하기 위해 인접 한 청크의 작은 조각을 읽어서 적은 양의 오버 헤드를 추가 합니다.

## <a name="statistics"></a>통계

서버를 사용 하지 않는 SQL 풀 쿼리 최적화 프로그램은 통계를 기반으로 최적의 쿼리 실행 계획을 생성 합니다. 수동으로 통계를 만들거나 서버를 사용 하지 않는 SQL 풀에서 자동으로 통계를 만들 수 있습니다. 어느 쪽이 든, 제공 된 샘플 속도로 특정 열을 반환 하는 별도의 쿼리를 실행 하 여 통계가 생성 됩니다. 이 쿼리에는 처리 된 데이터 양이 있습니다.

생성 된 통계를 활용 하는 동일한 쿼리 또는 다른 쿼리를 실행 하는 경우 가능한 경우 통계가 다시 사용 되며 통계 생성을 위해 추가 데이터가 처리 되지 않습니다.

Parquet 열에 대 한 통계를 만들면 파일에서 관련 열만 읽습니다. CSV 열에 대 한 통계를 만들면 전체 파일을 읽고 구문 분석 합니다.

## <a name="rounding"></a>반올림

처리 되는 데이터의 양은 쿼리당 가장 가까운 MB로 반올림 되 고 쿼리당 최소한 10mb의 데이터를 처리 합니다.

## <a name="what-is-not-included-in-data-processed"></a>처리 된 데이터에 포함 되지 않은 항목

- 서버 수준 메타 데이터 (예: 로그인, 역할, 서버 수준 자격 증명)
- 끝점에서 만든 데이터베이스에는 메타 데이터 (예: 사용자, 역할, 스키마, 뷰, 인라인 Tvf, 저장 프로시저, 데이터베이스 범위 자격 증명, 외부 데이터 원본, 외부 파일 형식, 외부 테이블)만 포함 됩니다.
  - 스키마 유추를 사용 하는 경우 파일 조각을 읽어 열 이름과 데이터 형식을 유추 합니다.
- 지정 된 샘플 비율에 따라 저장소에서 데이터를 처리 하는 CREATE STATISTICS를 제외한 DDL 문
- 메타 데이터 전용 쿼리

## <a name="reduce-amount-of-data-processed"></a>처리 되는 데이터의 양 줄이기

데이터를 Parquet와 같은 압축 된 칼럼 형식으로 분할 하 고 변환 하 여 처리 된 데이터의 쿼리당 크기를 최적화 하 고 더 나은 성능을 얻을 수 있습니다.

## <a name="examples"></a>예제

두 테이블에 동일한 크기의 열에 동일한 데이터가 있다고 가정해 보겠습니다.

- 5 TB CSV 파일로 지원 되는 population_csv 테이블
- 1TB의 Parquet 파일에 의해 지원 되는 population_parquet 테이블 – Parquet 압축 된 데이터가 포함 되어 있으므로이 테이블은 이전 테이블 보다 작습니다.
- 100 KB의 CSV 파일에 의해 지원 되는 very_small_csv 테이블

**쿼리 #1** : POPULATION_CSV에서 합계 (채우기)를 선택 합니다.

이 쿼리는 전체 파일을 읽고 구문 분석 하 여 모집단 열의 값을 가져옵니다. 노드는이 테이블의 조각을 처리 하 고, 각 조각의 모집단 합계는 노드 간에 전송 되며, 최종 합계는 끝점으로 전송 됩니다. 이 쿼리는 5TB의 데이터를 처리 하 고 조각 합계를 전송 하기 위한 작은 오버 헤드를 처리 합니다.

**쿼리 #2** : POPULATION_PARQUET에서 합계 (채우기)를 선택 합니다.

서버를 사용 하지 않는 SQL 풀에서 전체 파일 대신 압축 된 단일 열을 읽기 때문에 Parquet와 같은 압축 및 열 기반 형식을 쿼리하면 이전 쿼리 보다 더 낮은 데이터를 읽을 수 있습니다. 이 경우 0.2 TB를 읽습니다 (각각 5 개의 동일한 크기의 열, 0.2 TB). 노드는이 테이블의 조각을 처리 하 고, 각 조각의 모집단 합계는 노드 간에 전송 되며, 최종 합계는 끝점으로 전송 됩니다. 이 쿼리는 0.2 TB와 조각의 합계를 전송 하기 위한 작은 오버 헤드를 처리 합니다.

**쿼리 #3** : SELECT * FROM population_parquet

이 쿼리는 모든 열을 읽고 모든 데이터를 압축 되지 않은 형식으로 전송 합니다. 압축 형식이 5:1 이면 압축 되지 않은 데이터의 1TB + 전송 5tb를 읽기 때문에 6TB를 처리 합니다.

**쿼리 #4** : VERY_SMALL_CSV에서 COUNT (*)를 선택 합니다.

이 쿼리는 전체 파일을 읽습니다. 이 테이블에 대 한 저장소에 있는 파일의 총 크기는 100 KB입니다. 노드는이 테이블의 조각을 처리 하 고, 각 조각의 합계는 노드 간에 전송 되며, 최종 합계는 끝점으로 전송 됩니다. 이 쿼리는 100 KB 보다 약간 더 많은 데이터를 처리 합니다. 이 쿼리에 대해 처리 되는 데이터의 양은 [반올림](#rounding)에 지정 된 대로 최대 10mb로 반올림 됩니다.

## <a name="next-steps"></a>다음 단계

성능을 위해 쿼리를 최적화 하는 방법을 알아보려면 서버를 사용 하지 않는 [SQL 풀에 대 한 모범 사례](best-practices-sql-on-demand.md)를 확인 하세요.
