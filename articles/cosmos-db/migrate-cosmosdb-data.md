---
title: 수백 테라바이트의 데이터를 Azure Cosmos DB로 마이그레이션
description: 이 문서에서는 100초테라바이트의 데이터를 Cosmos DB로 마이그레이션하는 방법을 설명합니다.
author: bharathsreenivas
ms.service: cosmos-db
ms.subservice: cosmosdb-sql
ms.topic: conceptual
ms.date: 10/23/2019
ms.author: bharathb
ms.openlocfilehash: 69b400eb7838c986ac6f275da58c7457179ebea6
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/27/2020
ms.locfileid: "72880215"
---
# <a name="migrate-hundreds-of-terabytes-of-data-into-azure-cosmos-db"></a>수백 테라바이트의 데이터를 Azure Cosmos DB로 마이그레이션 

Azure Cosmos DB에 테라바이트의 데이터를 저장할 수 있습니다. 대규모 데이터 마이그레이션을 수행하여 프로덕션 워크로드를 Azure Cosmos DB로 이동할 수 있습니다. 이 문서에서는 대규모 데이터를 Azure Cosmos DB로 이동하는 데 관련된 문제를 설명하고 문제를 해결하고 데이터를 Azure Cosmos DB로 마이그레이션하는 데 도움이 되는 도구를 소개합니다. 이 사례 연구에서 고객은 Cosmos DB SQL API를 사용했습니다.  

전체 워크로드를 Azure Cosmos DB로 마이그레이션하기 전에 데이터 하위 집합을 마이그레이션하여 파티션 키 선택, 쿼리 성능 및 데이터 모델링과 같은 일부 측면의 유효성을 검사할 수 있습니다. 개념 증명의 유효성을 검사한 후 전체 워크로드를 Azure Cosmos DB로 이동할 수 있습니다.  

## <a name="tools-for-data-migration"></a>데이터 마이그레이션을 위한 도구 

Azure Cosmos DB 마이그레이션 전략은 현재 API 선택 및 데이터 크기에 따라 다릅니다. 데이터 모델링, 쿼리 성능, 파티션 키 선택 등을 위해 더 작은 데이터 집합을 마이그레이션하려면 [데이터 마이그레이션 도구](import-data.md) 또는 Azure Data [Factory의 Azure Cosmos DB 커넥터를](../data-factory/connector-azure-cosmos-db.md)선택할 수 있습니다. Spark에 익숙한 경우 [Azure Cosmos DB 스파크 커넥터를](spark-connector.md) 사용하여 데이터를 마이그레이션하도록 선택할 수도 있습니다.

## <a name="challenges-for-large-scale-migrations"></a>대규모 마이그레이션의 과제 

Azure Cosmos DB로 데이터를 마이그레이션하기 위한 기존 도구에는 대규모에서 특히 분명하게 드러나는 몇 가지 제한 사항이 있습니다.

 * **제한된 확장 기능**: 테라바이트 규모의 데이터를 가능한 한 빨리 Azure Cosmos DB로 마이그레이션하고 프로비저닝된 전체 처리량을 효과적으로 사용하려면 마이그레이션 클라이언트가 무기한 으로 확장할 수 있어야 합니다.  

* **진행률 추적 및 검사 포인트 의 부족**: 대규모 데이터 집합을 마이그레이션하는 동안 마이그레이션 진행 상황을 추적하고 검사 가리키는 것이 중요합니다. 그렇지 않으면 마이그레이션 중에 발생하는 오류로 인해 마이그레이션이 중지되고 프로세스를 처음부터 다시 시작해야 합니다. 전체 마이그레이션 프로세스의 99%가 이미 완료된 경우 전체 마이그레이션 프로세스를 다시 시작하는 것은 생산적이지 않습니다.  

* **배달 못한 편지 대기열 부족**: 대용량 데이터 집합 내에서 경우에 따라 원본 데이터의 일부에 문제가 있을 수 있습니다. 또한 클라이언트 또는 네트워크에 일시적인 문제가 있을 수 있습니다. 이러한 경우 중 하나일 경우 전체 마이그레이션이 실패하지 않아야 합니다. 대부분의 마이그레이션 도구에는 간헐적인 문제를 방지하는 강력한 재시도 기능이 있지만 항상 충분하지는 않습니다. 예를 들어 원본 데이터 문서의 0.01% 미만이 크기가 2MB보다 크면 Azure Cosmos DB에서 문서 쓰기가 실패하게 됩니다. 이상적으로는 마이그레이션 도구가 이러한 '실패한' 문서를 마이그레이션 후 처리할 수 있는 다른 배달 못한 편지 큐로 유지하는 것이 좋습니다. 

이러한 제한 사항 중 대부분은 Azure 데이터 팩터리, Azure 데이터 마이그레이션 서비스와 같은 도구에 대해 수정되고 있습니다. 

## <a name="custom-tool-with-bulk-executor-library"></a>대량 실행기 라이브러리가 있는 사용자 지정 도구 

위의 섹션에서 설명한 과제는 여러 인스턴스에서 쉽게 확장할 수 있고 일시적인 오류에 탄력적인 사용자 지정 도구를 사용하여 해결할 수 있습니다. 또한 사용자 지정 도구는 다양한 검사점에서 마이그레이션을 일시 중지하고 다시 시작할 수 있습니다. Azure Cosmos DB는 이미 이러한 기능 중 일부를 통합하는 [대량 실행기 라이브러리를](https://docs.microsoft.com/azure/cosmos-db/bulk-executor-overview) 제공합니다. 예를 들어 대량 실행기 라이브러리에는 이미 일시적인 오류를 처리하는 기능이 있으며 단일 노드에서 스레드를 확장하여 노드당 약 500K US를 소비할 수 있습니다. 또한 대량 실행기 라이브러리는 원본 데이터 집합을 검사점의 한 형태로 독립적으로 작동하는 마이크로 일괄 처리로 분할합니다.  

사용자 지정 도구는 대량 실행기 라이브러리를 사용하고 여러 클라이언트간에 확장되고 수집 프로세스 중에 오류를 추적할 수 있도록 지원합니다. 이 도구를 사용하려면 다른 마이그레이션 작업자가 각 파일을 선택하고 Azure Cosmos DB로 수집할 수 있도록 원본 데이터를 ADLS(Azure Data Lake Storage)의 고유한 파일로 분할해야 합니다. 사용자 지정 도구는 ADLS의 각 개별 소스 파일에 대한 마이그레이션 진행 률에 대한 메타데이터를 저장하고 관련 오류를 추적하는 별도의 컬렉션을 사용합니다.  

다음 이미지는 이 사용자 지정 도구를 사용하여 마이그레이션 프로세스를 설명합니다. 이 도구는 가상 시스템 집합에서 실행되고 있으며 각 가상 시스템은 Azure Cosmos DB의 추적 컬렉션을 쿼리하여 원본 데이터 파티션 중 하나에서 임대를 획득합니다. 이 작업이 완료되면 도구에서 원본 데이터 파티션을 읽고 대량 실행기 라이브러리를 사용하여 Azure Cosmos DB로 가져옵니다. 다음으로 추적 컬렉션이 업데이트되어 데이터 수집 진행률과 오류가 발생했습니다. 데이터 파티션이 처리된 후 도구는 사용 가능한 다음 소스 파티션을 쿼리하려고 시도합니다. 모든 데이터가 마이그레이션될 때까지 다음 원본 파티션을 계속 처리합니다. 도구의 소스 코드는 [여기에서](https://github.com/Azure-Samples/azure-cosmosdb-bulkingestion)확인할 수 있습니다.  

 
![마이그레이션 도구 설정](./media/migrate-cosmosdb-data/migrationsetup.png)
 

 

추적 컬렉션에는 다음 예제와 같은 문서가 포함되어 있습니다. 원본 데이터에서 각 파티션에 대해 이러한 문서가 하나씩 표시됩니다.  각 문서에는 원본 데이터 파티션의 위치, 마이그레이션 상태 및 오류(있는 경우)와 같은 메타데이터가 포함되어 있습니다.  

```json
{ 
  "owner": "25812@bulkimporttest07", 
  "jsonStoreEntityImportResponse": { 
    "numberOfDocumentsReceived": 446688, 
    "isError": false, 
    "totalRequestUnitsConsumed": 3950252.2800000003, 
    "errorInfo": [], 
    "totalTimeTakenInSeconds": 188, 
    "numberOfDocumentsImported": 446688 
  }, 
  "storeType": "AZURE_BLOB", 
  "name": "sourceDataPartition", 
  "location": "sourceDataPartitionLocation", 
  "id": "sourceDataPartitionId", 
  "isInProgress": false, 
  "operation": "unpartitioned-writes", 
  "createDate": { 
    "seconds": 1561667225, 
    "nanos": 146000000 
  }, 
  "completeDate": { 
    "seconds": 1561667515, 
    "nanos": 180000000 
  }, 
  "isComplete": true 
} 
```
 

## <a name="prerequisites-for-data-migration"></a>데이터 마이그레이션을 위한 필수 구성 조건 

데이터 마이그레이션을 시작하기 전에 고려해야 할 몇 가지 필수 구성 조건이 있습니다.  

#### <a name="estimate-the-data-size"></a>데이터 크기를 예측합니다.  

원본 데이터 크기는 Azure Cosmos DB의 데이터 크기에 정확히 매핑되지 않을 수 있습니다. Azure Cosmos DB에서 데이터 크기를 확인하기 위해 원본의 몇 가지 샘플 문서를 삽입할 수 있습니다. 샘플 문서 크기에 따라 마이그레이션 후 Azure Cosmos DB의 총 데이터 크기를 추정할 수 있습니다. 

예를 들어 Azure Cosmos DB에서 마이그레이션후 각 문서가 약 1KB이고 원본 데이터 집합에 약 600억 개의 문서가 있는 경우 Azure Cosmos DB의 예상 크기가 60TB에 가까워야 합니다. 

 

#### <a name="pre-create-containers-with-enough-rus"></a>충분한 RUs를 사용하여 컨테이너를 미리 만듭니다. 

Azure Cosmos DB는 저장소를 자동으로 확장하지만 가장 작은 컨테이너 크기부터 시작하는 것은 권장되지 않습니다. 컨테이너가 작을수록 처리량 가용성이 낮아지므로 마이그레이션을 완료하는 데 훨씬 더 오래 걸릴 수 있습니다. 대신 최종 데이터 크기(이전 단계에서 예상한 대로)로 컨테이너를 만들고 마이그레이션 워크로드가 프로비저닝된 처리량을 완전히 소비하는지 확인하는 것이 유용합니다.  

이전 단계에서. 데이터 크기는 약 60TB로 추정되었기 때문에 전체 데이터 집합을 수용하려면 최소 2.4M RUS의 컨테이너가 필요합니다.  

 

#### <a name="estimate-the-migration-speed"></a>마이그레이션 속도를 예측합니다. 

마이그레이션 워크로드가 프로비저닝된 전체 처리량을 소비할 수 있다고 가정하면 프로비저닝된 마이그레이션 속도의 추정을 제공할 수 있습니다. 이전 예제를 계속하면 Azure Cosmos DB SQL API 계정에 1KB 문서를 작성하려면 5개의 루가 필요합니다.  240만 루는 초당 480,000개의 문서(또는 480MB/s)를 전송할 수 있습니다. 즉, 60TB의 완전한 마이그레이션에는 125,000초 또는 약 34시간이 소요됩니다.  

하루 내에 마이그레이션을 완료하려면 프로비저닝된 처리량을 5백만 루로 늘려야 합니다. 

 

#### <a name="turn-off-the-indexing"></a>인덱싱 끄기:  

마이그레이션은 가능한 한 빨리 완료되어야 하므로 인더스트링된 각 문서에 대한 인덱스를 만드는 데 소요되는 시간과 RUs를 최소화하는 것이 좋습니다.  Azure Cosmos DB는 모든 속성을 자동으로 인덱싱하므로 선택한 몇 가지 용어로 인덱싱을 최소화하거나 마이그레이션 과정에서 완전히 해제하는 것이 좋습니다. 아래와 같이 인덱싱 모드를 없음으로 변경하여 컨테이너의 인덱싱 정책을 해제할 수 있습니다.  

 
```
  { 
        "indexingMode": "none" 
  } 
```
 

마이그레이션이 완료되면 인덱싱을 업데이트할 수 있습니다.  

## <a name="migration-process"></a>마이그레이션 프로세스 

필수 구성 이 완료된 후 다음 단계를 통해 데이터를 마이그레이션할 수 있습니다.  

1. 먼저 원본에서 Azure Blob 저장소로 데이터를 가져옵니다. 마이그레이션 속도를 높이려면 고유한 소스 파티션 간에 병렬화하는 것이 좋습니다. 마이그레이션을 시작하기 전에 원본 데이터 집합을 약 200MB 크기의 파일로 분할해야 합니다.   

2. 대량 실행기 라이브러리는 단일 클라이언트 VM에서 500,000개의 RUs를 사용하도록 확장할 수 있습니다. 사용 가능한 처리량은 5백만 루트이므로 10 Ubuntu 16.04 VM(Standard_D32_v3)은 Azure Cosmos 데이터베이스가 있는 동일한 리전에서 프로비전되어야 합니다. 마이그레이션 도구와 해당 설정 파일을 사용하여 이러한 VM을 준비해야 합니다.  

3. 클라이언트 가상 시스템 중 하나에서 큐 단계를 실행합니다. 이 단계에서는 ADLS 컨테이너를 검사하고 각 원본 데이터 집합의 파티션 파일에 대한 진행률 추적 문서를 만드는 추적 컬렉션을 만듭니다.  

4. 그런 다음 모든 클라이언트 VM에서 가져오기 단계를 실행합니다. 각 클라이언트는 소스 파티션에 대한 소유권을 가지고 Azure Cosmos DB로 데이터를 수집할 수 있습니다. 작업이 완료되고 추적 컬렉션에서 상태가 업데이트되면 클라이언트는 추적 컬렉션에서 사용 가능한 다음 소스 파티션을 쿼리할 수 있습니다.  

5. 이 프로세스는 전체 소스 파티션 집합이 들어올 때까지 계속됩니다. 모든 소스 파티션이 처리되면 동일한 추적 컬렉션의 오류 수정 모드에서 도구를 다시 실행해야 합니다. 이 단계는 오류로 인해 다시 처리해야 하는 원본 파티션을 식별하는 데 필요합니다.  

6. 이러한 오류 중 일부는 원본 데이터의 잘못된 문서 때문일 수 있습니다. 이러한 사항을 식별하고 수정해야 합니다. 다음으로 실패한 파티션에서 가져오기 단계를 다시 실행하여 다시 실행해야 합니다. 

마이그레이션이 완료되면 Azure Cosmos DB의 문서 수가 원본 데이터베이스의 문서 수와 동일한지 확인할 수 있습니다. 이 예에서 Azure Cosmos DB의 총 크기는 65테라바이트로 나타났습니다. 마이그레이션 후 인덱싱을 선택적으로 켜고 워크로드 작업에 필요한 수준으로 R을 낮출 수 있습니다.

## <a name="contact-the-azure-cosmos-db-team"></a>Azure 코스모스 DB 팀에 문의하기
이 가이드를 따라 대규모 데이터 집합을 Azure Cosmos DB로 성공적으로 마이그레이션할 수 있지만 대규모 마이그레이션의 경우 Azure Cosmos DB 제품 팀에 연락하여 데이터 모델링 및 일반 아키텍처 검토의 유효성을 검사하는 것이 좋습니다. 제품 팀은 데이터 집합 및 워크로드에 따라 귀하에게 적용할 수 있는 다른 성능 및 비용 최적화를 제안할 수도 있습니다. 대규모 마이그레이션에 대한 지원을 위해 Azure Cosmos DB 팀에 문의하려면 아래와 같이 "일반 권고" 문제 유형 및 "큰(TB+) 마이그레이션" 문제 하위 유형에서 지원 티켓을 열 수 있습니다.

![마이그레이션 지원 항목](./media/migrate-cosmosdb-data/supporttopic.png)


## <a name="next-steps"></a>다음 단계

* [.NET](bulk-executor-dot-net.md) 및 [Java에서](bulk-executor-java.md)대량 실행기 라이브러리를 사용하는 샘플 응용 프로그램을 사용해 보시면 자세히 알아보십시오. 
* 대량 실행기 라이브러리는 Cosmos DB 스파크 커넥터에 통합되어 자세한 내용은 [Azure Cosmos DB 스파크 커넥터](spark-connector.md) 문서를 참조하십시오.  
* "일반 권고" 문제 유형 및 "큰(TB+) 마이그레이션" 문제 하위 유형에서 지원 티켓을 열어 Azure Cosmos DB 제품 팀에 문의하여 대규모 마이그레이션에 대한 추가 도움말을 참조하세요. 
