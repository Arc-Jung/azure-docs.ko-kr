---
title: 매핑 데이터 흐름 성능 및 조정 가이드
description: Azure Data Factory에서 매핑 데이터 흐름의 매핑 성능에 영향을 주는 주요 요소에 대해 알아봅니다.
author: kromerm
ms.topic: conceptual
ms.author: makromer
ms.service: data-factory
ms.custom: seo-lt-2019
ms.date: 07/06/2020
ms.openlocfilehash: 9f420b37bd44a46d4149e89cf5876d8e8b712581
ms.sourcegitcommit: d7008edadc9993df960817ad4c5521efa69ffa9f
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 07/08/2020
ms.locfileid: "86114383"
---
# <a name="mapping-data-flows-performance-and-tuning-guide"></a>매핑 데이터 흐름 성능 및 조정 가이드

[!INCLUDE[appliesto-adf-asa-md](includes/appliesto-adf-asa-md.md)]

Azure Data Factory의 매핑 데이터 흐름은 대규모로 데이터 변환을 디자인, 배포 및 오케스트레이션하기 위한 코드 없는 인터페이스를 제공합니다. 매핑 데이터 흐름을 잘 모르는 경우 [매핑 데이터 흐름 개요](concepts-data-flow-overview.md)를 참조하세요.

ADF UX의 데이터 흐름을 디자인하고 테스트할 때 클러스터가 준비될 때까지 기다리지 않고 실시간으로 데이터 흐름을 실행하려면 디버그 모드로 전환해야 합니다. 자세한 내용은 [디버그 모드](concepts-data-flow-debug-mode.md)를 참조하세요.

이 비디오는 데이터 흐름을 사용하여 데이터를 변환하는 몇 가지 샘플 타이밍을 보여 줍니다.
> [!VIDEO https://www.microsoft.com/en-us/videoplayer/embed/RE4rNxM]

## <a name="monitoring-data-flow-performance"></a>데이터 흐름 성능 모니터링

매핑 데이터 흐름을 디자인하는 동안 구성 패널의 데이터 미리 보기 탭을 클릭하여 각 변환에 대해 단위 테스트를 수행할 수 있습니다. 논리를 확인한 후 종단 간 데이터 흐름을 파이프라인의 작업으로서 테스트합니다. 데이터 흐름 실행 작업을 추가하고 디버그 단추를 사용하여 데이터 흐름의 성능을 테스트합니다. 데이터 흐름의 실행 계획 및 성능 프로필을 열려면 파이프라인의 출력 탭에서 '작업' 아래의 안경 아이콘을 클릭합니다.

![데이터 흐름 모니터링](media/data-flow/mon002.png "데이터 흐름 모니터 2")

 이 정보를 사용하여 다양 한 크기의 데이터 원본에 대한 데이터 흐름의 성능을 예측할 수 있습니다. 자세한 내용은 [매핑 데이터 흐름 모니터링](concepts-data-flow-monitoring.md)을 참조하세요.

![데이터 흐름 모니터링](media/data-flow/mon003.png "데이터 흐름 모니터 3")

 파이프라인 디버그 실행의 경우에는 웜 클러스터의 전체 성능 계산을 위해 1분 정도의 클러스터 설정 시간이 필요합니다. 기본 Azure Integration Runtime를 초기화 하는 경우 실행 시간은 약 4 분 정도 걸릴 수 있습니다.

## <a name="increasing-compute-size-in-azure-integration-runtime"></a>Azure Integration Runtime에서 컴퓨팅 크기 늘리기

더 많은 코어가 있는 Integration Runtime은 Spark 컴퓨팅 환경에서 노드 수를 늘리고 데이터를 읽고, 쓰고, 변환하기 위한 더 많은 처리 능력을 제공합니다. ADF 데이터 흐름은 컴퓨팅 엔진에 Spark를 활용합니다. Spark 환경은 메모리 최적화 리소스에서 매우 효율적으로 작동합니다.

프로덕션의 대부분의 작업에 **최적화 된 메모리** 를 사용 하는 것이 좋습니다. 메모리에 더 많은 데이터를 저장 하 고 메모리 부족 오류를 최소화할 수 있습니다. 메모리 액세스에 최적화 됨은 계산에 최적화 된 것 보다 코어 당 더 높은 가격을 갖지만 더 빠른 변환 속도와 더 많은 파이프라인을 발생 시킬 수 있습니다. 데이터 흐름을 실행할 때 메모리 부족 오류가 발생하면 메모리 최적화 Azure IR 구성으로 전환합니다.

**계산에 최적화** 됨은 제한 된 수의 데이터 행에 대 한 디버그 및 데이터 미리 보기에 충분 합니다. 계산에 최적화 됨은 프로덕션 워크 로드와 함께 수행 되지 않을 가능성이 높습니다.

![새 IR](media/data-flow/ir-new.png "새 IR")

Integration Runtime를 만드는 방법에 대한 자세한 내용은 [Azure Data Factory의 Integration Runtime](concepts-integration-runtime.md)을 참조하세요.

### <a name="increase-the-size-of-your-debug-cluster"></a>디버그 클러스터의 크기 늘리기

기본적으로 디버그를 켜면 각 데이터 팩터리에 대해 자동으로 생성되는 기본 Azure Integration Runtime이 사용됩니다. 이 기본 Azure IR은 일반 컴퓨팅 속성을 사용하여 드라이버 노드에 대해 4개, 작업자 노드에 대해 4개, 모두 8개의 코어에 대해 설정됩니다. 대량의 데이터로 테스트하는 경우 더 큰 구성으로 Azure IR을 만들어 디버그 클러스터의 크기를 늘리고, 디버그를 켤 때 이 새로운 Azure IR를 선택할 수 있습니다. 이렇게 하면 ADF는 데이터 흐름에 대한 데이터 미리 보기와 파이프라인 디버그에 대해 이 Azure IR을 사용하게 됩니다.

### <a name="decrease-cluster-compute-start-up-time-with-ttl"></a>TTL을 사용하여 클러스터 컴퓨팅 시작 시간 줄이기

Azure IR의 데이터 흐름 속성에는 팩터리에 대해 클러스터 컴퓨팅 리소스 풀을 스탠드업할 수 있도록 하는 속성이 있습니다. 이 풀을 사용하면 실행을 위해 데이터 흐름 작업을 순차적으로 제출할 수 있습니다. 풀이 설정된 후에는 주문형 Spark 클러스터에서 각 후속 작업을 실행하는 데 1-2분이 소요됩니다. 리소스 풀의 초기 설정에는 약 4 분이 소요 됩니다. TTL(Time-to-Live) 설정에서 리소스 풀을 유지 관리하려는 시간을 지정합니다.

## <a name="optimizing-for-azure-sql-database-and-azure-sql-data-warehouse-synapse"></a>Azure SQL Database 및 Azure SQL Data Warehouse Synapse에 맞게 최적화

### <a name="partitioning-on-source"></a>원본에서 분할

1. **최적화** 탭으로 이동하고 **분할 설정**을 선택합니다.
1. **원본**을 선택합니다.
1. **파티션 수**에서 Azure SQL DB에 대한 최대 연결 수를 설정합니다. 데이터베이스에 대한 병렬 연결을 획득하기 위해 더 높은 설정을 시도할 수 있습니다. 그러나 일부 경우에는 제한된 수의 연결을 사용하여 더 빠른 성능을 얻을 수 있습니다.
1. 특정 테이블 열 또는 쿼리로 분할할 것인지를 선택합니다.
1. **열**을 선택한 경우 파티션 열을 선택합니다.
1. **쿼리**를 선택한 경우 데이터베이스 테이블의 파티션 구성표와 일치하는 쿼리를 입력합니다. 이 쿼리를 통해 원본 데이터베이스 엔진은 파티션 제거를 활용할 수 있습니다. 원본 데이터베이스 테이블은 분할할 필요가 없습니다. 원본이 아직 분할되지 않은 경우 ADF는 원본 변환에서 선택한 키에 따라 Spark 변환 환경에서 데이터 분할을 계속 사용합니다.

![원본 파트](media/data-flow/sourcepart3.png "원본 파트")

> [!NOTE]
> 원본에 대해 적절한 파티션 수를 선택하려면 Azure Integration Runtime에 대해 설정한 코어 수에 5를 곱하여 지정하는 것이 좋습니다. 예를 들어, ADLS 폴더에 있는 일련의 파일을 변환하고 32 코어 Azure IR을 활용하려는 경우 대상으로 사용하려는 파티션 수는 32 x 5 = 160개 파티션입니다.

### <a name="source-batch-size-input-and-isolation-level"></a>원본 일괄 처리 크기, 입력 및 격리 수준

원본 변환의 **원본 옵션**에서 다음 설정이 성능에 영향을 줄 수 있습니다.

* 일괄 처리 크기를 선택하면 ADF는 행 단위 대신 Spark 메모리의 세트에 데이터를 저장하게 됩니다. 일괄 처리 크기는 선택적 설정이며 적절하게 크기를 조정하지 않은 경우 컴퓨팅 노드에서 리소스가 부족할 수 있습니다. 이 속성을 설정하지 않으면 Spark 캐싱 일괄 처리 기본값이 사용됩니다.
* 쿼리를 설정하면 처리를 위해 데이터 흐름에 도착하기 전에 원본에서 행을 필터링할 수 있습니다. 이를 통해 초기 데이터를 더 빠르게 취득할 수 있습니다. 쿼리를 사용하는 경우 Azure SQL DB에 대해 선택적 쿼리 힌트(예: READ UNCOMMITTED)를 추가할 수 있습니다.
* 커밋되지 않은 읽기는 원본 변환에서 더 빠른 쿼리 결과를 제공합니다.

![원본](media/data-flow/source4.png "원본")

### <a name="sink-batch-size"></a>싱크 일괄 처리 크기

데이터 흐름의 행 단위 처리를 방지하려면 Azure SQL DB 및 Azure SQL DW 싱크의 설정 탭에서 **일괄 처리 크기**를 설정합니다. 일괄 처리 크기를 설정한 경우 ADF는 제공된 크기에 따라 일괄 처리로 데이터베이스 쓰기를 처리합니다. 이 속성을 설정하지 않으면 Spark 캐싱 일괄 처리 기본값이 사용됩니다.

![싱크](media/data-flow/sink4.png "sink")

### <a name="partitioning-on-sink"></a>싱크에서 분할

대상 테이블에서 데이터를 분산하지 않은 경우에도 싱크 변환에서 데이터를 분할하는 것이 좋습니다. 분할된 데이터를 사용하면 모든 연결에서 강제로 단일 노드/파티션을 사용하도록 하는 것보다 로드가 훨씬 더 빨라집니다. 싱크의 최적화 탭으로 이동하고 *라운드 로빈* 분할을 선택하여 싱크에 쓸 이상적인 파티션 수를 선택합니다.

### <a name="disable-indexes-on-write"></a>쓰기 시 인덱스 사용 안 함

파이프라인에서 데이터 흐름 작업 전에 싱크에서 작성된 대상 테이블의 인덱스를 사용하지 않도록 설정하는 [저장 프로시저 작업](transform-data-using-stored-procedure.md)을 추가합니다. 데이터 흐름 작업 후 해당 인덱스를 사용하도록 설정하는 다른 저장 프로시저 작업을 추가합니다. 또는 데이터베이스 싱크에서 전처리 및 후처리 스크립트를 활용합니다.

### <a name="increase-the-size-of-your-azure-sql-db-and-dw"></a>Azure SQL DB 및 DW의 크기 늘리기

일단 DTU 한도에 도달하면, 파이프라인 실행 전에 원본 크기 조정을 예약하고 Azure SQL DB 및 DW를 싱크하여 처리량을 늘리고 Azure 제한을 최소화합니다. 파이프라인 실행이 완료되면 데이터베이스를 다시 일반 실행 속도로 조정합니다.

* 887,000개 행 및 74개 열이 있는 SQL DB 원본 테이블에서 단일 파생 열이 있는 SQL DB 테이블로의 변환은 메모리 최적화 80 코어 디버그 Azure IR을 사용하여 종단 간에 약 3분이 소요됩니다.

### <a name="azure-synapse-sql-dw-only-use-staging-to-load-data-in-bulk-via-polybase"></a>[Azure Synapse SQL DW에만 해당] 스테이징을 사용하여 Polybase를 통해 데이터를 대량으로 로드

DW에 대한 행 단위 삽입을 방지하려면 ADF에서 [PolyBase](https://docs.microsoft.com/sql/relational-databases/polybase/polybase-guide)를 사용할 수 있도록 싱크 설정에서 **스테이징 사용**을 선택합니다. PolyBase를 사용하면 ADF가 데이터를 대량으로 로드할 수 있습니다.
* 파이프라인에서 데이터 흐름 작업을 실행할 경우 대량 로드 동안 데이터를 준비하기 위한 Blob 또는 ADLS Gen2 스토리지 위치를 선택해야 합니다.

* 74개 열이 있는 421Mb 파일의 파일 원본에서 Synapse 테이블 및 단일 파생 열로의 변환은 메모리 최적화 80 코어 디버그 Azure IR을 사용하여 종단 간에 약 4분이 소요됩니다.

## <a name="optimizing-for-files"></a>파일 최적화

각 변환에서 데이터 팩터리가 사용하도록 할 파티션 구성표를 최적화 탭에서 설정할 수 있습니다. 기본 분할 및 최적화를 유지하여 파일 기반 싱크를 먼저 테스트하는 것이 좋습니다. 파일 대상에 대 한 싱크에서 "현재 분할"로 분할 하면 Spark에서 작업에 대 한 적절 한 기본 분할을 설정할 수 있습니다. 기본 분할은 파티션당 128Mb를 사용 합니다.

* 더 작은 파일의 경우 Spark에 작은 파일을 분할하도록 요청하는 것보다 더 적은 수의 파티션을 선택할 때 더 빠르게 잘 진행될 수 있습니다.
* 원본 데이터에 대한 충분한 정보가 없는 경우 *라운드 로빈* 분할을 선택하고 파티션 수를 설정합니다.
* 데이터에 적절한 해시 키가 될 수 있는 열이 있는 경우 *해시 분할*을 선택합니다.

* 74개 열과 단일 파생 열이 있는 421Mb 파일의 파일 싱크를 포함하는 파일 원본에서 변환하는 데는 메모리 최적화 80 코어 디버그 Azure IR을 사용하여 종단 간에 약 2분이 소요됩니다.

데이터 미리 보기 및 파이프라인 디버그에서 디버그할 때 파일 기반 원본 데이터 세트의 제한 및 샘플링 크기가 읽은 행 수가 아니라 반환된 행 수에만 적용됩니다. 이로 인해 디버그 실행의 성능에 영향을 줄 수 있으며 흐름이 실패할 수 있습니다.
* 디버그 클러스터는 기본적으로 작은 단일 노드 클러스터이며 디버깅을 위해 작은 샘플 파일을 사용하는 것이 좋습니다. 디버그 설정으로 이동한 후, 임시 파일을 사용하여 데이터의 작은 하위 세트를 가리킵니다.

    ![디버그 설정](media/data-flow/debugsettings3.png "디버그 설정")

### <a name="file-naming-options"></a>파일 명명 옵션

Blob 또는 ADLS 파일 저장소를 기록하는 매핑 데이터 흐름에서 변환된 데이터를 작성하는 가장 일반적인 방법입니다. 싱크에서 명명된 파일이 아니라 컨테이너 또는 폴더를 가리키는 데이터 세트를 선택해야 합니다. 매핑 데이터 흐름은 실행을 위해 Spark를 사용하므로 출력은 파티션 구성표에 따라 여러 파일로 분할됩니다.

일반적인 파티션 구성표는 _단일 파일로 출력_을 선택해야 합니다. 그러면 모든 출력 PART 파일이 싱크의 단일 파일에 병합됩니다. 이 작업을 수행하려면 출력이 단일 클러스터 노드의 단일 파티션으로 줄어듭니다. 많은 양의 원본 파일을 단일 출력 파일에 결합하는 경우 클러스터 노드 리소스가 부족할 수 있습니다.

컴퓨팅 노드 리소스가 고갈되지 않도록 하려면 데이터 흐름의 최적화된 기본 체계를 유지하고 출력 폴더의 모든 PART 파일을 새 단일 파일에 병합하는 복사 작업을 파이프라인에 추가합니다. 이 기법은 파일 병합에서 변환 작업을 분리하고 _단일 파일에 출력_ 설정과 동일한 결과를 보관합니다.

### <a name="looping-through-file-lists"></a>파일 목록 반복

원본 변환이 For Each 작업을 통해 반복되는 대신, 여러 파일에 반복되는 경우 매핑 데이터 흐름이 더 효율적으로 실행됩니다. 원본 변환에서 와일드카드 또는 파일 목록을 사용하는 것이 좋습니다. 데이터 흐름 프로세스는 Spark 클러스터 내에서 반복이 진행되도록 하여 더 빠르게 실행됩니다. 자세한 내용은 [원본 변환의 와일드카드 사용](connector-azure-data-lake-storage.md#mapping-data-flow-properties)을 참조하세요.

예를 들어, Blob 스토리지의 폴더에 처리하려는 2019년 7월 데이터 파일 목록이 있는 경우 원본 변환에서 다음과 같은 와일드카드를 사용할 수 있습니다.

```DateFiles/*_201907*.txt```

와일드카드를 사용하면 파이프라인에는 데이터 흐름 작업이 하나만 포함됩니다. 이 경우 Blob 저장소에 대해 조회를 수행하고 데이터 흐름 실행 작업 내에서 ForEach를 사용하여 일치하는 모든 파일에 대해 반복되는 것보다 더 잘 진행됩니다.

병렬 모드의 파이프라인 For Each는 실행되는 모든 데이터 흐름 작업에 대해 작업 클러스터를 실행하여 여러 클러스터를 생성합니다. 이로 인해 동시 실행 수가 많은 Azure 서비스가 제한될 수 있습니다. 그러나 파이프라인에서 순차 세트와 함께 For Each 내에서 데이터 흐름 실행을 사용하면 제한 및 리소스 고갈을 방지할 수 있습니다. 이렇게 하면 강제로 데이터 팩터리는 데이터 흐름에 대해 순차적으로 각 파일을 실행하게 됩니다.

순서대로 데이터 흐름에 For Each를 사용하는 경우 Azure Integration Runtime에서 TTL 설정을 활용하는 것이 좋습니다. 이는 각 파일에 반복기 내에서 전체 4 분 클러스터 시작 시간이 발생 하기 때문입니다.

### <a name="optimizing-for-cosmosdb"></a>CosmosDB에 맞게 최적화

CosmosDB 싱크에 대해 처리량 및 일괄 처리 속성을 설정할 경우 파이프라인 데이터 흐름 작업에서 해당 데이터 흐름을 실행하는 동안에만 적용됩니다. 원래 컬렉션 설정은 데이터 흐름을 실행한 후 CosmosDB에서 적용됩니다.

* 일괄 처리 크기: 데이터의 대략적인 행 크기를 계산하고 행 크기 * 일괄 처리 크기가 200만보다 작은지 확인합니다. 이 크기보다 작으면 일괄 처리 크기를 늘려 처리량을 높입니다.
* 처리량: 여기에서 더 높은 처리량을 설정하여 CosmosDB에 문서를 더 빨리 쓸 수 있도록 합니다. 높은 처리량 설정에 따라 더 높은 수준의 비용이 발생한다는 점에 유의합니다.
*   쓰기 처리량 예산: 분당 총 RU보다 작은 값을 사용합니다. 많은 수의 Spark 파티션이 포함된 데이터 흐름이 있는 경우 예산 처리량을 설정하여 해당 파티션에서 부하를 분산시킬 수 있습니다.

## <a name="join-and-lookup-performance"></a>조인 및 조회 성능

데이터 흐름의 조인 성능을 관리하는 작업은 데이터 변환의 수명 주기 동안 수행되는 매우 일반적인 작업입니다. ADF의 데이터 흐름에서는 이러한 작업이 Spark의 해시 조인으로 수행되므로 조인 전에 데이터를 정렬하지 않아도 됩니다. 그러나 조인, 있음 및 조회 변환에 적용되는 "브로드캐스트" 조인 최적화를 사용하여 성능 향상의 이점을 누릴 수 있습니다.

이렇게 하면 조인 관계의 한쪽 내용을 Spark 노드에 푸시하여 즉석에서 순서가 섞이지 않도록 합니다. 이 작업은 참조 조회에 사용되는 소규모 테이블에 적합합니다. 노드 메모리에 맞지 않을 수 있는 대규모 테이블은 브로드캐스트 최적화에 적합하지 않습니다.

조인 작업이 많은 데이터 흐름에 권장 되는 구성은 "브로드캐스트"에 대해 최적화를 "자동"으로 설정 하 고 ***메모리 최적화*** Azure Integration Runtime 구성을 사용 하는 것입니다. 데이터 흐름을 실행하는 동안 메모리 오류나 브로드캐스트 시간 제한이 발생하는 경우에는 브로드캐스트 최적화를 해제할 수 있습니다. 그러나 이로 인해 데이터 흐름이 더 느리게 수행됩니다. 필요에 따라 조인의 왼쪽이나 오른쪽만 또는 양쪽 모두에서 푸시다운하도록 데이터 흐름에 지시할 수 있습니다.

![브로드캐스트 설정](media/data-flow/newbroad.png "브로드캐스트 설정")

또 다른 조인 최적화는 Spark의 크로스 조인 구현 경향을 방지하는 방식으로 조인을 구축하는 것입니다. 예를 들어, 조인 조건에 리터럴 값을 포함하는 경우 Spark는 전체 카티션 곱을 먼저 수행한 후 조인된 값을 필터링하라는 요구 조건으로 인식할 수 있습니다. 그러나 조인 조건의 양쪽에 열 값이 있는 경우 이러한 Spark로 인한 카티션 곱을 방지하고 조인 및 데이터 흐름의 성능을 향상시킬 수 있습니다.

## <a name="next-steps"></a>다음 단계

성능과 관련된 다음과 같은 다른 데이터 흐름 문서를 참조하세요.

- [데이터 흐름 최적화 탭](concepts-data-flow-overview.md#optimize)
- [데이터 흐름 작업](control-flow-execute-data-flow-activity.md)
- [데이터 흐름 성능 모니터링](concepts-data-flow-monitoring.md)
