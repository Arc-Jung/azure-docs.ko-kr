---
title: 데이터 흐름 성능 및 튜닝 가이드 매핑
description: Azure 데이터 팩터리에서 매핑 데이터 흐름의 성능에 영향을 주는 주요 요인에 대해 알아봅니다.
author: kromerm
ms.topic: conceptual
ms.author: makromer
ms.service: data-factory
ms.custom: seo-lt-2019
ms.date: 04/14/2020
ms.openlocfilehash: c09a035c8994118b0fb116f357485766e05883ac
ms.sourcegitcommit: b80aafd2c71d7366838811e92bd234ddbab507b6
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 04/16/2020
ms.locfileid: "81418442"
---
# <a name="mapping-data-flows-performance-and-tuning-guide"></a>데이터 흐름 성능 및 튜닝 가이드 매핑

[!INCLUDE[appliesto-adf-xxx-md](includes/appliesto-adf-xxx-md.md)]

Azure 데이터 팩터리의 데이터 흐름 매핑은 대규모 데이터 변환을 설계, 배포 및 오케스트레이션할 수 있는 코드 없는 인터페이스를 제공합니다. 데이터 흐름 매핑에 익숙하지 않은 경우 [데이터 흐름 매핑 개요를](concepts-data-flow-overview.md)참조하십시오.

ADF UX에서 데이터 흐름을 디자인하고 테스트할 때는 클러스터가 워밍업될 때까지 기다리지 않고 디버그 모드를 전환하여 실시간으로 데이터 흐름을 실행해야 합니다. 자세한 내용은 [디버그 모드를](concepts-data-flow-debug-mode.md)참조하십시오.

이 비디오에서는 데이터 흐름을 사용하여 데이터를 변환하는 몇 가지 샘플 타이밍을 보여 주며 다음과 같은 샘플을 보여 주며 다음과 같은 작업을 수행합니다.
> [!VIDEO https://www.microsoft.com/en-us/videoplayer/embed/RE4rNxM]

## <a name="monitoring-data-flow-performance"></a>데이터 흐름 성능 모니터링

매핑 데이터 흐름을 디자인하는 동안 구성 패널의 데이터 미리 보기 탭을 클릭하여 각 변환을 단위 테스트할 수 있습니다. 논리를 확인한 후 데이터 흐름을 파이프라인의 활동으로 종단 간 테스트합니다. 데이터 흐름 실행 활동을 추가하고 디버그 버튼을 사용하여 데이터 흐름의 성능을 테스트합니다. 데이터 흐름의 실행 계획 및 성능 프로필을 열려면 파이프라인의 출력 탭에서 '작업' 아래의 안경 아이콘을 클릭합니다.

![데이터 흐름 모니터](media/data-flow/mon002.png "데이터 흐름 모니터 2")

 이 정보를 사용하여 다양한 크기의 데이터 원본에 대해 데이터 흐름의 성능을 예측할 수 있습니다. 자세한 내용은 [매핑 데이터 흐름 모니터링을](concepts-data-flow-monitoring.md)참조하십시오.

![데이터 흐름 모니터링](media/data-flow/mon003.png "데이터 흐름 모니터 3")

 파이프라인 디버그 실행의 경우 웜 클러스터의 경우 전체 성능 계산에서 클러스터 설정 시간의 약 1분이 필요합니다. 기본 Azure 통합 런타임을 초기화하는 경우 스핀업 시간이 약 5분 정도 걸릴 수 있습니다.

## <a name="increasing-compute-size-in-azure-integration-runtime"></a>Azure 통합 런타임에서 컴퓨팅 크기 증가

코어가 많은 통합 런타임은 Spark 컴퓨팅 환경의 노드 수를 늘리고 데이터를 읽고 쓰고 변환하는 데 더 많은 처리 능력을 제공합니다. ADF 데이터 흐름은 컴퓨팅 엔진에 스파크를 활용합니다. Spark 환경은 메모리에 최적화된 리소스에서 매우 잘 작동합니다.
* 처리 속도가 입력 속도보다 높게 하려면 **계산 최적화** 클러스터를 사용해 보십시오.
* **메모리에** 더 많은 데이터를 캐시하려는 경우 메모리 최적화 클러스터를 사용해 보십시오. 최적화된 메모리는 컴퓨트 최적화보다 코어당 가격포인트가 높지만 변환 속도가 빨라질 수 있습니다.

![새로운 IR](media/data-flow/ir-new.png "새로운 IR")

통합 런타임을 만드는 방법에 대한 자세한 내용은 [Azure 데이터 팩터리의 통합 런타임을](concepts-integration-runtime.md)참조하십시오.

### <a name="increase-the-size-of-your-debug-cluster"></a>디버그 클러스터의 크기 증가

기본적으로 디버그를 켜면 각 데이터 팩터리에 대해 자동으로 만들어지는 기본 Azure 통합 런타임이 사용됩니다. 이 기본 Azure IR은 일반 계산 속성을 사용하여 8개의 코어, 드라이버 노드에 대해 4개, 작업자 노드에 대해 4개로 설정됩니다. 더 큰 데이터로 테스트할 때 더 큰 구성을 사용하는 Azure IR을 만들어 디버그 클러스터의 크기를 늘리고 디버그를 켤 때 이 새 Azure IR을 선택할 수 있습니다. 이렇게 하면 ADF가 데이터 흐름이 있는 데이터 미리 보기 및 파이프라인 디버그에 이 Azure IR을 사용하도록 지시합니다.

### <a name="decrease-cluster-compute-start-up-time-with-ttl"></a>TTL을 통해 클러스터 계산 시작 시간 단축

데이터 흐름 속성 아래에 Azure IR에 팩토리에 대한 클러스터 계산 리소스 풀을 사용할 수 있는 속성이 있습니다. 이 풀을 사용하면 실행을 위해 데이터 흐름 활동을 순차적으로 제출할 수 있습니다. 풀이 설정되면 온디맨드 Spark 클러스터에서 작업을 실행하는 데 1~2분 정도 걸릴 수 있습니다. 리소스 풀의 초기 설정에는 약 6분이 소요됩니다. TTL(Time-to-Live) 설정에서 리소스 풀을 유지 관리할 시간을 지정합니다.

## <a name="optimizing-for-azure-sql-database-and-azure-sql-data-warehouse-synapse"></a>Azure SQL 데이터베이스 및 Azure SQL 데이터 웨어하우스 시냅스에 대한 최적화

### <a name="partitioning-on-source"></a>소스에서 분할

1. **최적화** 탭으로 이동하여 **분할 설정 선택**
1. **소스**를 선택합니다.
1. **파티션 수에서**Azure SQL DB에 대한 최대 연결 수를 설정합니다. 더 높은 설정을 시도하여 데이터베이스에 대한 병렬 연결을 얻을 수 있습니다. 그러나 제한된 수의 연결로 인해 성능이 빨라질 수 있는 경우도 있습니다.
1. 특정 테이블 열또는 쿼리로 분할할지 여부를 선택합니다.
1. **열을**선택한 경우 파티션 열을 선택합니다.
1. **쿼리를**선택한 경우 데이터베이스 테이블의 분할 구성표와 일치하는 쿼리를 입력합니다. 이 쿼리를 사용하면 원본 데이터베이스 엔진이 파티션 제거를 활용할 수 있습니다. 원본 데이터베이스 테이블을 분할할 필요가 없습니다. 원본이 아직 분할되지 않은 경우에도 ADF는 소스 변환에서 선택한 키를 기반으로 Spark 변환 환경에서 데이터 분할을 계속 사용합니다.

![소스 부품](media/data-flow/sourcepart3.png "소스 부품")

> [!NOTE]
> 원본용 파티션 수를 선택하는 데 도움이 되는 좋은 가이드는 Azure 통합 런타임에 대해 설정한 코어 수를 기반으로 하며 해당 수를 5로 곱합니다. 예를 들어 ADLS 폴더의 일련의 파일을 변환하고 32코어 Azure IR을 활용하려는 경우 대상으로 하는 파티션 수는 32 x 5 = 160파티션입니다.

### <a name="source-batch-size-input-and-isolation-level"></a>소스 배치 크기, 입력 및 격리 수준

소스 변환의 **소스 옵션에서** 다음 설정은 성능에 영향을 줄 수 있습니다.

* 일괄 처리 크기는 ADF가 행별 대신 스파크 메모리에 데이터를 집합에 저장하도록 지시합니다. 일괄 처리 크기는 선택적 설정이며 제대로 크기가 조정되지 않은 경우 계산 노드의 리소스가 부족할 수 있습니다. 이 속성을 설정하지 않는 것은 Spark 캐싱 일괄 처리 기본값을 활용합니다.
* 쿼리를 설정하면 처리를 위해 데이터 흐름에 도착하기 전에 원본에서 행을 필터링할 수 있습니다. 이렇게 하면 초기 데이터 수집이 빨라집니다. 쿼리를 사용하는 경우 READ UNCOMMITTED과 같은 Azure SQL DB에 대한 선택적 쿼리 힌트를 추가할 수 있습니다.
* 커밋되지 않은 읽기는 소스 변환에서 더 빠른 쿼리 결과를 제공합니다.

![원본](media/data-flow/source4.png "원본")

### <a name="sink-batch-size"></a>싱크 배치 크기

데이터 흐름의 행별 처리를 방지하려면 Azure SQL DB 및 Azure SQL DW 싱크에 대한 설정 탭에서 **일괄 처리 크기를** 설정합니다. 일괄 처리 크기를 설정하면 ADF는 제공된 크기에 따라 데이터베이스 쓰기를 일괄 처리합니다. 이 속성을 설정하지 않는 것은 Spark 캐싱 일괄 처리 기본값을 활용합니다.

![sink](media/data-flow/sink4.png "sink")

### <a name="partitioning-on-sink"></a>싱크대에서 분할

대상 테이블에 데이터가 분할되어 있지 않더라도 싱크 변환에서 데이터를 분할하는 것이 좋습니다. 분할된 데이터는 종종 모든 연결을 통해 단일 노드/파티션을 사용하도록 로드하는 속도가 훨씬 빨라집니다. 싱크대의 최적화 탭으로 이동하여 *라운드 로빈* 분할을 선택하여 싱크대에 쓸 파티션의 이상적인 수를 선택합니다.

### <a name="disable-indexes-on-write"></a>쓰기시 인덱스 사용 안 함

파이프라인에서 Sink에서 작성된 대상 테이블의 인덱스를 사용하지 않도록 설정하는 데이터 흐름 작업 전에 [저장 프로시저 활동을](transform-data-using-stored-procedure.md) 추가합니다. 데이터 흐름 활동 후 해당 인덱스를 활성화하는 다른 저장 프로시저 활동을 추가합니다. 또는 데이터베이스 싱크에서 전처리 및 사후 처리 스크립트를 활용합니다.

### <a name="increase-the-size-of-your-azure-sql-db-and-dw"></a>Azure SQL DB 및 DW의 크기를 늘립니다.

파이프라인이 실행되기 전에 원본의 크기 조정을 예약하고 Azure SQL DB 및 DW를 싱크하여 처리량을 늘리고 DTU 한도에 도달하면 Azure 제한을 최소화합니다. 파이프라인 실행이 완료되면 데이터베이스의 크기를 정상 실행 속도로 다시 조정합니다.

* 887k 행과 74개의 열을 단일 파생 열 변환이 있는 SQL DB 테이블이 있는 SQL DB 원본 테이블은 메모리에 최적화된 80코어 디버그 Azure IRs를 사용하여 종단 간 약 3분이 소요됩니다.

### <a name="azure-synapse-sql-dw-only-use-staging-to-load-data-in-bulk-via-polybase"></a>[Azure 시냅스 SQL DW만] 스테이징을 사용하여 Polybase를 통해 대량으로 데이터 로드

DW에 행별 삽입을 방지하려면 ADF에서 [PolyBase를](https://docs.microsoft.com/sql/relational-databases/polybase/polybase-guide)사용할 수 있도록 싱크 설정에서 **스테이징 활성화를** 선택합니다. PolyBase를 사용하면 ADF가 데이터를 대량으로 로드할 수 있습니다.
* 파이프라인에서 데이터 흐름 활동을 실행할 때 대량 로드 하는 동안 데이터를 스테이징할 Blob 또는 ADLS Gen2 저장소 위치를 선택 해야 합니다.

* 시냅스 테이블에 74개의 열을 가진 421Mb 파일의 파일 소스와 단일 파생 열 변환은 메모리에 최적화된 80코어 디버그 Azure IRs를 사용하여 종단 간 약 4분이 소요됩니다.

## <a name="optimizing-for-files"></a>파일 최적화

각 변환에서 최적화 탭에서 데이터 팩터리에서 사용할 분할 체계를 설정할 수 있습니다. 기본 분할 및 최적화를 유지 하는 파일 기반 싱크를 먼저 테스트 하는 것이 좋습니다.

* 작은 파일의 경우 Spark에 작은 파일을 분할하도록 요청하는 것보다 더 적은 수의 파티션을 선택하면 더 빠르게 작동할 수 있습니다.
* 원본 데이터에 대한 정보가 충분하지 않은 경우 *라운드 로빈* 분할을 선택하고 파티션 수를 설정합니다.
* 데이터에 좋은 해시 키가 될 수 있는 열이 있는 경우 *해시 분할을 선택합니다.*

* 74개의 열이 있는 421Mb 파일의 파일 싱크와 단일 파생 열 변환이 있는 파일 소스는 최적화된 80코어 디버그 Azure IRs를 사용하여 종단 간 약 2분이 소요됩니다.

데이터 미리 보기 및 파이프라인 디버그에서 디버깅할 때 파일 기반 원본 데이터 집합의 제한 및 샘플링 크기는 읽은 행 수가 아니라 반환되는 행 수에만 적용됩니다. 디버그 실행의 성능에 영향을 미치고 흐름이 실패할 수 있습니다.
* 디버그 클러스터는 기본적으로 작은 단일 노드 클러스터이며 디버깅을 위해 샘플 작은 파일을 사용하는 것이 좋습니다. 디버그 설정으로 이동하여 임시 파일을 사용하여 데이터의 작은 하위 집합을 가리킵니다.

    ![디버그 설정](media/data-flow/debugsettings3.png "디버그 설정")

### <a name="file-naming-options"></a>파일 이름 지정 옵션

Blob 또는 ADLS 파일 저장소를 작성하는 데이터 흐름 매핑에서 변환된 데이터를 작성하는 가장 일반적인 방법입니다. 싱크대에서 명명된 파일이 아닌 컨테이너 또는 폴더를 가리키는 데이터 집합을 선택해야 합니다. 매핑 데이터 흐름은 Spark를 사용하여 실행을 수행하므로 분할 구성표에 따라 여러 파일로 출력이 분할됩니다.

일반적인 분할 구성표는 모든 출력 PART 파일을 싱크의 단일 파일로 병합하는 _단일 파일로 출력을_선택하는 것입니다. 이 작업을 수행하려면 출력이 단일 클러스터 노드의 단일 파티션으로 줄어듭니다. 많은 대용량 소스 파일을 단일 출력 파일로 결합하는 경우 클러스터 노드 리소스가 부족할 수 있습니다.

계산 노드 리소스가 소모되지 않도록 하려면 데이터 흐름에 기본, 최적화된 스키마를 유지하고 파이프라인에 모든 PART 파일을 출력 폴더에서 새 단일 파일로 병합하는 복사 활동을 추가합니다. 이 기술은 변환 작업을 파일 병합과 분리하고 _출력을 단일 파일로_설정하는 것과 동일한 결과를 얻을 수 있습니다.

### <a name="looping-through-file-lists"></a>파일 목록을 반복

Source 변환이 For Each 활동을 통해 반복하는 대신 여러 파일을 반복할 때 매핑 데이터 흐름이 더 잘 실행됩니다. 소스 변환에서 와일드카드 또는 파일 목록을 사용하는 것이 좋습니다. 데이터 흐름 프로세스는 Spark 클러스터 내에서 루핑이 발생할 수 있도록 하여 더 빠르게 실행됩니다. 자세한 내용은 [소스 변환에서 와일드카드를](connector-azure-data-lake-storage.md#mapping-data-flow-properties)참조하십시오.

예를 들어 Blob Storage의 폴더에서 처리하려는 2019년 7월의 데이터 파일 목록이 있는 경우 아래는 소스 변환에 사용할 수 있는 와일드카드입니다.

```DateFiles/*_201907*.txt```

와일드카드를 사용하면 파이프라인에 하나의 데이터 흐름 활동만 포함됩니다. 이렇게 하면 Blob 스토어에 대한 조회보다 성능이 향상되며, 내부에 데이터 흐름 실행 활동이 있는 ForEach를 사용하여 일치하는 모든 파일을 연속합니다.

### <a name="optimizing-for-cosmosdb"></a>코스모스DB에 대한 최적화

CosmosDB 싱크에 처리량 및 일괄 처리 속성을 설정하면 파이프라인 데이터 흐름 활동에서 해당 데이터 흐름을 실행할 때만 적용됩니다. 원래 컬렉션 설정은 데이터 흐름 실행 후 CosmosDB에 의해 적용됩니다.

* 일괄 처리 크기: 데이터의 대략적인 행 크기를 계산하고 rowSize * 일괄 처리 크기가 2백만 개 미만인지 확인합니다. 그렇다면 배치 크기를 늘려 처리량을 향상시려면
* 처리량: 문서가 CosmosDB에 더 빠르게 쓸 수 있도록 처리량 설정을 여기에 설정합니다. 높은 처리량 설정에 따라 더 높은 RU 비용을 염두에 두십시오.
*   처리량 예산 작성: 분당 총 RS보다 작은 값을 사용합니다. Spark 파티션 수가 많은 데이터 흐름이 있는 경우 예산 처리량을 설정하면 해당 파티션 간에 더 많은 균형을 맞출 수 있습니다.

## <a name="join-performance"></a>참여 실적

데이터 흐름에서 조인의 성능을 관리하는 것은 데이터 변환의 수명 주기 동안 수행하는 매우 일반적인 작업입니다. ADF에서 데이터 흐름은 Spark에서 해시 조인으로 수행되기 때문에 조인 전에 데이터를 정렬할 필요가 없습니다. 그러나 "브로드캐스트" 조인 최적화를 통해 향상된 성능을 활용할 수 있습니다. 이렇게 하면 조인 관계의 양쪽 의 내용을 스파크 노드로 밀어 셔플을 방지할 수 있습니다. 참조 조회에 사용되는 작은 테이블에 적합합니다. 노드의 메모리에 맞지 않을 수 있는 큰 테이블은 브로드캐스트 최적화에 적합하지 않습니다.

또 다른 조인 최적화는 교차 조인을 구현하는 Spark의 경향을 방지하는 방식으로 조인을 작성하는 것입니다. 예를 들어 조인 조건에 리터럴 값을 포함하면 Spark는 전체 카르테시안 제품을 먼저 수행한 다음 결합된 값을 필터링해야 하는 요구 사항으로 볼 수 있습니다. 그러나 조인 조건의 양쪽에 열 값이 있는지 확인하면 이 Spark 로 유도된 카르테시안 제품을 방지하고 조인 및 데이터 흐름의 성능을 향상시킬 수 있습니다.

## <a name="next-steps"></a>다음 단계

성능과 관련된 다른 데이터 흐름 문서를 참조하십시오.

- [데이터 흐름 최적화 탭](concepts-data-flow-overview.md#optimize)
- [데이터 흐름 활동](control-flow-execute-data-flow-activity.md)
- [데이터 흐름 성능 모니터링](concepts-data-flow-monitoring.md)
