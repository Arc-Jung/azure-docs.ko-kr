<properties
	pageTitle="복사 작업 성능 및 조정 가이드 | Microsoft Azure"
	description="복사 작업을 통한 Azure Data Factory의 데이터 이동의 성능에 영향을 주는 주요 요소에 대해 알아봅니다."
	services="data-factory"
	documentationCenter=""
	authors="spelluru"
	manager="jhubbard"
	editor="monicar"/>

<tags
	ms.service="data-factory"
	ms.workload="data-services"
	ms.tgt_pltfrm="na"
	ms.devlang="na"
	ms.topic="article"
	ms.date="06/03/2016"
	ms.author="spelluru"/>


# 복사 작업 성능 및 조정 가이드
이 문서에서는 Azure Data Factory의 데이터 이동(복사 작업) 성능에 영향을 주는 주요 요소에 대해 설명합니다. 또한 내부 테스트 중에 관측된 성능을 나열하고 복사 작업의 성능을 최적화하는 다양한 방법을 설명합니다.

복사 작업을 사용하면, 다음 예제와 같이, 데이터 이동 처리량을 높일 수 있습니다.

- 3시간 내에 데이터 1TB를 온-프레미스 파일 시스템 및 Azure Blob 저장소에서 Azure Blob 저장소로 수집합니다(즉, @ 100MBps).
- 3시간 내에 데이터 1TB를 온-프레미스 파일 시스템 및 Azure Blob 저장소에서 Azure Data Lake 저장소로 수집합니다(즉, @ 100MBps). 
- 3시간 내에 데이터 1TB를 Azure Blob 저장소에서 Azure SQL 데이터 웨어하우스로 수집합니다(즉, @ 100MBps). 

다음 섹션에서 복사 작업 성능 및 튜닝 팁에 대해 자세히 알아보고, 성능을 향상시키세요.

> [AZURE.NOTE] 복사 작업에 대해 전반적으로 잘 알고 있다면, 이 문서를 읽기 전에 [데이터 이동 활동](data-factory-data-movement-activities.md)을 살펴보세요.

## 성능 튜닝 단계
복사 작업을 사용하여 Azure 데이터 팩터리의 성능을 튜닝하기 위해 제안하는 일반적인 단계는 다음과 같습니다.

1.	**기초 설정.** 개발 단계 중 대표적인 샘플 데이터에 대한 복사 작업을 사용하여 파이프라인을 테스트합니다. Azure 데이터 팩터리의 [모델 조각화](data-factory-scheduling-and-execution.md#time-series-datasets-and-data-slices)를 활용하여 사용하는 데이터의 양을 제한할 수 있습니다.

	**모니터링 및 관리 앱**을 사용하여 실행 시간 및 성능 특성을 수집합니다. 데이터 팩터리 홈 페이지에서 **모니터링 및 관리** 타일을 클릭하고, 트리 뷰에서 **출력 데이터 집합**을 선택한 다음, **Activity Windows**(작업 기간) 목록에서 복사 작업 실행을 선택합니다. 복사 작업 기간은 **Activity Windows**(작업 기간) 목록에서, 복사되는 데이터의 크기 및 처리량은 오른쪽의 **Activity Window Explorer**(작업 기간 탐색기) 창에서 볼 수 있습니다. 앱에 대해 자세히 알아보려면, [모니터링 및 관리 앱을 사용하여 Azure 데이터 팩터리 파이프라인 모니터링 및 관리](data-factory-monitor-manage-app.md)를 살펴보세요.
	
	![작업 실행 세부 정보](./media/data-factory-copy-activity-performance/mmapp-activity-run-details.png)

	시나리오의 성능 및 구성을 내부 관찰에 기반하여 아래 게시된 복사 작업의 [성능 참조](#performance-reference)와 비교할 수 있습니다.
2. **성능 진단 및 최적화** 관찰한 성능이 기대 보다 낮은 경우 병목 현상의 영향을 제거하거나 줄일 수 있도록 성능 병목을 식별하고 최적화를 수행해야 합니다. 성능 진단에 대한 자세한 내용은 이 문서의 범위를 벗어나지만 다음과 같이 몇 가지 일반적인 고려 사항을 나열합니다.
	- [원본](#considerations-on-source)
	- [싱크](#considerations-on-sink)
	- [직렬화/역직렬화](#considerations-on-serializationdeserialization)
	- [압축](#considerations-on-compression)
	- [열 매핑](#considerations-on-column-mapping)
	- [데이터 관리 게이트웨이](#considerations-on-data-management-gateway)
	- [기타 고려 사항](#other-considerations)
	- [병렬 복사](#parallel-copy)
	- [클라우드 데이터 이동 단위](#cloud-data-movement-units)    

3. **전체 데이터에 해당 구성 확장** 실행 결과 및 성능에 만족하면 데이터 집합 정의 및 파이프라인 활성 기간을 확장하여 그림에서 전체 데이터를 포함할 수 있습니다.

## 성능 참조
> [AZURE.IMPORTANT] **고지 사항:** 아래 데이터는 지침 및 높은 수준의 계획을 목적으로 게시되었습니다. 대역폭, 하드웨어, 구성 등이 해당 클래스에서 최고라고 가정합니다. 참조용으로만 사용합니다. 관찰하는 데이터 이동 처리량은 변수 범위의 영향을 받습니다. 나중에 섹션을 참조하여 데이터 이동 요구 사항에 대한 성능을 조정하고 개선하는 방법에 대해 알아봅니다. 이 데이터는 성능 개선 사항 및 기능을 추가할 때 업데이트됩니다.

![성능 매트릭스](./media/data-factory-copy-activity-performance/CopyPerfRef.png)

주의할 사항:

- 처리량은 다음 수식을 사용하여 계산됩니다. [원본에서 읽은 데이터의 크기]/[복사 작업 실행 기간]
- [TPC-H](http://www.tpc.org/tpch/) 데이터 집합은 위 숫자를 계산하는 데 활용되었습니다.
- Microsoft Azure 데이터 저장소의 경우 원본 및 싱크는 동일한 Azure 지역에 있습니다.
- **cloudDataMovementUnits**은 1로 설정되고, **parallelCopies**는 지정되지 않았습니다.
- 하이브리드(온-프레미스와 클라우드 또는 클라우드와 온-프레미스) 데이터 이동의 경우 데이터 관리 게이트웨이(단일 인스턴스)는 다음 구성을 사용하여 온-프레미스 데이터 저장소가 아닌 다른 컴퓨터에서 호스팅되었습니다. 게이트웨이에서 실행 중인 단일 작업을 통해 복사 작업은 이 컴퓨터의 CPU/메모리 리소스 및 네트워크 대역폭의 작은 부분을 사용합니다.
	<table>
	<tr>
		<td>CPU</td>
		<td>32 코어 2.20GHz Intel Xeon® E5-2660 v2</td>
	</tr>
	<tr>
		<td>메모리</td>
		<td>128GB</td>
	</tr>
	<tr>
		<td>네트워크</td>
		<td>인터넷 인터페이스: 10Gbps. 인트라넷 인터페이스: 40Gbps</td>
	</tr>
	</table>

## 병렬 복사
복사 작업의 처리량을 높이고 데이터 이동 시간을 줄이는 한 가지 방법은, **복사 작업 실행 내에서 병렬로** 원본에서 데이터를 읽어오거나 대상에 데이터를 쓰는 것입니다.
 
이 설정은 작업 정의의 **concurrency** 속성과 다릅니다. 동시성 속성은 다양한 작업 기간(오전1-2시, 오전2-3시, 오전3-4시, 등)의 데이터를 처리하기 위해 런타임 시 동시에 실행되는 **동시 복사 작업 실행**의 수를 결정합니다. 이것은 기록 로드를 수행하는 경우에 특히 유용합니다. 반면에, 이 문서에서 설명하는 병렬 복사 기능은 **단일 작업 실행**에 적용됩니다.

처리해야 하는 과거의 조각이 여러 개 있는 다음 예제를 고려하여 **동일한 시나리오**를 살펴보겠습니다. Data Factory 서비스는 각 조각에 대한 복사 작업(작업 실행) 인스턴스를 하나 실행합니다.

- 첫 번째 작업 기간(오전 1시 - 오전 2시)의 데이터 조각 ==> 작업 실행 1
- 두 번째 작업 기간(오전 2시 - 오전 3시)의 데이터 조각 ==> 작업 실행 2
- 세 번째 작업 기간(오전 3시 - 오전 4시)의 데이터 조각 ==> 작업 실행 3
- 등을 나타낼 수 있습니다.

이 예제의 **동시성** 설정이 **2**이기 때문에, **작업 실행 1** 및 **작업 실행 2**에서 두 작업 기간의 데이터를 **동시에** 복사하여 데이터 이동 성능을 향상시킬 수 있습니다. 하지만, 작업 실행 1에 관련된 파일이 여러 개이면, 원본에서 대상으로 한 번에 하나의 파일이 복사됩니다.

### parallelCopies
**parallelCopies** 속성을 사용하여 복사 작업에 사용할 병렬 처리를 나타낼 수 있습니다. 간단히 말해, 이 속성을 병렬로 원본에서 읽어오거나 싱크 데이터 저장소에 쓰는 복사 작업 내 최대 스레드 수라고 생각할 수 있습니다.

각각의 복사 작업 실행에 대해, Azure Data Factory는 원본 데이터 저장소의 데이터를 대상 데이터 저장소에 복사하는 데 사용할 병렬 복사의 수를 지능적으로 결정합니다. 사용되는 병렬 복사의 기본 수는 원본 및 싱크의 유형에 따라 달라집니다.

원본 및 싱크 |	서비스에 의해 결정되는 기본 병렬 복사 개수
------------- | -------------------------------------------------
**파일 기반 저장소**(Azure Blob, Azure Data Lake, 온-프레미스 파일 시스템, 온-프레미스 HDFS) 간의 데이터 복사 | **파일 크기** 및 **클라우드 데이터 이동 단위의 수**(다음 섹션에서 정의 참조)에 기반하여 **1~32** 사이의 수가, 두 클라우드 데이터 저장소 간에 데이터를 복사하거나, 하이브리드 복사(온-프레미스 데이터 저장소의/저장소에 데이터를 복사하는)에 사용되는 게이트웨이 컴퓨터에 대한 물리적인 구성에 사용됩니다.
**원본 데이터 저장소의 데이터를 Azure 테이블에** 복사 | 4
기타 모든 원본 및 싱크 쌍 | 1

대부분의 경우, 기본 동작이 최고의 처리량을 제공합니다. 하지만, 데이터 저장소를 사용하여 컴퓨터에 대한 로드를 제어하거나 복사 성능을 조정하기 위해 **parallelCopies** 속성의 값을 지정하여 기본 값을 재정의할 수 있습니다. **1에서 32(두 숫자 모두 포함)** 사이여야 합니다. 런타임 시, 복사 작업은 최고의 성능을 제공하기 위해 구성된 값 이하의 값을 선택합니다.

	"activities":[  
	    {
	        "name": "Sample copy activity",
	        "description": "",
	        "type": "Copy",
	        "inputs": [{ "name": "InputDataset" }],
	        "outputs": [{ "name": "OutputDataset" }],
	        "typeProperties": {
	            "source": {
	                "type": "BlobSource",
	            },
	            "sink": {
	                "type": "AzureDataLakeStoreSink"
	            },
	            "parallelCopies": 8
	        }
	    }
	]

다음 사항에 유의하세요.

- 파일 기반 저장소 사이의 데이터 복사는, 파일 수준에서 병렬 처리가 발생합니다. 다시 말해, 단일 파일 내 청크가 없습니다. 런타임 시 복사 작업에 사용되는 병렬 복사의 실제 수는 사용에게 있는 파일의 수를 넘지 않습니다. 복사 동작이 mergeFile이면, 병렬 처리는 사용되지 않습니다.
- 특히, 동일한 데이터 저장소에 대해 실행되는 동일한 작업의 동시 실행이나 작업이 여러 개인 경우에는, parallelCopies 속성의 값을 지정할 때, 원본 및 싱크 데이터 저장소에 초래될 로드의 증가는 물론 게이트웨이(하이브리드 복사인 경우)를 고려하십시오. 데이터 저장소나 게이트웨이가 로드로 인해 과부하가 걸리면, 로드가 감소되도록 parallelCopies 값을 줄이십시오.
- 파일 기반이 아닌 저장소에서 파일 기반 저장소로 데이터를 복사하는 경우에는 parallelCopies 속성을 지정해도 무시되고, 병렬 처리는 사용되지 않습니다.

> [AZURE.NOTE] 하이브리드 복사를 수행할 때 parallelCopies 기능의 이점을 활용하려면, 1.11 버전 이상의 데이터 관리 게이트웨이를 사용해야 합니다.

### 클라우드 데이터 이동 단위
**클라우드 데이터 이동 단위**는 클라우드-클라우드 복사 작업을 수행하는 데 사용되는 Azure Data Factory 서비스 내 단일 단위의 힘(CPU, 메모리, 네트워크 자원 할당의 조합)을 나타내는 척도입니다. 하이브리드 복사를 수행할 때는 적용되지 않습니다. 기본적으로, Azure Data Factory 서비스는 단일 클라우드 데이터 이동 단위를 사용하여 단일 복사 작업 실행을 수행합니다. **cloudDataMovementUnits** 속성에 대한 값을 지정하여 기본값을 재정의할 수 있습니다. 현재, cloudDataMovementUnits 설정은 **두 Azure blob 저장소 사이**에 데이터를 복사하거나 **Azure Blob 저장소에서 Azure Data Lake 저장소**로 데이터를 복사하는 **경우에만 지원**되며, 복사할 파일이 여러 개이고, 각 파일의 크기가 16MB 이상인 경우에 효과가 나타납니다.

**parallelCopies** 속성의 값을 높게 설정하고 다수의 비교적 큰 파일을 복사하면, 단일 클라우드 데이터 이동 단위에 대한 리소스 제한으로 인해 성능은 향상되지 않습니다. 이런 경우, 대량의 데이터를 높은 처리량으로 복사하기 위해 더 많은 클라우드 데이터 이동 단위를 사용할 수 있습니다. 복사 작업에 사용할 클라우드 데이터 이동 단위의 수를 지정하려면, **cloudDataMovementUnits** 속성에 대한 값을 아래와 같이 설정합니다.

	"activities":[  
	    {
	        "name": "Sample copy activity",
	        "description": "",
	        "type": "Copy",
	        "inputs": [{ "name": "InputDataset" }],
	        "outputs": [{ "name": "OutputDataset" }],
	        "typeProperties": {
	            "source": {
	                "type": "BlobSource",
	            },
	            "sink": {
	                "type": "AzureDataLakeStoreSink"
	            },
	            "cloudDataMovementUnits": 4
	        }
	    }
	]

cloudDataMovementUnits 속성에 **허용되는 값** 은 1(기본값), 2, 4, 8입니다. 더 높은 처리량을 위해 더 많은 클라우드 데이터 이동 단위가 필요하면 [Azure 지원](https://azure.microsoft.com/blog/2014/06/04/azure-limits-quotas-increase-requests/)에 문의하시기 바랍니다. 런타임 시 복사 작업에 사용되는 **클라우드 데이터 이동 단위의 실제 수**는, 크기 기준을 충족하는 원본에서 복사될 파일의 수에 따라서, 구성된 값과 같아지거나 작아집니다.

> [AZURE.NOTE] parallelCopies 값은 cloudDataMovementUnits(지정된 경우) 값보다 크거나 같아야 합니다. cloudDataMovementUnits이 1보다 크면, 해당되는 복사 작업 실행을 위해 cloudDataMovementUnits 전반에 병렬 데이터 이동이 분산되고, 이를 통해 처리량이 올라갑니다.

**cloudDataMovementUnits**을 2, 4, 8로 설정하여 큰 파일을 여러 개 복사하는 경우, 성능 참조 섹션에 언급된 참조 숫자의 2배, 4배, 7배까지 성능이 도달할 수 있습니다.

위의 2가지 속성을 활용하여 데이터 이동 처리량을 향상시키려면 여기에서 [샘플 사용 사례](#case-study---parallel-copy)를 참조하세요.
 
복사 작업의 총 시간을 기준으로 요금이 청구된다는 점을 기억하는 것이 **중요**합니다. 따라서 클라우드 단위 1개로 1시간이 걸렸던 복사 작업이 이제 클라우드 단위 4개로 15분이 걸리는 경우 전체 청구 금액은 거의 같습니다. 또 다른 시나리오는 다음과 같습니다. 클라우드 단위 4개를 사용하는데 복사 작업이 실행된 상태에서 첫 번째 클라우드 단위는 10분을 사용하고, 두 번째 클라우드 단위는 10분을 사용하며, 세 번째 클라우드 단위는 5분을 사용하고, 네 번째 클라우드 단위는 5분을 사용한다고 가정하면, 총 복사(데이터 이동) 시간 30분(10 + 10 + 5 + 5)에 대해 요금이 청구됩니다. **parallelCopies** 사용은 청구 요금에 영향을 미치지 않습니다.

## 준비된 복사
원본 데이터 저장소에서 싱크 데이터 저장소에 데이터를 복사할 경우 중간 준비 저장소인 Azure Blob 저장소를 사용할 수 있습니다. 이 준비 기능은 다음과 같은 경우에 특히 유용합니다.

1.	**때로는 느린 네트워크 연결을 통해 하이브리드 데이터 이동(즉, 온-프레미스 데이터 저장소에서 클라우드 데이터 저장소 또는 그 반대로)을 수행하는 데 오랜 시간이 걸립니다.** 이러한 데이터 이동의 성능을 향상시키려면 데이터 온-프레미스를 압축하여 클라우드의 준비 데이터 저장소에 대한 연결을 통해 데이터를 이동하는 데 걸리는 시간을 줄일 수 있습니다. 그런 다음 데이터를 대상 데이터 저장소에 로드하기 전에 준비 저장소에서 데이터의 압축을 해제합니다. 
2.	**IT 정책으로 인해 방화벽에서 포트 80 및 443이 아닌 포트를 열지 않으려 합니다.** 예를 들어 온-프레미스 데이터 저장소에서 Azure SQL 데이터베이스 싱크 또는 Azure SQL 데이터 웨어하우스 싱크에 데이터를 복사할 경우 Windows 방화벽 및 회사 방화벽 모두에 대한 포트 1433에서 아웃바운드 TCP 통신을 사용하도록 설정해야 합니다. 이러한 시나리오에서 데이터 관리 게이트웨이를 활용하여 준비 Azure Blob 저장소에 데이터를 먼저 복사할 수 있습니다. 이는 Http(s) 즉, 포트 443을 통해 수행되고 준비 Blob 저장소에서 SQL 데이터베이스 또는 SQL 데이터 웨어하우스로 데이터를 로드합니다. 이러한 흐름에서 포트 1433을 사용할 필요가 없습니다. 
3.	**PolyBase를 통해 다양한 데이터 저장소에서 Azure SQL 데이터 웨어하우스에 데이터를 수집합니다.** Azure SQL 데이터 웨어하우스는 많은 양의 데이터를 SQL 데이터 웨어하우스에 로드하는 처리량이 높은 메커니즘인 PolyBase를 제공합니다. 그러나 이렇게 하려면 원본 데이터가 Azure Blob 저장소에 있어야 하고 일부 추가 조건을 충족해야 합니다. Azure Blob 저장소 이외의 데이터 저장소에서 데이터를 로드할 경우 중간 준비 Azure blob 저장소를 통해 데이터를 복사할 수 있습니다. 이 경우에 Azure 데이터 팩터리는 PolyBase의 요구 사항을 만족하도록 데이터에 필요한 변환을 수행하고 SQL 데이터 웨어하우스로 데이터를 로드하는 데 PolyBase를 활용합니다. 자세한 내용 및 샘플은 [PolyBase를 사용하여 Azure SQL 데이터 웨어하우스에 데이터 로드](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse)를 참조하세요.

### 준비 복사의 작동 방법
준비 기능을 사용하도록 설정하면 먼저 데이터가 원본 데이터 저장소에서 준비 데이터 저장소(직접 준비)로 복사된 다음 준비 데이터 저장소에서 복사되어 데이터 저장소를 싱크합니다. Azure 데이터 팩터리는 자동으로 사용자에 대한 2단계 흐름을 관리하고 데이터 이동이 완료된 후에 준비 저장소에서 임시 데이터를 정리합니다.

원본 및 싱크 데이터 저장소가 모두 클라우드에 있고 데이터 관리 게이트웨이를 활용하지 않는 **클라우드 복사 시나리오**에서 복사 작업은 **Azure 데이터 팩터리 서비스**에 의해 수행됩니다.

![준비 복사 - 클라우드 시나리오](media/data-factory-copy-activity-performance/staged-copy-cloud-scenario.png)

반면에 **하이브리드 복사 시나리오**에서는 원본이 온-프레미스이고 싱크가 클라우드에 있습니다. 이 때 원본 데이터 저장소에서 준비 데이터 저장소로 데이터를 이동하는 작업은 **데이터 관리 게이트웨이**에 의해 수행되고 준비 데이터 저장소에서 싱크 데이터 저장소로 데이터를 이동하는 작업은 **Azure 데이터 팩터리 서비스**에 의해 수행됩니다.

![준비 복사 - 하이브리드 시나리오](media/data-factory-copy-activity-performance/staged-copy-hybrid-scenario.png)

준비 저장소를 사용한 데이터 이동을 사용하도록 설정하면 원본 데이터 저장소에서 중간/준비 데이터 저장소로 데이터를 이동하기 전에 데이터를 압축할지 및 중간/준비 데이터 저장소에서 싱크 데이터 저장소로 데이터를 이동하기 전에 압축할지 여부를 지정할 수 있습니다.

클라우드 데이터에서 온-프레미스 데이터 저장소에 또는 준비 저장소를 사용하여 두 온-프레미스 데이터 저장소 간에 데이터를 복사하는 작업은 이 시점에서 지원되지 않지만 곧 지원될 예정입니다.

### 구성
복사 작업에 **enableStaging** 설정을 구성하여 데이터를 대상 데이터 저장소에 로드하기 전에 Azure Blob 저장소에서 준비할지 여부를 지정할 수 있습니다. enableStaging을 true로 설정한 경우 다음 테이블에 나열된 추가 속성을 지정해야 합니다. Azure 저장소 또는 준비된 Azure 저장소 SAS 연결된 서비스가 아직 없는 경우 만들어야 합니다.

속성 | 설명 | 기본값 | 필수
--------- | ----------- | ------------ | --------
enableStaging | 중간 준비 저장소를 통해 데이터를 복사할지 여부를 지정합니다. | False | 아니요
linkedServiceName | 중간 준비 저장소로 사용될 Azure 저장소를 참조하여 이름을 [AzureStoage](data-factory-azure-blob-connector.md#azure-storage-linked-service) 또는 [AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service) 연결된 서비스로 지정합니다. <br/><br/> PolyBase를 통해 Azure SQL 데이터 웨어하우스로 데이터를 로드하는 데 SAS(공유 액세스 서명)을 포함한 Azure 저장소를 사용할 수 없습니다. 다른 모든 시나리오에서 사용할 수 있습니다. | 해당 없음 | 예, enableStaging true로 설정된 경우입니다. 
path | 준비 데이터가 포함된 Azure Blob 저장소에 경로를 지정합니다. 경로를 제공하지 않으면 서비스는 임시 데이터를 저장하는 컨테이너를 만듭니다. <br/><br/> SAS를 포함한 Azure 저장소를 사용하지 않거나 임시 데이터가 상주해야 한다는 강력한 요구 사항이 없으면 경로를 지정할 필요가 없습니다. | 해당 없음 | 아니요
enableCompression | 데이터가 원본 데이터 저장소에서 싱크 데이터 저장소로 이동하는 경우 압축할지 여부를 지정하여 통신 중에 전송되는 데이터의 양을 감소시킵니다. | False | 아니요

다음은 위의 속성을 가진 복사 작업에 대한 샘플 정의입니다.

	"activities":[  
	{
		"name": "Sample copy activity",
		"type": "Copy",
		"inputs": [{ "name": "OnpremisesSQLServerInput" }],
		"outputs": [{ "name": "AzureSQLDBOutput" }],
		"typeProperties": {
			"source": {
				"type": "SqlSource",
			},
			"sink": {
				"type": "SqlSink"
			},
	    	"enableStaging": true,
			"stagingSettings": {
				"linkedServiceName": "MyStagingBlob",
				"path": "stagingcontainer/path",
				"enableCompression": true
			}
		}
	}
	]

### 청구 영향
복사 기간의 두 단계 및 해당하는 각가의 복사 형식에 따라 요금이 청구됩니다. 즉:

- 클라우드 복사 중에 준비 저장소를 사용할 경우(예를 들어 Azure Data Lake에서 Azure SQL 데이터 웨어하우스 등 클라우드 데이터 저장소에서 다른 클라우드 데이터 저장소에 데이터를 복사) [1단계 및 2단계 복사 기간의 합]x[클라우드 복사 단가]로 요금이 청구됩니다.
- 하이브리드 복사 중에 준비 저장소를 사용하는 경우(예를 들어 온-프레미스 SQL Server 데이터베이스에서 Azure SQL 데이터 웨어하우스 등 온-프레미스 데이터 저장소에서 클라우드 데이터 저장소로 데이터를 복사) [하이브리드 복사 기간]x[클라우드 복사 단가]+[클라우드 복사 기간]x[하이브리드 복사 단가]로 요금이 청구됩니다.


## 원본에 대한 고려 사항
### 일반
기본 데이터 저장소가 복사 작업을 포함하여 다른 실행 중인 워크로드에 의해 과부화되지 않도록 합니다.

Microsoft 데이터 저장소의 경우 데이터 저장소 성능 특성를 이해하고 응답 시간을 최소화하며 처리량을 최대화할 수 있도록 하는 데이터 저장소 특정 [모니터링 및 튜닝 항목](#appendix-data-store-performance-tuning-reference)을 참조합니다.

**Azure Blob 저장소**에서 **Azure SQL 데이터 웨어하우스**로 데이터를 복사하는 경우에는, 성능을 높이기 위해 **PolyBase**를 사용하는 것이 좋습니다. 자세한 내용은 [PolyBase를 사용하여 Azure SQL 데이터 웨어하우스에 데이터 로드](data-factory-azure-sql-data-warehouse-connector.md###use-polybase-to-load-data-into-azure-sql-data-warehouse)를 참조하세요.


### 파일 기반 데이터 저장소
*(Azure Blob, Azure 데이터 레이크, 온-프레미스 파일 시스템 포함)*

- **평균 파일 크기 및 파일 개수**: 복사 작업은 데이터 파일을 하나씩 전송합니다. 동일한 양의 데이터를 이동하는 경우 각 파일에 대한 부트스트랩 단계이기 때문에 적은 수의 큰 파일 대신 많은 수의 작은 파일로 데이터가 구성되는 경우 전체 처리량은 느려집니다. 따라서 가능하면 작은 파일을 더 큰 파일에 결합하여 처리량을 높입니다.
- **파일 형식 및 압축**: 성능을 향상하는 다양한 방법은 [직렬화/역직렬화에 대한 고려 사항](#considerations-on-serializationdeserialization) 및 [압축에 대한 고려 사항](#considerations-on-compression) 섹션을 참조하세요.
- 또한 **데이터 관리 게이트웨이**를 사용해야 하는 **온-프레미스 파일 시스템** 시나리오는 [게이트웨이에 대한 고려 사항](#considerations-on-data-management-gateway) 섹션을 참조하세요.

### 관계형 데이터 저장소
*(Azure SQL 데이터베이스, Azure SQL 데이터 웨어하우스, SQL Server 데이터베이스, Oracle 데이터베이스, MySQL 데이터베이스, DB2, Teradata 데이터베이스, Sybase 데이터베이스, PostgreSQL 데이터베이스 포함)*

- **데이터 패턴**: 테이블 스키마는 복사본 처리량에 영향을 줍니다. 동일한 양의 데이터를 복사하려면 데이터베이스가 더 적은 행 수를 포함하는 데이터에서 적은 배치를 보다 효율적으로 검색할 수 있기 때문에 행 크기가 크면 행 크기가 작은 경우 보다 더 성능이 나아집니다.
- **쿼리 또는 저장 프로시저**: 데이터를 보다 효율적으로 가져오기 위해 복사 작업 원본에서 지정한 쿼리 또는 저장 프로시저의 논리를 최적화합니다.
- 또한 **데이터 관리 게이트웨이**를 사용해야 하는 SQL Server 및 Oracle과 같은 **온-프레미스 관계형 데이터베이스**는 [게이트웨이에 대한 고려 사항](#considerations-on-data-management-gateway) 섹션을 참조하세요.

## 싱크에 대한 고려 사항

### 일반
기본 데이터 저장소가 복사 작업을 포함하여 다른 실행 중인 워크로드에 의해 과부화되지 않도록 합니다.

Microsoft 데이터 저장소의 경우 데이터 저장소 성능 특성를 이해하고 응답 시간을 최소화하며 처리량을 최대화할 수 있도록 하는 데이터 저장소 특정 [모니터링 및 튜닝 항목](#appendix-data-store-performance-tuning-reference)을 참조합니다.

**Azure Blob 저장소**에서 **Azure SQL 데이터 웨어하우스**로 데이터를 복사하는 경우에는, 성능을 높이기 위해 **PolyBase**를 사용하는 것이 좋습니다. 자세한 내용은 [PolyBase를 사용하여 Azure SQL 데이터 웨어하우스에 데이터 로드](data-factory-azure-sql-data-warehouse-connector.md###use-polybase-to-load-data-into-azure-sql-data-warehouse)를 참조하세요.


### 파일 기반 데이터 저장소
*(Azure Blob, Azure 데이터 레이크, 온-프레미스 파일 시스템 포함)*

- **복사 동작**: 다른 파일 기반 데이터 저장소에서 데이터를 복사하는 경우 복사 작업은 "copyBehavior" 속성을 통해 계층 구조를 유지하고 계층 구조를 평면화하며 파일을 병합하는 등 세 가지 형식의 동작을 제공합니다. 계층 구조를 유지 또는 평면화하는 작업은 성능 오버 헤드가 거의 발생하지 않는 반면 파일을 병합하는 작업은 추가 성능 오버 헤드가 발생합니다.
- **파일 형식 및 압축**: 성능을 향상하는 다양한 방법은 [직렬화/역직렬화에 대한 고려 사항](#considerations-on-serializationdeserialization) 및 [압축에 대한 고려 사항](#considerations-on-compression) 섹션을 참조하세요.
- 현재 **Azure Blob**의 경우 최적화된 데이터 전송 및 처리량에 대해 블록 Blob를 지원합니다.
- 또한 **데이터 관리 게이트웨이**를 사용해야 하는 **온-프레미스 파일 시스템** 시나리오는 [게이트웨이에 대한 고려 사항](#considerations-on-data-management-gateway) 섹션을 참조하세요.

### 관계형 데이터 저장소
*(Azure SQL 데이터베이스, Azure SQL 데이터 웨어하우스, SQL Server 데이터베이스 포함)*

- **복사 동작**: "sqlSink"에 대해 구성된 속성에 따라 복사 작업은 데이터를 대상 데이터베이스에 서로 다른 방식으로 작성합니다.
	- 기본적으로 데이터 이동 서비스는 대량 복사 API를 사용하여 추가 모드에 데이터를 삽입하며 이는 최상의 성능을 제공합니다.
	- 싱크에서 저장된 프로시저를 구성하는 경우 데이터베이스는 대량 로드 행별로 데이터를 적용하므로 성능이 크게 저하됩니다. 데이터의 크기가 크면 적용할 수 있을 때 대신 "sqlWriterCleanupScript" 속성(아래 참조)을 사용하도록 전환하는 것이 좋습니다.
	- 실행한 각 복사 작업에 "sqlWriterCleanupScript" 속성을 구성하는 경우 서비스는 스크립트를 먼저 트리거한 다음 대량 복사 API를 사용하여 데이터를 삽입합니다. 예를 들어 최신 데이터를 사용하여 전체 테이블을 덮어쓰려면 원본에서 새 데이터를 대량으로 로드하기 전에 먼저 스크립트를 지정하여 모든 레코드를 삭제할 수 있습니다.
- **데이터 패턴 및 배치 크기**:
	- 테이블 스키마는 복사 처리량에 영향을 받습니다. 동일한 양의 데이터를 복사하려면 데이터베이스가 데이터에서 적은 배치를 보다 효율적으로 커밋할 수 있기 때문에 행 크기가 크면 행 크기가 작은 경우 보다 더 성능이 나아집니다.
	- 복사 작업은 일련의 배치에 데이터를 삽입하며 여기서 배치에 포함된 행 수는 "writeBatchSize" 속성을 사용하여 설정될 수 있습니다. 데이터에 작은 크기의 행이 있으면 높은 값을 가진 "writeBatchSize" 속성을 설정하여 적은 수의 배치 오버헤드로 혜택을 받고 처리량을 증가시킬 수 있습니다. 데이터의 행 크기가 큰 경우 writeBatchSize의 증가에 주의합니다 – 값이 크면 데이터베이스의 오버로드로 인해 복사 오류가 발생할 수 있습니다.
- 또한 **데이터 관리 게이트웨이**를 사용해야 하는 SQL Server 및 Oracle과 같은 **온-프레미스 관계형 데이터베이스**는 [게이트웨이에 대한 고려 사항](#considerations-on-data-management-gateway) 섹션을 참조하세요.


### NoSQL 저장소
*(Azure 테이블, Azure DocumentDB를 포함)*

- **Azure 테이블의 경우**:
	- **파티션**: 인터리브 파티션에 데이터를 작성하면 성능이 크게 저하됩니다. 파티션 키로 원본 데이터의 순서를 선택할 수 있으므로 데이터는 파티션 각각에 효율적으로 삽입되거나 논리를 조정하여 단일 파티션에 데이터를 기록할 수 있습니다.
- **Azure DocumentDB**의 경우:
	- **배치 크기**: "writeBatchSize" 속성은 문서를 작성하는 DocumentDB 서비스에 대한 병렬 요청 수를 나타냅니다. DocumentDB에 더 많은 병렬 요청이 전송되기 때문에 “writeBatchSize” 증가하는 경우 더 나은 성능을 기대할 수 있습니다. 그러나 DocumentDB(오류 메시지 "요청 속도가 큽니다")에 작성할 때 제한에 주의하세요. 문서의 크기, 문서에서 용어의 수 및 대상 컬렉션의 인덱싱 정책 등 여러 가지 요인으로 인해 제한이 발생할 수 있습니다. 복사 처리량을 더 높이려면 더 나은 컬렉션(예: S3)을 사용하는 것이 좋습니다.

## 직렬화/역직렬화에 대한 고려 사항
입력 데이터 집합 또는 출력 데이터 집합이 파일인 경우 직렬화 및 역직렬화가 발생할 수 있습니다. 현재 복사 작업은 Avro 및 텍스트(예: CSV 및 TSV) 데이터 형식을 지원합니다.

**복사 동작:**

- 파일 기반 데이터 저장소 간에 파일을 복사하는 경우:
	- 두 입력 및 출력 데이터 집합이 동일한 파일 형식이거나 파일 형식 설정이 없을 때 데이터 이동 서비스는 직렬화/역직렬화를 수행하지 않고 이진 복사를 실행합니다. 따라서 원본/싱크 파일 형식 설정이 다른 시나리오에 비해 더 나은 처리량을 관찰하게 됩니다.
	- 인코딩 형식만 다른 반면 입력 및 출력 데이터 집합이 모두 텍스트 형식인 경우 데이터 이동 서비스는 직렬화/역직렬화를 수행하지 않고 인코딩 변환을 수행하며 이렇게 되면 이진 복사본에 비해 일부 성능 오버헤드가 발생합니다.
	- 입력 및 출력 데이터 집합이 파일 형식이 다르거나 구분 기호와 같이 구성이 다른 경우 데이터 이동 서비스는 원본 데이터를 역직렬화하여 스트리밍, 변환한 다음 바람직한 출력 형식으로 직렬화합니다. 이전 시나리오에 비해 훨씬 더 심각한 성능 오버헤드가 발생합니다.
- 비파일 기반 데이터 저장소(예: 관계형 저장소에 대한 파일 기반 저장소) 간에 파일을 복사할 때 직렬화 또는 역직렬화의 단계는 필수적이고 이는 상당한 성능 오버헤드를 발생시킬 수 있습니다.

**파일 형식:** 파일 형식을 선택하는 것은 복사 성능이 영향을 줄 수 있습니다. 예를 들어 Avro는 데이터를 사용하여 메타데이터를 저장하는 간단한 이진 형식이며 처리 및 쿼리에 대한 Hadoop 에코시스템을 광범위하게 지원합니다. 그러나 Avro는 텍스트 형식에 비해 복사 처리량이 더 낮은 직렬화/역직렬화의 경우 더 비쌉니다. 처리 흐름을 따라 사용할 파일 형식을 선택하는 작업은 전체적으로 이루어져야 합니다. 원본 데이터 저장소에 저장하거나 외부 시스템에서 추출될 데이터 형식에서 시작하여 저장소로 가장 적절한 형식, 분석 처리 및 쿼리, 그리고 보고 및 시각화 도구에 대한 데이터 마트에 데이터를 내보낼 형식 등이 포함됩니다. 경우에 따라 읽기 및 쓰기 성능에 대해 최적인 파일 형식은 전체 분석 프로세스를 고려하는 데 적합할 수 있습니다.

## 압축에 대한 고려 사항
입력 또는 출력 데이터 집합이 파일인 경우 대상에 데이터를 쓸 때 복사 작업을 구성하여 압축하거나 압축을 해제할 수 있습니다. 압축을 사용하여 I/O 및 CPU 간에 다음과 같이 절충합니다. 데이터를 압축하는 작업은 추가 계산 리소스 비용이 들지만 반대로 네트워크 I/O 및 저장소를 줄이며 이는 데이터에 따라 전체 복사 처리량을 높일 수 있습니다.

**코덱:** GZIP, BZIP2 및 Deflate 압축 형식이 지원됩니다. 세 가지 형식은 모두 처리를 위해 Azure HDInsight에서 사용할 수 있습니다. 압축 코덱에는 각각 고유성이 있습니다. 예를 들어 BZIP2는 가장 낮은 복사 처리량을 갖지만 처리를 위해 분할될 수 있다는 점에서 최상의 Hive 쿼리 성능을 제공합니다. GZIP는 가장 균형 있는 옵션을 제공하고 가장 자주 사용됩니다. 종단 간 시나리오에 가장 적합한 코덱을 선택해야 합니다.

**수준:** 각 압축 코덱의 경우 빠른 압축 및 최적 압축이라는 두 옵션 중에서 선택할 수 있습니다. 파일이 최적으로 압축되지 않은 경우에도 가장 빠르게 압축된 옵션은 데이터를 최대한 빨리 압축합니다. 최적으로 압축된 옵션은 최소한의 데이터를 생성하도록 압축에 더 많은 시간을 사용합니다. 두 옵션 모두 테스트하여 어떤 옵션이 사용자에게 더 나은 성능을 제공하는지 확인할 수 있습니다.

**고려 사항:** 대역폭 회사 네트워크 및 Azure가 제한 요소인 경우 온-프레미스 저장소와 클라우드 간의 대용량 데이터를 복사하고 입력 데이터 집합 및 출력 데이터 집합을 모두 압축되지 않은 형식으로 만들려면 압축을 통한 **중간 Azure Blob**의 사용을 고려할 수 있습니다. 보다 구체적으로 단일 복사 작업을 두 개의 복사 작업으로 나눌 수 있습니다. 원본에서 중간 또는 준비 Blob에 압축된 형식으로 복사한 첫 번째 복사 작업 및 싱크를 작성하는 동안 준비 단계에서 압축된 데이터를 복사하고 압축을 해제하는 두 번째 복사 작업입니다.

## 열 매핑에 대한 고려 사항
복사 작업에서 "columnMappings" 속성은 출력 열에 대한 입력 열의 하위 집합을 매핑하는 데 사용될 수 있습니다. 데이터 이동 서비스는 원본에서 데이터를 읽은 후에 싱크를 작성하기 전에 데이터에 열 매핑을 수행해야 합니다. 이 추가 처리는 복사 처리량을 감소시킵니다.

원본 데이터 저장소가 예를 들어 Azure SQL/SQL Server와 같은 관계형 저장소 또는 Azure 테이블/Azure DocumentDB와 같은 NoSQL 저장소처럼 쿼리를 사용할 수 있는 경우 열 매핑을 사용하는 대신 쿼리 속성에 열 필터링/다시 정렬 논리를 푸시하도록 고려할 수 있습니다. 이렇게 하면 원본 데이터 저장소에서 데이터를 읽는 동안 프로젝션을 수행하는 결과가 발생하며 훨씬 더 효율적입니다.

## 데이터 관리 게이트웨이에 대한 고려 사항
게이트웨이 설치 권장 사항은 [데이터 관리 게이트웨이의 사용에 대한 고려 사항](data-factory-move-data-between-onprem-and-cloud.md#Considerations-for-using-Data-Management-Gateway)을 참조합니다.

**게이트웨이 컴퓨터 환경:** 전용 컴퓨터를 사용하여 데이터 관리 게이트웨이를 호스팅하는 것이 좋습니다. 게이트웨이 컴퓨터에서 복사 작업을 하는 동안 PerfMon과 같은 도구를 사용하여 CPU, 메모리 및 대역폭 사용량을 검토합니다. CPU, 메모리 또는 네트워크 대역폭에 병목 상태가 발생하는 경우 더 강력한 컴퓨터로 전환합니다.

**동시 복사 작업 실행:** 데이터 관리 게이트웨이의 단일 인스턴스는 동시에 많은 복사 작업을 지원할 수 있습니다. 즉, 게이트웨이는 동시에 여러 복사 작업을 수행할 수 있습니다.(동시 작업의 수는 게이트웨이 컴퓨터의 하드웨어 구성을 기반으로 계산됩니다) 추가 복사 작업은 게이트웨이에서 선택되거나 작업 제한 시간이 초과될 때까지 큐에서 대기합니다. 게이트웨이에서 리소스 경합을 방지하려면 한 번에 큐에 대기하는 복사 작업의 양을 줄이도록 활동의 일정을 준비하거나 여러 게이트웨이에 부하를 분할하는 것이 좋습니다.


## 기타 고려 사항
복사할 데이터의 크기가 매우 큰 경우 Azure 데이터 팩터리의 조각화 메커니즘을 사용하여 비즈니스 논리를 추가 파티션 데이터에 조정할 수 있고 복사 작업을 더 자주 예약하여 각 복사 작업이 실행되는 데이터 크기를 줄입니다.

지정된 시간에 동일한 데이터 저장소에 접근하는 데이터 집합 및 복사 작업의 수에 주의합니다. 많은 수의 동시 복사 작업은 데이터 저장소를 제한하고 성능 저하, 복사 작업 내부 재시도 및 일부 경우 실행 오류를 발생시킬 수 있습니다.

## 사례 연구 – 온-프레미스 SQL Server에서 Azure Blob로 복사합니다.
**시나리오:** 파이프라인은 온-프레미스 SQL Server에서 Azure Blob로 CSV 형식으로 데이터를 복사하도록 작성됩니다. 복사를 더 빠르게 하려면 CSV 파일이 BZIP2 형식으로 압축되도록 지정합니다.

**테스트 및 분석:** 복사 작업의 처리량이 2MB/s보다 적고 성능 벤치 마크 보다 훨씬 더 느린 것으로 관찰됩니다.

**성능 분석 및 튜닝:** 성능 문제를 해결하려면 우선 데이터가 처리되고 이동되는 방법을 살펴보겠습니다.

1.	**데이터 읽기:** 게이트웨이는 SQL Server에 연결을 열고 쿼리를 보냅니다. SQL Server는 데이터 스트림을 인트라넷을 통해 게이트웨이로 전송하여 응답합니다.
2.	게이트웨이는 데이터 스트림을 CSV 형식으로 **직렬화**하고 데이터를 BZIP2 스트림으로 **압축**합니다.
3.	**데이터 쓰기:** 게이트웨이는 인터넷을 통해 Azure Blob로 BZIP2 스트림을 업로드합니다.

보이는 대로 데이터를 처리하고 다음 스트리밍 순으로 이동합니다. SQL Server -> LAN -> 게이트웨이 -> WAN -> Azure Blob **전반적인 성능은 파이프라인을 통해 최소 처리량에서 제어됩니다**.

![데이터 흐름](./media/data-factory-copy-activity-performance/case-study-pic-1.png)

다음 중 하나 이상의 요소가 성능 병목이 될 수 있습니다.

1.	**원본:** SQL Server 자체는 과도한 로드로 인해 처리량이 낮아집니다.
2.	**데이터 관리 게이트웨이:**
	1.	**LAN:** 게이트웨이가 낮은 대역폭 연결을 사용하는 SQL Server에서 멀리 떨어져 있습니다.
	2.	**게이트웨이 컴퓨터에서 로드**는 다음을 수행하는 제한에 도달했습니다.
		1.	**직렬화:** CSV에 대한 데이터 스트림을 직렬화하면 처리량이 느려집니다.
		2.	**압축:** 느린 압축 코덱이 선택되었습니다.(예: Core i7 2.8MB/s의 BZIP2)
	3.	**WAN:** 회사 네트워크와 Azure 간의 낮은 대역폭입니다.(예: T1= 1544kbps, T2=6312 kbps)
4.	**싱크:** Azure Blob는 처리량이 낮습니다.(해당 SLA가 최소 60MB/s를 보장할 가능성은 상당히 낮음)

이 경우 BZIP2 데이터 압축은 전체 파이프라인을 느리게 만들 수 있습니다. GZIP 압축 코덱을 전환하면 병목 상태를 완화할 수 있습니다.


## 사례 연구 - 병렬 복사  

**시나리오 I:** 1MB 파일 1000개를 온-프레미스 파일 시스템에서 Azure Blob 저장소로 복사하는 경우.

**분석 및 성능 튜닝:** 쿼드 코어 컴퓨터에 데이터 관리 게이트웨이를 설치했다고 가정할 때, Data Factory는 기본적으로 16개의 병렬 복사를 사용하여 파일 시스템에서 Azure Blob으로 동시에 파일을 이동합니다. 이렇게 하면 처리량이 만족스럽게 됩니다. 원한다면 병렬 복사 개수를 명시적으로 지정할 수도 있습니다. 다수의 작은 파일을 복사하는 경우, 병렬 복사는 관련된 리소스를 보다 효과적으로 활용하여 처리량을 급격히 향상시키는 데 유용합니다.

![시나리오 1](./media/data-factory-copy-activity-performance/scenario-1.png)

**시나리오 II:** 크기가 500MB인 Blob 20개를 Azure Blob 저장소에서 Azure Data Lake 저장소로 복사하는 경우.

**분석 및 성능 튜닝:** 이 시나리오에서 Data Factory는 기본적으로 단일 복사(parallelCopies를 1로 설정)를 사용하고 단일 클라우드 데이터 이동 단위를 사용하여 Azure Blob에서 Azure Data Lake로 데이터를 복사합니다. 처리량을 관찰하면 위의 [성능 참조 섹션](#performance-reference)에 언급된 것에 근접한 것을 볼 수 있습니다.

![시나리오 2](./media/data-factory-copy-activity-performance/scenario-2.png)

개별 파일의 크기가 수십 MB를 초과하고 전체 볼륨이 큰 경우에는, parallelCopies 값을 높여도 단일 클라우드 데이터 이동 단위에 대한 리소스 제한이 있기 때문에 복사 성능이 개선되지 않습니다. 대신, 데이터 이동을 수행할 리소스를 더 확보하기 위해서 클라우드 데이터 이동 단위를 더 지정해야 합니다. Data Factory에서 사용자를 위해 병렬 처리를 수행할 수 있도록, parallelCopies 속성에 대한 값은 지정하지 마십시오. 이런 경우, cloudDataMovementUnits을 4로 지정하면 처리량이 약 4배가 됩니다.

![시나리오 3](./media/data-factory-copy-activity-performance/scenario-3.png)

## 데이터 저장소 성능 튜닝 참조
다음은 지원되는 데이터 저장소에 대한 몇 가지 성능 모니터링 및 튜닝 참조입니다.

- Azure 저장소(Azure Blob, Azure 테이블 포함): [Azure 저장소 확장성 목표](../storage/storage-scalability-targets.md) 및 [Azure 저장소 성능 및 확장성 검사 목록](../storage//storage-performance-checklist.md)입니다.
- Azure SQL 데이터베이스: [성능을 모니터링](../sql-database/sql-database-service-tiers.md#monitoring-performance)하고 DTU(데이터베이스 트랜잭션 단위) 비율을 확인할 수 있습니다.
- Azure SQL 데이터 웨어하우스: 해당 기능은 데이터 웨어하우스 단위(DWU)로 측정됩니다. [SQL 데이터 웨어하우스를 통한 탄력적인 성능과 확장](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md)을 참조합니다.
- Azure DocumentDB: [DocumentDB의 성능 수준](../documentdb/documentdb-performance-levels.md)입니다.
- 온-프레미스 SQL Server: [성능에 대한 모니터링 및 튜닝](https://msdn.microsoft.com/library/ms189081.aspx)을 수행합니다.
- 온-프레미스 파일 서버: [파일 서버에 대한 성능 튜닝](https://msdn.microsoft.com/library/dn567661.aspx)입니다.

<!---HONumber=AcomDC_0608_2016-->