---
title: '잠재적 Dirichlet 할당: 모듈 참조'
titleSuffix: Azure Machine Learning
description: 잠재적으로 분류 되지 않은 텍스트를 범주로 그룹화 하는 Dirichlet 할당 모듈을 사용 하는 방법에 대해 알아봅니다.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: likebupt
ms.author: keli19
ms.date: 06/05/2020
ms.openlocfilehash: 2fa969b6dd89000b4d669bc5d42aa09b3cf3a2b2
ms.sourcegitcommit: 877491bd46921c11dd478bd25fc718ceee2dcc08
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 07/02/2020
ms.locfileid: "84751687"
---
# <a name="latent-dirichlet-allocation-module"></a>잠재적 Dirichlet 할당 모듈

이 문서에서는 Azure Machine Learning designer (미리 보기)에서 숨어 있는 Dirichlet 할당 모듈을 사용 하 여 다른 방법으로는 분류 되지 않은 텍스트를 범주로 그룹화 하는 방법을 설명 합니다. 

LDA (숨어 있는 Dirichlet 할당)는 유사한 텍스트를 찾기 위해 자연어 처리에 자주 사용 됩니다. 또 다른 일반적인 용어는 *항목 모델링*입니다.

이 모듈은 텍스트 열을 가져오고 다음 출력을 생성 합니다.

+ 각 범주에 대 한 점수와 함께 원본 텍스트

+ 각 범주에 대해 추출 된 용어와 계수를 포함 하는 기능 매트릭스

+ 입력으로 사용 되는 새 텍스트에 저장 하 고 다시 적용할 수 있는 변환입니다.

이 모듈에서는 scikit 라이브러리를 사용 합니다. Scikit에 대 한 자세한 내용은 자습서 및 알고리즘에 대 한 설명이 포함 된 [GitHub 리포지토리](https://github.com/scikit-learn/scikit-learn)를 참조 하세요.

## <a name="more-about-latent-dirichlet-allocation"></a>숨어 있는 Dirichlet 할당에 대 한 자세한 정보

LDA는 일반적으로 분류 방법이 아닙니다. 그러나 인기 방법을 사용 하므로 알려진 클래스 레이블을 제공 하 고 패턴을 유추할 필요가 없습니다.  대신 알고리즘은 토픽 그룹을 식별 하는 데 사용 되는 확률 모델을 생성 합니다. 확률 모델을 사용 하 여 기존 학습 사례 또는 모델에 제공 하는 새 사례를 입력으로 분류할 수 있습니다.

텍스트와 범주 간의 관계를 강력 하 게 가정 하지 않기 때문에 인기 모델을 사용 하는 것이 좋습니다. 이는 수학적 모델 항목에 대 한 단어 분포만 사용 합니다.

이론적 자료는이 문서에서 설명 합니다 .이 문서에서는 PDF 다운로드로 사용할 수 있습니다. [Dirichlet 할당: Blei, 고도 및 요르단](https://ai.stanford.edu/~ang/papers/nips01-lda.pdf).

이 모듈의 구현은 LDA에 대 한 [scikit 라이브러리](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/decomposition/_lda.py) 를 기반으로 합니다.

자세한 내용은 [기술 참고 사항](#technical-notes) 섹션을 참조 하세요.

## <a name="how-to-configure-latent-dirichlet-allocation"></a>잠재적 Dirichlet 할당을 구성 하는 방법

이 모듈에는 원시 또는 전처리 된 텍스트 열을 포함 하는 데이터 집합이 필요 합니다.

1. 파이프라인에 **숨어 있는 Dirichlet 할당** 모듈을 추가 합니다.

2. 모듈에 대 한 입력으로 하나 이상의 텍스트 열을 포함 하는 데이터 집합을 제공 합니다.

3. **대상 열**에 대해 분석할 텍스트가 포함 된 열을 하나 이상 선택 합니다.

    여러 열을 선택할 수 있지만 **문자열** 데이터 형식 이어야 합니다.

    LDA는 텍스트에서 많은 기능 행렬을 만들기 때문에 일반적으로 단일 텍스트 열을 분석 합니다.

4. **모델링할 항목 수**에 대해 1에서 1000 사이의 정수를 입력 하 여 입력 텍스트에서 파생 시킬 범주 또는 항목 수를 나타냅니다.

    기본적으로 5 개의 항목이 생성 됩니다.

5. **N 그램**의 경우 해시 중에 생성 되는 n 그램의 최대 길이를 지정 합니다.

    기본값은 2 이며,이는 바이 그램 및 29그램을 모두 생성 한다는 의미입니다.

6. **정규화** 옵션을 선택 하 여 출력 값을 확률로 변환 합니다. 

    변환 된 값을 정수로 표시 하는 대신 출력 및 기능 데이터 집합의 값은 다음과 같이 변환 됩니다.

    + 데이터 집합의 값은의 확률로 표시 됩니다 `P(topic|document)` .

    + 기능 항목 매트릭스의 값은의 확률로 표시 됩니다 `P(word|topic)` .

    > [!NOTE] 
    > Azure Machine Learning designer (미리 보기)에서 scikit 라이브러리는 버전 0.19에서 정규화 되지 않은 *doc_topic_distr* 출력을 더 이상 지원 하지 않습니다. 이 모듈에서는 **정규화** 매개 변수를 *기능 토픽 행렬* 출력에만 적용할 수 있습니다. *변환 된 데이터 집합* 출력은 항상 정규화 됩니다.

7. 다음 고급 매개 변수를 설정 하려면 **모든 옵션 표시**옵션을 선택한 다음 **TRUE** 로 설정 합니다.

    이러한 매개 변수는 LDA의 scikit 구현에만 적용 됩니다. Scikit의 LDA에 대 한 몇 가지 좋은 자습서와 공식 [scikit-배우기 문서](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html)도 있습니다.

    + 가는 **매개 변수**입니다. 토픽 배포판의 희박도에 대해 이전 확률을 제공 합니다. 이 매개 변수는이 매개 변수에 해당 `topic_word_prior` 합니다. 단어의 분포가 플랫 인 것으로 간주 되는 경우 값 **1** 을 사용 합니다. 즉, 모든 단어에 equiprobable 가정 합니다. 대부분의 단어를 거의 표시 하지 않는 것으로 생각 되는 경우 더 낮은 값으로 설정할 수 있습니다.

    + **알파 매개 변수**입니다. 문서 별 항목 가중치에 대 한 이전 확률을 지정 합니다. 이 매개 변수는이 매개 변수에 해당 `doc_topic_prior` 합니다.

    + **예상 문서 수**입니다. 처리할 문서 (행)의 최고 예상 값을 나타내는 숫자를 입력 합니다. 이 매개 변수를 사용 하면 모듈이 충분 한 크기의 해시 테이블을 할당할 수 있습니다. `total_samples`Scikit-배우기의 매개 변수에 해당 합니다.

    + **일괄 처리의 크기**입니다. LDA 모델에 전송 된 각 텍스트 배치에 포함할 행 수를 나타내는 숫자를 입력 합니다. 이 매개 변수는 `batch_size` scikit-배우기의 매개 변수에 해당 합니다.

    + **업데이트 일정 학습에 사용 된 반복의 초기 값**입니다. 온라인 학습에서 초기 반복의 학습 률에 가중치를 지정 하는 시작 값을 지정 합니다. 이 매개 변수는 `learning_offset` scikit-배우기의 매개 변수에 해당 합니다.

    + **업데이트 중에 반복에 적용 되는 전원**입니다. 온라인 업데이트 중 학습 률을 제어 하기 위해 반복 횟수에 적용 되는 전원 수준을 표시 합니다. 이 매개 변수는 `learning_decay` scikit-배우기의 매개 변수에 해당 합니다.

    + **데이터에 대 한 패스의 수**입니다. 알고리즘이 데이터를 순환 하는 최대 횟수를 지정 합니다. 이 매개 변수는 `max_iter` scikit-배우기의 매개 변수에 해당 합니다.

8. 텍스트를 분류 하기 전에 초기 패스에서 n-문법 목록을 만들려면 **ngrams의 빌드 사전** 또는 **LDA 이전에 ngrams 빌드**를 선택 합니다.

    초기 사전을 미리 만든 경우 나중에 모델을 검토할 때 사전을 사용할 수 있습니다. 결과를 숫자 인덱스가 아닌 텍스트에 매핑할 수 있는 것은 일반적으로 해석 하기가 더 쉽습니다. 그러나 사전을 저장 하면 더 오래 걸리고 추가 저장소를 사용 합니다.

9. **최대 크기 ngram 사전의**경우 n-영문법 사전에서 만들 수 있는 총 행 수를 입력 합니다.

    이 옵션은 사전의 크기를 제어 하는 데 유용 합니다. 그러나 입력의 ngrams 수가이 크기를 초과 하는 경우 충돌이 발생할 수 있습니다.

10. 파이프라인을 제출합니다. LDA 모듈은 Bayes 정리를 사용 하 여 개별 단어와 연결 될 수 있는 항목을 결정 합니다. 단어는 토픽 또는 그룹과 독점적으로 연결 되지 않습니다. 대신 각 n-영문법에는 검색 된 클래스와 연결 될 확률이 있습니다.

## <a name="results"></a>결과

모듈의 두 출력은 다음과 같습니다.

+ **변환 된 데이터 집합**:이 출력에는 입력 텍스트, 검색 된 항목 수 및 각 범주에 대 한 각 텍스트 예제의 점수가 포함 됩니다.

+ **기능 항목 행렬**: 가장 왼쪽에 있는 열에는 추출 된 텍스트 기능이 포함 되어 있습니다. 각 범주에 대 한 열에는 해당 범주의 해당 기능에 대 한 점수가 포함 됩니다.


### <a name="lda-transformation"></a>LDA 변환

또한이 모듈은 데이터 집합에 LDA를 적용 하는 *LDA 변환을* 출력 합니다.

이 변환을 저장 하 고 다른 데이터 집합에 다시 사용할 수 있습니다. 이 기법은 많은 모음에 대해 학습 하 고 계수 또는 범주를 다시 사용 하려는 경우에 유용할 수 있습니다.

이 변환을 다시 사용 하려면 숨어 있는 Dirichlet 할당 모듈의 오른쪽 패널에서 **데이터 집합 등록** 아이콘을 선택 하 여 모듈 목록에서 해당 모듈을 **데이터 집합** 범주 아래에 보관 합니다. 그런 다음이 모듈을 [변환 적용](apply-transformation.md) 모듈에 연결 하 여이 변환을 다시 사용할 수 있습니다.

### <a name="refining-an-lda-model-or-results"></a>LDA 모델 또는 결과 구체화

일반적으로 모든 요구를 충족 하는 단일 LDA 모델을 만들 수는 없습니다. 한 작업에 대해 디자인 된 모델에도 정확성을 향상 시키기 위해 많은 반복이 필요할 수 있습니다. 이러한 모든 방법을 사용해 모델을 개선 하는 것이 좋습니다.

+ 모델 매개 변수 변경
+ 시각화를 사용 하 여 결과 이해
+ 실무 전문가의 의견을 받아 생성 된 항목이 유용한 지 여부 결정

질적 측정은 결과를 평가 하는 데 유용할 수도 있습니다. 항목 모델링 결과를 평가 하려면 다음을 고려 하십시오.

+ 정확도. 유사한 항목이 정말 유사 합니까?
+ 분포도. 비즈니스 문제에 대해 필요한 경우 모델이 유사한 항목 사이에서 판별 수 있나요?
+ 확장성 넓은 범위의 텍스트 범주 또는 좁은 대상 도메인 에서만 작동 하나요?

자연 언어 처리를 사용 하 여 텍스트를 정리, 요약 및 단순화 하거나 범주화 하 여 LDA를 기반으로 하는 모델의 정확도를 향상 시킬 수 있습니다. 예를 들어 Azure Machine Learning에서 모두 지원 되는 다음 기술은 분류 정확도를 향상 시킬 수 있습니다.

+ 중지 단어 제거

+ 대/소문자 정규화

+ 분류 정리 또는 형태소 분석

+ 명명된 엔터티 인식

자세한 내용은 [전처리 텍스트](preprocess-text.md)를 참조 하세요.

디자이너에서 텍스트 처리에 r 또는 Python 라이브러리를 사용할 수도 있습니다. [r 스크립트 실행](execute-r-script.md), [python 스크립트 실행](execute-python-script.md)을 참조 하세요.



## <a name="technical-notes"></a>기술 정보

이 섹션에는 구현 세부 정보, 팁 및 질문과 대답 (faq)이 포함 되어 있습니다.

### <a name="implementation-details"></a>구현 세부 정보

기본적으로 변환 된 데이터 집합 및 기능-토픽 행렬에 대 한 출력의 분포는 확률로 정규화 됩니다.

+ 변환 된 데이터 집합은 문서가 지정 된 항목의 조건부 확률로 정규화 됩니다. 이 경우 각 행의 합계는 1과 같습니다.

+ 토픽 행렬은 토픽에 지정 된 단어의 조건부 확률로 정규화 됩니다. 이 경우 각 열의 합계는 1과 같습니다.

> [!TIP]
> 경우에 따라 모듈이 빈 항목을 반환할 수도 있습니다. 가장 자주 발생 하는 원인은 알고리즘의 의사 난수 초기화입니다. 이 경우 관련 매개 변수를 변경 해 볼 수 있습니다. 예를 들어 N-영문법 사전의 최대 크기 또는 기능 해시에 사용할 비트 수를 변경 합니다.

### <a name="lda-and-topic-modeling"></a>LDA 및 토픽 모델링

숨겨진 Dirichlet 할당은 일반적으로 미분류 텍스트에서 범주를 학습 하는 것을 의미 하는 *내용 기반 토픽 모델링*에 사용 됩니다. 내용 기반 토픽 모델링에서 토픽은 단어에 대 한 분포입니다.

예를 들어 여러 제품을 포함 하는 고객 리뷰 모음을 제공 했다고 가정 합니다. 시간이 지남에 따라 고객이 제출한 리뷰의 텍스트에는 여러 용어가 포함 되어 있으며,이 중 일부는 여러 항목에서 사용 됩니다.

LDA 프로세스에서 식별 하는 *토픽* 은 개별 제품에 대 한 검토를 나타내거나 제품 검토 그룹을 나타낼 수 있습니다. 항목 자체는 단어 집합에 대 한 시간에 따른 확률 분포만 LDA 합니다.

용어는 어떤 제품에만 국한 되지 않습니다. 다른 제품을 참조 하거나 모든 항목에 적용 되는 일반 용어 ("멋진", "바람직하지 않음") 일 수 있습니다. 다른 용어는 의미 없는 단어 일 수 있습니다. 그러나 LDA 메서드는 공동 발생의 확률을 제외 하 고 universe의 모든 단어를 캡처하지 않거나 단어 간의 관계를 파악 하지 않습니다. 대상 도메인에서 사용 되는 단어만 그룹화 할 수 있습니다.

인덱스를 계산한 후에는 거리 기반 유사성 측정값이 텍스트의 개별 행을 비교 하 여 두 텍스트 조각이 유사한 지 여부를 확인 합니다. 예를 들어 제품에 강력한 상관 관계가 지정 된 여러 이름이 있는 것을 확인할 수 있습니다. 또는 강력한 부정적 용어를 일반적으로 특정 제품과 연결 하는 것을 알 수 있습니다. 유사성 측정값을 사용 하 여 관련 용어를 식별 하 고 권장 구성을 만들 수 있습니다.

###  <a name="module-parameters"></a>모듈 매개 변수

|이름|Type|범위|선택 사항|기본값|Description|  
|----------|----------|-----------|--------------|-------------|-----------------|  
|대상 열|열 선택||필요한 공간|StringFeature|대상 열 이름 또는 인덱스입니다.|  
|모델링할 토픽 수|정수|[1, 1000]|필요한 공간|5|N 개 항목에 대 한 문서 분포를 모델링 합니다.|  
|N그램|정수|[1, 10]|필요한 공간|2|해시 중에 생성 된 N 그램의 순서입니다.|  
|일반화|부울|True 또는 False|필요한 공간|true|출력을 확률로 정규화 합니다.  변환 된 데이터 집합은 P (토픽&#124;문서)이 되 고 기능 토픽 행렬은 P (word&#124;토픽)가 됩니다.|  
|모든 옵션 표시|부울|True 또는 False|필요한 공간|False|Scikit에 고유한 추가 매개 변수를 제공 합니다 (온라인 학습 LDA).|  
|가는 매개 변수|Float|[0.00001; 1.0]|[ **모든 옵션 표시** ] 확인란이 선택 된 경우 적용 됩니다.|0.01|항목의 이전 배포 항목입니다.|  
|알파 매개 변수|Float|[0.00001; 1.0]|[ **모든 옵션 표시** ] 확인란이 선택 된 경우 적용 됩니다.|0.01|문서 항목 이전 배포.|  
|예상 문서 수|정수|[1;int.MaxValue]|[ **모든 옵션 표시** ] 확인란이 선택 된 경우 적용 됩니다.|1000|예상 문서 수입니다. `total_samples`매개 변수에 해당 합니다.|  
|일괄 처리 크기|정수|[1, 1024]|[ **모든 옵션 표시** ] 확인란이 선택 된 경우 적용 됩니다.|32|일괄 처리의 크기입니다.|  
|학습 빈도 업데이트 일정에 사용 되는 반복의 초기 값|정수|[0; int. Int32.maxvalue|[ **모든 옵션 표시** ] 확인란이 선택 된 경우 적용 됩니다.|0|초기 반복의 학습 률을 가중치 하는 초기 값입니다. `learning_offset`매개 변수에 해당 합니다.|  
|업데이트 중에 반복에 적용 되는 전원|Float|[0.0; 1.0]|[ **모든 옵션 표시** ] 확인란이 선택 된 경우 적용 됩니다.|0.5|학습 률을 제어 하기 위해 반복 횟수에 적용 되는 전원입니다. `learning_decay`매개 변수에 해당 합니다. |  
|학습 반복 횟수|정수|[1, 1024]|[ **모든 옵션 표시** ] 확인란이 선택 된 경우 적용 됩니다.|25|학습 반복 횟수입니다.|  
|Ngrams의 빌드 사전|부울|True 또는 False|[ **모든 옵션 표시** ] 확인란이 선택 *되지 않은* 경우에 적용 됩니다.|True|LDA을 계산 하기 전에 ngrams 사전을 작성 합니다. 모델 검사 및 해석에 유용 합니다.|  
|Ngram 사전의 최대 크기|정수|[1;int.MaxValue]|**Ngrams의 빌드 사전 사전이** **True** 인 경우에 적용 됩니다.|20000|Ngrams 사전의 최대 크기입니다. 입력의 토큰 수가이 크기를 초과 하면 충돌이 발생할 수 있습니다.|  
|기능 해시에 사용할 비트 수입니다.|정수|[1, 31]|**모든 옵션 표시** 확인란을 선택 *하지 않은* 경우 적용 되 고 **Ngrams의 빌드 사전이** **False** 인 경우 적용 됩니다.|12|기능 해시에 사용할 비트 수입니다.| 
|LDA 전에 ngrams의 사전 빌드|부울|True 또는 False|[ **모든 옵션 표시** ] 확인란이 선택 된 경우 적용 됩니다.|True|LDA 전에 ngrams 사전을 빌드합니다. 모델 검사 및 해석에 유용 합니다.|  
|사전에 있는 최대 n 그램 수|정수|[1;int.MaxValue]|**모든 옵션 표시** 확인란을 선택 하 고 **Ngrams의 빌드 사전** 옵션을 **True로 설정** 하는 경우에 적용 됩니다.|20000|사전의 최대 크기입니다. 입력의 토큰 수가이 크기를 초과 하면 충돌이 발생할 수 있습니다.|  
|해시 비트 수|정수|[1, 31]|**모든 옵션 표시** 확인란이 선택 되어 있고 **Ngrams의 빌드 사전** 옵션이 **False** 인 경우에 적용 됩니다.|12|기능 해시 중에 사용할 비트 수입니다.|   


## <a name="next-steps"></a>다음 단계

Azure Machine Learning에서 [사용 가능한 모듈 세트](module-reference.md)를 참조하세요. 

모듈과 관련 된 오류 목록은 [디자이너의 예외 및 오류 코드](designer-error-codes.md)를 참조 하세요.
