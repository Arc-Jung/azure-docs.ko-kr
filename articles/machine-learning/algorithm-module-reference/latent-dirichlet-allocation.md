---
title: 잠재 디리클렛 할당
titleSuffix: Azure Machine Learning
description: 잠재 Dirichlet 할당 모듈을 사용하여 분류되지 않은 텍스트를 여러 범주로 그룹화하는 방법을 알아봅니다.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: likebupt
ms.author: keli19
ms.date: 03/11/2020
ms.openlocfilehash: 1384491489c175ffc338f80a99aa8d5050f835d5
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/28/2020
ms.locfileid: "80109226"
---
# <a name="latent-dirichlet-allocation"></a>잠재 디리클렛 할당

이 문서에서는 Azure 기계 학습 디자이너(미리 보기)에서 **잠재 Dirichlet 할당** 모듈을 사용하여 분류되지 않은 텍스트를 여러 범주로 그룹화하는 방법을 설명합니다. 

LDA(잠복 Dirichlet 할당)는 종종 NLP(자연어 처리)에서 유사한 텍스트를 찾는 데 사용됩니다. 또 다른 일반적인 용어는 *토픽 모델링입니다.*

이 모듈은 텍스트 열을 가져와 다음 출력을 생성합니다.

+ 각 범주에 대한 점수와 함께 소스 텍스트

+ 각 범주에 대해 추출된 용어 및 계수를 포함하는 피쳐 매트릭스

+ 입력으로 사용되는 새 텍스트에 저장하고 다시 적용할 수 있는 변환

이 모듈에서는 사이킷 학습 라이브러리를 사용합니다. scikit-learn에 대한 자세한 내용은 자습서 및 알고리즘 설명이 포함된 [GitHub 리포지토리]를 참조하십시오.

### <a name="more-about-latent-dirichlet-allocation-lda"></a>한눈에 보는 잠재 디리클렛 할당 (LDA)

일반적으로 LDA는 그당 분류하는 방법이 아니지만 생성 적 접근 방식을 사용합니다. 즉, 알려진 클래스 레이블을 제공한 다음 패턴을 유추할 필요가 없습니다.  대신 알고리즘은 주제 그룹을 식별하는 데 사용되는 확률 모델을 생성합니다. 확률 모델을 사용하여 기존 교육 사례 또는 모델에 제공하는 새 사례를 입력으로 분류할 수 있습니다.

생성 모델은 텍스트와 범주 간의 관계에 대해 강력한 가정을 하지 않도록 하고 주제의 텍스트 를 모델링하기 위해 단어 의 분포만 사용하기 때문에 바람직할 수 있습니다.

+ 이론은 이 문서에서 설명, PDF 다운로드로 사용할 수: [잠재 Dirichlet 할당: Blei, Ng, 그리고 요르단](https://ai.stanford.edu/~ang/papers/nips01-lda.pdf)

+ 이 모듈의 구현은 LDA에 대한 [scikit 학습 라이브러리를](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/decomposition/_lda.py) 기반으로 합니다.

자세한 내용은 기술 [노트](#technical-notes) 섹션을 참조하십시오.

## <a name="how-to-configure-latent-dirichlet-allocation"></a>잠재 디리클렛 할당을 구성하는 방법

이 모듈에는 원시 또는 사전 처리된 텍스트 열이 포함된 데이터 집합이 필요합니다.

1. **파이프라인에 잠재 디리클렛 할당** 모듈을 추가합니다.

2. 모듈에 대한 입력으로 하나 이상의 텍스트 열이 포함된 데이터 집합을 제공합니다.

3. **대상 열의**경우 분석할 텍스트가 포함된 열 중 하나를 선택합니다.

    여러 열을 선택할 수 있지만 문자열 데이터 형식이어야 합니다.

    일반적으로 LDA는 텍스트에서 큰 피쳐 행렬을 생성하므로 일반적으로 단일 텍스트 열을 분석합니다.

4. **모델링할 토픽 수의**경우 입력 텍스트에서 파생할 범주 또는 토픽 수를 나타내는 1에서 1000 사이의 정수를 입력합니다.

    기본적으로 5개의 주제가 만들어집니다.

5. **N-그램의**경우 해싱 중에 생성된 N그램의 최대 길이를 지정합니다.

    기본값은 2이므로 큰 램과 유니그램이 모두 생성됩니다.

6. 출력 값을 확률로 변환하는 **정규화** 옵션을 선택합니다. 따라서 변환된 값을 정수로 나타내는 대신 출력 및 피쳐 데이터 집합의 값은 다음과 같이 변환됩니다.

    + 데이터 집합의 값은 `P(topic|document)`.

    + 피처 토픽 매트릭스의 값은 `P(word|topic)`.

    > [!NOTE] 
    > Azure Machine Learning 디자이너(미리 보기)에서 sitkit-learn을 기반으로 하는 라이브러리는 버전 0.19에서 비정규화된 *doc_topic_distr* 출력을 더 이상 지원하지 않으므로 이 모듈에서는 **정규화** 매개 변수를 **기능 주제 매트릭스** 출력에만 적용할 수 있으므로 **변환된 데이터 집합** 출력은 항상 정규화됩니다.

7. 옵션을 선택하고 **모든 옵션 표시를**선택한 다음 보고 싶은 경우 TRUE로 설정한 다음 추가 고급 매개 변수를 설정합니다.

    이러한 매개 변수는 LDA의 scikit-learn 구현에 만연합니다. SCIKIT-learn에 LDA에 대한 몇 가지 좋은 튜토리얼뿐만 아니라 공식 [scikit-learn 문서가](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html)있습니다.

    + **Rho 매개 변수**. 토픽 분포의 희소성에 대한 사전 확률을 제공합니다. sklearn의 `topic_word_prior` 매개 변수에 해당합니다. 단어 분포가 평평하다고 예상되는 경우 값 1을 사용합니다. 즉, 모든 단어는 동등하다고 가정합니다. 대부분의 단어가 드물게 표시되면 훨씬 낮은 값으로 설정할 수 있습니다.

    + **알파 매개 변수**. 문서별 토픽 가중치의 희소성에 대한 이전 확률을 지정합니다.  sklearn의 `doc_topic_prior` 매개 변수에 해당합니다.

    + **예상 문서 수입니다.** 처리될 문서 수(행)의 가장 좋은 추정치를 나타내는 숫자를 입력합니다. 이렇게 하면 모듈에서 충분한 크기의 해시 테이블을 할당할 수 있습니다.  scikit-learn의 `total_samples` 매개 변수에 해당합니다.

    + **일괄 처리의 크기**. LDA 모델로 전송된 각 텍스트 배치에 포함할 행 수를 나타내는 숫자를 입력합니다. scikit-learn의 `batch_size` 매개 변수에 해당합니다.

    + **학습 업데이트 일정에 사용되는 반복의 초기 값입니다.** 온라인 학습에서 초기 반복에 대한 학습 속도를 낮추는 시작 값을 지정합니다. scikit-learn의 `learning_offset` 매개 변수에 해당합니다.

    + **업데이트 중에 반복에 적용된 전원**입니다. 온라인 업데이트 중 학습 률을 제어하기 위해 반복 개수에 적용되는 전력 수준을 나타냅니다. scikit-learn의 `learning_decay` 매개 변수에 해당합니다.

    + **데이터를 통과하는 횟수입니다.** 알고리즘이 데이터를 순환할 최대 횟수를 지정합니다. scikit-learn의 `max_iter` 매개 변수에 해당합니다.

8. 텍스트를 분류하기 **Build dictionary of ngrams** 전에 초기 패스에서 n-gram 목록을 만들려면 옵션을 선택합니다. **Build dictionary of ngrams prior to LDA**

    미리 초기 사전을 만드는 경우 나중에 모델을 검토할 때 사전을 사용할 수 있습니다. 수치 인덱스가 아닌 텍스트에 결과를 매핑할 수 있다는 것은 일반적으로 해석하기 쉽습니다. 그러나 사전을 저장하는 데 시간이 오래 걸리고 추가 저장소를 사용합니다.

9. **ngram 사전의 최대 크기의**경우 n-gram 사전에서 만들 수 있는 총 행 수를 입력합니다.

    이 옵션은 사전의 크기를 제어하는 데 유용합니다. 그러나 입력의 n그램 수가 이 크기를 초과하면 충돌이 발생할 수 있습니다.

10. 파이프라인을 제출합니다. LDA 모듈은 베이즈 정리를 사용하여 개별 단어와 연관될 수 있는 주제를 결정합니다. 단어는 주제 나 그룹과 독점적으로 연관되지 않습니다. 대신, 각 n-gram은 검색된 클래스와 연결될 확률을 가지고 있습니다.

## <a name="results"></a>결과

모듈의 두 출력은 다음과 같습니다.

+ **변환된 데이터 집합**: 각 범주에 대한 각 텍스트 예제의 점수와 함께 입력 텍스트 및 지정된 수의 검색된 범주를 포함합니다.

+ **특징 주제 매트릭스**: 가장 왼쪽 열에는 추출된 텍스트 피처가 포함되어 있으며 해당 범주에서 해당 피처의 점수가 포함된 각 범주에 대한 열이 있습니다.


### <a name="lda-transformation"></a>LDA 변환

또한 이 모듈은 데이터 집합에 *LDA를* 적용하는 LDA 변환을 출력합니다.

이 변환은 Module의 오른쪽 창에 **있는 Outputs+logs** 탭 아래에 데이터 집합을 등록하여 저장하고 다른 데이터 집합에 다시 사용할 수 있습니다. 이 기능은 큰 코퍼스에 대해 학습하고 계수 또는 범주를 다시 사용하려는 경우에 유용할 수 있습니다.

### <a name="refining-an-lda-model-or-results"></a>LDA 모델 또는 결과 구체화

일반적으로 모든 요구 사항을 충족하는 단일 LDA 모델을 만들 수 없으며 한 작업에 대해 설계된 모델도 정확도를 높이기 위해 많은 반복이 필요할 수 있습니다. 모델을 개선하기 위해 다음 방법을 모두 시도하는 것이 좋습니다.

+ 모델 매개변수 변경
+ 시각화를 사용하여 결과 이해
+ 생성된 주제가 유용한지 여부를 확인하기 위해 주제 전문가의 피드백을 받습니다.

정성적 측정은 결과를 평가하는 데에도 유용할 수 있습니다. 토픽 모델링 결과를 평가하려면 다음을 고려하십시오.

+ 정확도 - 비슷한 항목이 정말 비슷합니까?
+ 다양성 - 비즈니스 문제에 필요한 경우 모델이 유사한 항목을 구별할 수 있습니까?
+ 확장성 - 광범위한 텍스트 범주에서 작동합니까 아니면 좁은 대상 도메인에서만 작동합니까?

LDA를 기반으로 하는 모델의 정확도는 종종 자연어 처리를 사용하여 텍스트를 정리, 요약 및 단순화하거나 분류하여 향상시킬 수 있습니다. 예를 들어 Azure 기계 학습에서 모두 지원되는 다음 기술은 분류 정확도를 향상시킬 수 있습니다.

+ 중지 단어 제거

+ 대/소문자 정규화

+ 레마화 또는 형태소 분석

+ 명명된 엔터티 인식

자세한 내용은 [텍스트 전처리를](preprocess-text.md)참조하십시오.

디자이너에서 텍스트 처리를 위해 R 또는 파이썬 라이브러리를 사용할 수도 있습니다: [R 스크립트 실행,](execute-r-script.md) [파이썬 스크립트 실행](execute-python-script.md)



## <a name="technical-notes"></a>기술 정보

이 섹션에는 자주 묻는 질문에 대한 구현 세부 정보, 팁 및 답변이 포함되어 있습니다.

### <a name="implementation-details"></a>구현 세부 정보

기본적으로 변환된 데이터 집합 및 피처 토픽 행렬에 대한 출력 분포는 확률로 정규화됩니다.

+ 변환된 데이터 집합은 문서에 지정된 토픽의 조건부 확률로 정규화됩니다. 이 경우 각 행의 합계는 1입니다.

+ 피처 토픽 매트릭스는 토픽을 받은 단어의 조건부 확률로 정규화됩니다. 이 경우 각 열의 합은 1입니다.

> [!TIP]
> 경우에 따라 모듈은 알고리즘의 의사 무작위 초기화로 인해 발생하는 빈 토픽을 반환할 수 있습니다.  이 경우 N-gram 사전의 최대 크기 또는 기능 해싱에 사용할 비트 수와 같은 관련 매개 변수를 변경할 수 있습니다.

### <a name="lda-and-topic-modeling"></a>LDA 및 토픽 모델링

LDA(잠재 디리클렛 할당)는 기본적으로 분류되지 않은 텍스트에서 범주를 학습하는 것을 의미하는 *콘텐츠 기반 토픽 모델링에*자주 사용됩니다. 콘텐츠 기반 토픽 모델링에서 토픽은 단어에 대한 분포입니다.

예를 들어 많은 제품이 포함된 고객 리뷰 모음을 제공했다고 가정합니다. 시간이 지남에 따라 많은 고객이 제출 한 리뷰의 텍스트는 많은 용어를 포함하고, 그 중 일부는 여러 주제에 사용됩니다.

LDA 프로세스에서 식별되는 **주제는** 개별 제품 A에 대한 리뷰를 나타내거나 제품 리뷰 그룹을 나타낼 수 있습니다. LDA에게 주제 자체는 단어 집합에 대한 시간 지남에 따라 확률 분포일 뿐입니다.

조건은 한 제품에 만연한 경우는 드물지만 다른 제품을 참조하거나 모든 제품에 적용되는 일반적인 용어일 수 있습니다("great", "awful"). 다른 용어는 노이즈 단어일 수 있습니다.  그러나 LDA 메서드는 우주의 모든 단어를 캡처하거나 단어가 공존 확률을 제외하고 어떻게 관련되어 있는지 이해하려는 의도가 아니라는 것을 이해하는 것이 중요합니다. 대상 도메인에 사용된 단어만 그룹화할 수 있습니다.

인덱스라는 용어를 계산한 후 거리 기반 유사성 측정값을 사용하여 개별 텍스트 행을 비교하여 두 텍스트가 서로 같은지 여부를 확인합니다.  예를 들어 제품에 강력한 상관 관계가 있는 여러 이름이 있을 수 있습니다. 또는, 당신은 강하게 부정적인 용어는 일반적으로 특정 제품과 연결되어 있음을 발견 할 수 있습니다. 유사성 측정값을 사용하여 관련 용어를 식별하고 권장 사항을 만들 수 있습니다.

###  <a name="module-parameters"></a>모듈 매개 변수

|이름|Type|범위|Optional|기본값|설명|  
|----------|----------|-----------|--------------|-------------|-----------------|  
|대상 열|열 선택||필수|StringFeature|대상 열 이름 또는 인덱스|  
|모델링할 주제 수|정수|[1;1000]|필수|5|N 항목에 대한 문서 배포 모델링|  
|N그램|정수|[1;10]|필수|2|해싱 중에 생성된 N그램 순서|  
|정규화|부울|True 또는 False|필수|true|출력을 확률로 정규화합니다.  변환된 데이터 집합은 P(주제&#124;문서)이고 기능 주제 행렬은 P(단어&#124;항목)이 됩니다.|  
|모든 옵션 표시|부울|True 또는 False|필수|False|scikit 학습 온라인 LDA에 특정 추가 매개 변수를 제공합니다|  
|Rho 매개 변수|Float|[0.00001;1.0]|**모든 옵션 표시** 확인란을 선택한 경우에 적용됩니다.|0.01|주제 단어 사전 배포|  
|알파 매개 변수|Float|[0.00001;1.0]|**모든 옵션 표시** 확인란을 선택한 경우에 적용됩니다.|0.01|문서 주제 사전 배포|  
|예상 문서 수|정수|[1;int.MaxValue]|**모든 옵션 표시** 확인란을 선택한 경우에 적용됩니다.|1000|예상 문서 수(total_samples 매개 변수에 해당)|  
|일괄 처리 의 크기|정수|[1;1024]|**모든 옵션 표시** 확인란을 선택한 경우에 적용됩니다.|32|일괄 처리 의 크기|  
|학습 속도 업데이트 일정에 사용되는 반복의 초기 값|정수|[0;int. 최대값]|**모든 옵션 표시** 확인란을 선택한 경우에 적용됩니다.|0|초기 반복에 대한 학습 속도를 낮추는 초기 값입니다. learning_offset 매개 변수에 해당|  
|업데이트 중 반복에 적용된 전원|Float|[0.0;1.0]|**모든 옵션 표시** 확인란을 선택한 경우에 적용됩니다.|0.5|학습 속도를 제어하기 위해 반복 카운트에 적용된 전원입니다. learning_decay 매개 변수에 해당 |  
|학습 반복 횟수|정수|[1;1024]|**모든 옵션 표시** 확인란을 선택한 경우에 적용됩니다.|25|학습 반복 횟수|  
|ngrams의 사전 을 구축|부울|True 또는 False|**모든 옵션 표시** 확인란을 *선택하지 않은* 경우 적용됩니다.|True|LDA를 계산하기 전에 ngrams 사전을 작성합니다. 모델 검사 및 해석에 유용합니다.|  
|ngram 사전의 최대 크기|정수|[1;int.MaxValue]|**ngrams의 빌드 사전이** True인 경우에 적용됩니다.|20000|ngrams 사전의 최대 크기입니다. 입력의 토큰 수가 이 크기를 초과하면 충돌이 발생할 수 있습니다.|  
|피쳐 해싱에 사용할 비트 수|정수|[1;31]|**모든 옵션 표시** 확인란이 *선택되지 않고* **ngrams의 빌드 사전이** False인 경우에 적용됩니다.|12|피쳐 해싱에 사용할 비트 수| 
|LDA 이전에 ngrams의 사전 을 구축|부울|True 또는 False|**모든 옵션 표시** 확인란을 선택한 경우에 적용됩니다.|True|LDA 이전에 ngrams 사전을 빌드합니다. 모델 검사 및 해석에 유용합니다.|  
|사전에서 ngrams의 최대 수|정수|[1;int.MaxValue]|**모든 옵션 표시** 확인란을 선택하고 **ngrams의 빌드 사전이** True인 경우에 적용됩니다.|20000|사전의 최대 크기입니다. 입력의 토큰 수가 이 크기를 초과하면 충돌이 발생할 수 있습니다.|  
|해시 비트 수|정수|[1;31]|**모든 옵션 표시** 확인란을 선택하고 **ngrams의 빌드 사전이** False인 경우에 적용됩니다.|12|피쳐 해싱 중에 사용할 비트 수|   


## <a name="next-steps"></a>다음 단계

Azure 기계 학습에 사용할 수 있는 [모듈 집합을](module-reference.md) 참조하십시오.   
모듈과 관련된 오류 목록은 [디자이너의 예외 및 오류 코드를](designer-error-codes.md)참조하십시오.
