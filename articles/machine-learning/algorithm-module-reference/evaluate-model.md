---
title: '모델 평가: 모듈 참조'
titleSuffix: Azure Machine Learning
description: Azure Machine Learning에서 모델 평가 모듈을 사용 하 여 학습 된 모델의 정확도를 측정 하는 방법에 대해 알아봅니다.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: likebupt
ms.author: keli19
ms.date: 04/24/2020
ms.openlocfilehash: cf9597f4a722ff9cda68e87b31db77c989afcb0b
ms.sourcegitcommit: edccc241bc40b8b08f009baf29a5580bf53e220c
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 04/24/2020
ms.locfileid: "82129841"
---
# <a name="evaluate-model-module"></a>모델 평가 모듈

이 문서에서는 Azure Machine Learning designer (미리 보기)의 모듈을 설명 합니다.

이 모듈을 사용 하 여 학습 된 모델의 정확도를 측정 합니다. 모델에서 생성 된 점수가 포함 된 데이터 집합을 제공 하 고 **모델 평가** 모듈은 산업 표준 평가 메트릭 집합을 계산 합니다.
  
 **평가 모델** 에서 반환 되는 메트릭은 평가 하는 모델 유형에 따라 달라 집니다.  
  
-   **분류 모델**    
-   **회귀 모델**  
-   **클러스터링 모델**  


> [!TIP]
> 모델 평가를 처음 접하는 경우 EdX에서 [기계 학습 과정](https://blogs.technet.microsoft.com/machinelearning/2015/09/08/new-edx-course-data-science-machine-learning-essentials/) 의 일부로 Stephen Elston에 의해 비디오 시리즈를 권장 합니다. 


## <a name="how-to-use-evaluate-model"></a>모델 평가를 사용 하는 방법
1. [점수 모델](./score-model.md) 의 **점수가 매겨진 데이터 집합** 출력을 **모델 평가**의 왼쪽 입력 포트에 연결 합니다. 

2. 필드 두 번째 모델에 대 한 [점수 매기기 모델](./score-model.md) 의 **점수가 매겨진 데이터 집합** 출력을 **모델 평가**의 **오른쪽** 입력에 연결 합니다. 동일한 데이터에서 서로 다른 두 모델의 결과를 쉽게 비교할 수 있습니다. 두 입력 알고리즘은 동일한 알고리즘 형식 이어야 합니다. 또는 서로 다른 매개 변수를 사용하여 동일한 데이터에 대해 수행한 두 번의 실행 결과 생성된 점수를 비교할 수 있습니다.

    > [!NOTE]
    > 알고리즘 형식이 ' Machine Learning 알고리즘 '의 ' 2 클래스 분류 ', ' 다중 클래스 분류 ', ' 회귀 ', ' 클러스터링 '을 참조 합니다. 

3. 파이프라인을 제출 하 여 평가 점수를 생성 합니다.

## <a name="results"></a>결과

**모델 평가**를 실행 한 후 모듈을 마우스 오른쪽 단추로 클릭 하 고 **평가 결과 시각화** 를 선택 하 여 결과를 확인 합니다.

**모델 평가**의 두 입력에 데이터 집합을 연결 하는 경우 결과에는 두 데이터 집합 또는 두 모델 모두에 대 한 메트릭이 포함 됩니다.
왼쪽 포트에 연결 된 모델이 나 데이터가 먼저 보고서에 표시 된 다음 데이터 집합에 대 한 메트릭 또는 올바른 포트에 연결 된 모델이 표시 됩니다.  

예를 들어 다음 이미지는 동일한 데이터를 기반으로 하지만 다른 매개 변수를 사용 하는 두 클러스터링 모델의 결과 비교를 나타냅니다.  

![Comparing2Models](media/module/evaluate-2-models.png)  

이는 클러스터링 모델 이므로 평가 결과는 두 회귀 모델의 점수를 비교 하거나 두 개의 분류 모델을 비교 하는 경우와 다릅니다. 그러나 전체 프레젠테이션은 동일 합니다. 

## <a name="metrics"></a>메트릭

이 섹션에서는 **모델 평가**에서 사용 하도록 지원 되는 특정 유형의 모델에 대해 반환 되는 메트릭에 대해 설명 합니다.

+ [분류 모델](#metrics-for-classification-models)
+ [회귀 모델](#metrics-for-regression-models)
+ [클러스터링 모델](#metrics-for-clustering-models)

### <a name="metrics-for-classification-models"></a>분류 모델에 대 한 메트릭

분류 모델을 평가할 때 다음과 같은 메트릭이 보고 됩니다.
  
-   **정확도** 는 전체 사례에 대 한 실제 결과의 비율로 분류 모델의 적합도를 측정 합니다.  
  
-   **전체 자릿수** 는 모든 긍정 결과에 대 한 실제 결과의 비율입니다.  
  
-   **회수** 는 모델에서 반환 하는 모든 올바른 결과의 비율입니다.  
  
-   **F-점수** 는 전체 자릿수의 가중치가 적용 된 평균으로 계산 되며, 0과 1 사이의 값이 가장 좋습니다. 여기서 이상적인 F 점수 값은 1입니다.  
  
-   **Cc** 는 y 축에서 진정한 긍정을 사용 하 여 그린 곡선 아래의 면적을 측정 하 고 x 축에는 가양성을 측정 합니다. 이 메트릭은 여러 유형의 모델을 비교할 수 있는 단일 숫자를 제공 하기 때문에 유용 합니다.  
  
- **평균 로그 손실은** 잘못 된 결과에 대 한 패널티를 표현 하는 데 사용 되는 단일 점수입니다. 두 확률 분포 (true)와 모델에 있는 분포의 차이로 계산 됩니다.  
  
- **학습 로그 손실은** 임의 예측을 통해 분류자의 장점을 나타내는 단일 점수입니다. 로그 손실은 출력의 확률을 레이블의 알려진 값 (그라운드 참)과 비교 하 여 모델의 불확실성을 측정 합니다. 전체적으로 모델에 대 한 로그 손실을 최소화 하려고 합니다.

### <a name="metrics-for-regression-models"></a>회귀 모델에 대 한 메트릭
 
회귀 모델에 대해 반환 되는 메트릭은 오류 양을 예측 하도록 디자인 되었습니다.  관찰 된 값과 예측 값의 차이가 적으면 모델은 데이터 웰에 맞게 고려 됩니다. 그러나 잔차의 패턴을 살펴보면 (한 예측 지점과 해당 하는 실제 값 간의 차이) 모델의 잠재적 바이어스에 대해 많은 정보를 확인할 수 있습니다.  
  
 회귀 모델 평가에 대해 다음과 같은 메트릭이 보고 됩니다.
  
- **MAE (절대 평균 오차)** 는 실제 결과에 대 한 예측의 종료 방법을 측정 합니다. 따라서 점수가 낮을수록 좋습니다.  
  
- **RMSE (제곱 평균 제곱 오차)** 는 모델에서 오류를 요약 하는 단일 값을 만듭니다. 메트릭은 차이를 제곱 하 여 오버 예측과 예측에서의 차이를 무시 합니다.  
  
- **상대 절대 오차 (RAE)** 는 예상 값과 실제 값의 상대적 절대 차이입니다. 평균 차이는 산술 평균으로 나뉩니다.  
  
- **RSE (상대 제곱 오차** ) 마찬가지로 실제 값의 총 제곱 오차로 나누어 예측 값의 총 제곱 오차를 표준화 합니다.  
  

  
- 일반적으로 R<sup>2</sup>라고도 하는 **결정 계수**는 모델의 예측 능력을 0에서 1 사이의 값으로 나타냅니다. 0은 모델이 무작위로 사용 됨을 의미 합니다 (아무 것도 설명 하지 않음). 1은 완벽 한 일치를 의미 합니다. 그러나 낮은 값은 완전히 정상이 고 높은 값은 주의 대상이 될 수 있으므로 R<sup>2</sup> 값을 해석 하는 데 주의를 기울여야 합니다.

###  <a name="metrics-for-clustering-models"></a>클러스터링 모델에 대 한 메트릭

클러스터링 모델은 다양 한 측면에서 분류 및 회귀 모델과 크게 다르므로 [모델 평가](evaluate-model.md) 는 클러스터링 모델에 대해 다른 통계 집합을 반환 합니다.  
  
 클러스터링 모델에 대해 반환 되는 통계는 각 클러스터에 할당 된 데이터 요소 수, 클러스터 간의 분리 크기 및 각 클러스터 내에서 데이터 요소가 얼마나 bunched를 나타냅니다.  
  
 클러스터링 모델에 대 한 통계는 전체 데이터 집합에 대해 평균을 계산 하며, 클러스터 당 통계를 포함 하는 추가 행을 포함 합니다.  
  
클러스터링 모델 평가에 대해 다음과 같은 메트릭이 보고 됩니다.
    
-   열에서 **다른 중심과 평균 거리**의 점수는 클러스터의 각 지점이 다른 모든 클러스터의 중심에 얼마나 가까운 지를 나타냅니다.   

-   클러스터에 대 한 **평균 거리**열의 점수는 클러스터에 있는 모든 지점의 거리를 해당 클러스터의 중심로 나타냅니다.  
  
-   **요소 수** 열에는 각 클러스터에 할당 된 데이터 요소 수와 클러스터에 있는 전체 데이터 요소 수가 표시 됩니다.  
  
     클러스터에 할당 된 데이터 요소 수가 사용 가능한 총 데이터 요소 수보다 적으면 데이터 요소를 클러스터에 할당할 수 없음을 의미 합니다.  
  
-   **클러스터 센터에 대 한 최대 거리**열의 점수는 각 지점과 해당 지점의 클러스터 중심 사이의 거리 합계를 나타냅니다.  
  
     이 수가 높으면 클러스터가 널리 분산 된 것일 수 있습니다. 클러스터의 확산을 확인 하려면 **클러스터 센터의 평균 거리** 와 함께이 통계를 검토 해야 합니다.   

-   결과의 각 섹션 아래쪽에 있는 **평가** 점수는 해당 특정 모델에서 만든 클러스터에 대 한 평균 점수를 나열 합니다.  
  

## <a name="next-steps"></a>다음 단계

Azure Machine Learning [사용할 수 있는 모듈 집합](module-reference.md) 을 참조 하세요. 