---
title: '모델 평가: 모듈 참조'
titleSuffix: Azure Machine Learning
description: Azure 기계 학습에서 모델 평가 모듈을 사용하여 학습된 모델의 정확도를 측정하는 방법을 알아봅니다.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: likebupt
ms.author: keli19
ms.date: 02/24/2020
ms.openlocfilehash: c1bcbb6a368c9c80f968c48c1a6e0bc6c95133d6
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/28/2020
ms.locfileid: "79456407"
---
# <a name="evaluate-model-module"></a>모델 모듈 평가

이 문서에서는 Azure 기계 학습 디자이너(미리 보기)의 모듈에 대해 설명합니다.

이 모듈을 사용하여 학습된 모델의 정확도를 측정합니다. 모델에서 생성된 점수를 포함하는 데이터 집합을 제공하고 **모델 평가** 모듈은 산업 표준 평가 메트릭 집합을 계산합니다.
  
 **모델 평가에서** 반환되는 메트릭은 평가중인 모델 유형에 따라 다릅니다.  
  
-   **분류 모델**    
-   **회귀 모델**  
-   **클러스터링 모델**  


> [!TIP]
> 모델 평가를 새로 접하는 경우 EdX의 [기계 학습 과정의](https://blogs.technet.microsoft.com/machinelearning/2015/09/08/new-edx-course-data-science-machine-learning-essentials/) 일부로 스티븐 엘스턴 박사의 비디오 시리즈를 추천합니다. 


**모델 평가** 모듈을 사용하는 방법에는 세 가지가 있습니다.

+ 교육 데이터에 대한 점수를 생성하고 이러한 점수를 기반으로 모델을 평가합니다.
+ 모델에서 점수를 생성하지만 해당 점수를 예약된 테스트 세트의 점수와 비교합니다.
+ 동일한 데이터 집합을 사용하여 서로 다르지만 관련된 두 모델의 점수 비교

## <a name="use-the-training-data"></a>교육 데이터 사용

모델을 평가하려면 입력 열 및 점수 집합이 포함된 데이터 집합에 연결해야 합니다.  사용할 수 있는 다른 데이터가 없는 경우 원래 데이터 집합을 사용할 수 있습니다.

1. [점수 모델의](./score-model.md) **점수가 매겨짐된 데이터 집합** 출력을 모델 **평가**의 입력에 연결합니다. 
2. **모델 평가** 모듈을 클릭하고 파이프라인을 실행하여 평가 점수를 생성합니다.

## <a name="use-testing-data"></a>테스트 데이터 사용

기계 학습의 일반적인 시나리오는 [분할](./split-data.md) 모듈 또는 [파티션 및 샘플](./partition-and-sample.md) 모듈을 사용하여 원본 데이터 집합을 학습 및 테스트 데이터 집합으로 분리하는 것입니다. 

1. [점수 모델의](score-model.md) **점수가 매겨짐된 데이터 집합** 출력을 모델 **평가**의 입력에 연결합니다. 
2. 테스트 데이터가 포함된 데이터 분할 모듈의 출력을 **모델 평가의**오른쪽 입력에 연결합니다.
2. **모델 평가 모듈을** 클릭하고 **선택한 실행을** 선택하여 평가 점수를 생성합니다.

## <a name="compare-scores-from-two-models"></a>두 모델의 점수 비교

두 번째 점수 집합을 **모델 평가에**연결할 수도 있습니다.  점수는 알려진 결과를 가지고 있는 공유 평가 집합이거나 동일한 데이터에 대해 다른 모델의 결과 집합일 수 있습니다.

이 기능은 동일한 데이터에서 서로 다른 두 모델의 결과를 쉽게 비교할 수 있으므로 유용합니다. 또는 서로 다른 매개 변수를 사용하여 동일한 데이터에 대해 수행한 두 번의 실행 결과 생성된 점수를 비교할 수 있습니다.

1. [점수 모델의](score-model.md) **점수가 매겨짐된 데이터 집합** 출력을 모델 **평가**의 입력에 연결합니다. 
2. 두 번째 모델에 대한 점수 모델 모듈의 출력을 **모델 평가의**오른쪽 입력에 연결합니다.
3. 파이프라인을 제출합니다.

## <a name="results"></a>결과

**모델 평가를**실행한 후 모듈을 마우스 오른쪽 단추로 클릭하고 평가 **결과 시각화를** 선택하여 결과를 확인합니다.

데이터 집합을 **모델 평가의**두 입력에 모두 연결하면 결과에 두 데이터 집합 또는 두 모델 모두에 대한 메트릭이 포함됩니다.
왼쪽 포트에 연결된 모델 또는 데이터는 보고서에서 먼저 표시되고 데이터 집합에 대한 메트릭 또는 오른쪽 포트에 연결된 모델이 표시됩니다.  

예를 들어 다음 이미지는 동일한 데이터에 대해 빌드되었지만 매개 변수가 다른 두 클러스터링 모델의 결과를 비교한 것입니다.  

![비교2모델](media/module/evaluate-2-models.png)  

클러스터링 모델이므로 평가 결과는 두 회귀 모델의 점수를 비교하거나 두 분류 모델을 비교한 경우와 다릅니다. 그러나 전체 프레젠테이션은 동일합니다. 

## <a name="metrics"></a>메트릭

이 섹션에서는 **모델 평가에**사용할 때 지원되는 특정 유형의 모델에 대해 반환된 메트릭에 대해 설명합니다.

+ [분류 모델](#metrics-for-classification-models)
+ [회귀 모델](#metrics-for-regression-models)
+ [클러스터링 모델](#metrics-for-clustering-models)

### <a name="metrics-for-classification-models"></a>분류 모델에 대한 메트릭

분류 모델을 평가할 때 다음 메트릭이 보고됩니다.
  
-   **정확도는** 분류 모델의 장점을 실제 결과의 비율로 총 사례에 대한 비율로 측정합니다.  
  
-   **정밀도는** 모든 긍정적인 결과에 대한 진정한 결과의 비율입니다.  
  
-   **회수는** 모델에서 반환하는 모든 올바른 결과의 일부입니다.  
  
-   **F 점수는** 0에서 1 사이의 가중 평균과 0과 1 사이의 리콜로 계산되며 이상적인 F 점수 값은 1입니다.  
  
-   **AUC는** y축에 참 긍정과 x축의 거짓 긍정으로 플롯된 곡선 아래의 영역을 측정합니다. 이 메트릭은 다양한 유형의 모델을 비교할 수 있는 단일 숫자를 제공하기 때문에 유용합니다.  
  
- **평균 로그 손실은** 잘못된 결과에 대한 페널티를 표현하는 데 사용되는 단일 점수입니다. 실제 분포와 모델의 두 확률 분포 간의 차이로 계산됩니다.  
  
- **학습 로그 손실은** 무작위 예측에 대한 분류자의 이점을 나타내는 단일 점수입니다. 로그 손실은 출력하는 확률을 레이블의 알려진 값(접지 진실)과 비교하여 모델의 불확실성을 측정합니다. 모델 전체의 로그 손실을 최소화하려고 합니다.

### <a name="metrics-for-regression-models"></a>회귀 모델에 대한 메트릭
 
회귀 모델에 반환된 메트릭은 오류 의 양을 추정하도록 설계되었습니다.  관찰된 값과 예측값 간의 차이가 작은 경우 모델에 잘 맞는 것으로 간주됩니다. 그러나 잔차 패턴(예측된 점과 해당 실제 값 간의 차이)을 살펴보면 모델의 잠재적 편향에 대해 많은 것을 알 수 있습니다.  
  
 회귀 모델을 평가하기 위해 다음 메트릭이 보고됩니다.
  
- **평균 절대 오차(MAE)는** 예측이 실제 결과에 얼마나 근접하는지 측정합니다. 따라서, 낮은 점수는 더 낫다.  
  
- **RMSE(루트 평균 제곱 오류)는** 모델의 오류를 요약하는 단일 값을 만듭니다. 차이를 제곱하면 메트릭은 초과 예측과 언더 예측 간의 차이를 무시합니다.  
  
- **상대 절대 오차(RAE)는** 예상 값과 실제 값 간의 상대적 절대 차이입니다. 평균 차이는 산술 평균으로 나누기 때문입니다.  
  
- **상대 제곱 오차(RSE)는** 실제 값의 총 제곱 오차로 나누어 예측 된 값의 총 제곱 오차를 마찬가지로 정규화합니다.  
  

  
- <sup>R2라고도</sup>하는 결정 **계수는**모델의 예측 전력을 0과 1 사이의 값으로 나타냅니다. 0은 모델이 임의임을 의미합니다(아무 설명도 없음). 1은 완벽한 착용감을 의미합니다. 그러나 낮은 값은 완전히 정상일 수 있고 높은 값이 의심될 수 있기 때문에<sup>R2</sup> 값을 해석할 때는 주의해야 합니다.

###  <a name="metrics-for-clustering-models"></a>클러스터링 모델에 대한 메트릭

클러스터링 모델은 여러 면에서 분류 및 회귀 모델과 크게 다르기 때문에 [모델 평가는](evaluate-model.md) 클러스터링 모델에 대해 다른 통계 집합을 반환합니다.  
  
 클러스터링 모델에 대해 반환된 통계는 각 클러스터에 할당된 데이터 포인트 수, 클러스터 간 분리 량 및 각 클러스터 내에서 데이터 요소가 얼마나 긴밀하게 묶이는지를 설명합니다.  
  
 클러스터링 모델에 대한 통계는 전체 데이터 집합에 걸쳐 평균화되며 클러스터당 통계가 포함된 추가 행이 있습니다.  
  
클러스터링 모델을 평가하기 위해 다음 메트릭이 보고됩니다.
    
-   열의 점수인 **기타 중심까지의 평균 거리는**평균적으로 클러스터의 각 점이 다른 모든 클러스터의 중심에 얼마나 가까운지를 나타냅니다.   

-   열의 점수인 **클러스터 중심까지의 평균 거리는**클러스터의 중심에 있는 모든 점의 근접성을 나타냅니다.  
  
-   **포인트 수** 열에는 각 클러스터에 할당된 데이터 소수점과 모든 클러스터의 총 전체 데이터 포인트 수가 표시됩니다.  
  
     클러스터에 할당된 데이터 소수점 수가 사용 가능한 총 데이터 소수점 보다 적으면 데이터 포인트를 클러스터에 할당할 수 없음을 의미합니다.  
  
-   열의 점수인 **클러스터 중심까지의 최대 거리는**각 점과 해당 점의 클러스터 중심 사이의 거리의 합을 나타냅니다.  
  
     이 숫자가 높으면 클러스터가 널리 분산되어 있음을 의미할 수 있습니다. 클러스터 중심까지의 평균 **거리와** 함께 이 통계를 검토하여 클러스터의 스프레드를 결정해야 합니다.   

-   결과의 각 섹션 하단에 있는 **결합 평가** 점수에는 해당 특정 모델에서 생성된 클러스터의 평균 점수가 나열됩니다.  
  

## <a name="next-steps"></a>다음 단계

Azure 기계 학습에 사용할 수 있는 [모듈 집합을](module-reference.md) 참조하십시오. 