---
title: Automl을 사용 하 여 과잉 맞춤 & 불균형 있는 데이터 방지
titleSuffix: Azure Machine Learning
description: Azure Machine Learning의 자동화 된 기계 학습 솔루션을 사용 하 여 ML 모델의 일반적인 문제를 식별 하 고 관리 합니다.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: conceptual
ms.reviewer: nibaccam
author: nibaccam
ms.author: nibaccam
ms.date: 04/09/2020
ms.openlocfilehash: 76f920ad6aae68defb567a7a6623d1ffd488af5f
ms.sourcegitcommit: 849bb1729b89d075eed579aa36395bf4d29f3bd9
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 04/28/2020
ms.locfileid: "80874860"
---
# <a name="prevent-overfitting-and-imbalanced-data-with-automated-machine-learning"></a>자동화 된 기계 학습으로 과잉 맞춤 및 불균형 데이터 방지

과도 하 게 분산 된 데이터는 machine learning 모델을 빌드할 때 일반적인 문제입니다. 기본적으로 Azure Machine Learning의 자동화 된 Machine Learning은 이러한 위험을 식별 하 고이를 완화 하는 데 유용한 모범 사례를 구현 하는 데 도움이 되는 차트와 메트릭을 제공 합니다. 

## <a name="identify-over-fitting"></a>과도 한 맞춤 식별

기계 학습의 과도 한 맞춤은 모델이 학습 데이터에 적합 한 경우에 발생 하며,이로 인해 보이지 않는 테스트 데이터를 정확 하 게 예측할 수 없습니다. 즉, 모델은 단순히 학습 데이터의 특정 패턴 및 노이즈를 memorized 실제 데이터에 대 한 예측을 만들기에 충분 하지 않습니다.

다음 학습 된 모델 및 해당 학습 및 테스트 정확도을 고려 합니다.

| 모델 | 학습 정확도 | 테스트 정확도 |
|-------|----------------|---------------|
| A | 99.9% | 95% |
| b | 87% | 87% |
| C | 99.9% | 45% |

모델 **A**를 고려 하 여 보이지 않는 데이터의 테스트 정확도가 학습 정확도 보다 낮으면 모델이 과도 하 게 조정 되는 일반적인 오해 있습니다. 그러나 테스트 정확도는 항상 학습 정확도 보다 작아야 하 고, 과도 하 게 일치 하는 것과 적절 한 일치에 대 한 차이는 *얼마나* 정확 하지 않습니다. 

모델 **a** 와 **B**를 비교할 때 모델 **a** 는 테스트 정확도가 높기 때문에 더 나은 모델입니다. 테스트 정확도가 95%에서 약간 낮은 경우에는 오버 맞춤을 제안 하는 것이 중요 한 차이가 아닙니다. 학습 및 테스트 정확도는 서로 가까이 있으므로 모델 **B** 를 선택 하지 않는 것이 좋습니다.

모델 **C** 는 오버 맞춤의 명확한 사례를 나타냅니다. 학습 정확도는 매우 높고 테스트 정확도는 많지 않습니다. 이러한 구분은 주관적 이지만 문제 및 데이터에 대 한 지식 및 크고 많을는 허용 되는 오류에 대 한 정보를 제공 합니다.

## <a name="prevent-over-fitting"></a>과도 맞춤 방지

황당한 대부분의 경우 학습 중에 표시 되는 기능 값 조합이 항상 대상에 대해 정확히 동일한 출력을 생성 한다고 가정 합니다.

과도 한 맞춤을 방지 하는 가장 좋은 방법은 다음과 같은 ML 모범 사례를 따르는 것입니다.

* 추가 학습 데이터 사용 및 통계 바이어스 제거
* 대상 누출 방지
* 보다 작은 기능 사용
* **정규화 및 하이퍼 매개 변수 최적화**
* **모델 복잡성 제한 사항**
* **교차 유효성 검사**

자동화 된 ML의 컨텍스트에서 위의 처음 세 개 항목은 **구현 하**는 모범 사례입니다. 마지막 3 개의 굵게 표시 된 항목은 오버 맞춤을 방지 하기 위해 기본적으로 자동화 된 ML을 구현 하는 **최선의 방법** 입니다. 자동화 된 ML 이외의 설정에서는 오버 맞춤 모델을 방지 하기 위해 6 가지 모범 사례를 모두 따르는 것이 좋습니다.

### <a name="best-practices-you-implement"></a>구현 모범 사례

**더 많은 데이터** 를 사용 하는 것은 과도 한 맞춤을 방지 하는 가장 간단 하 고 좋은 방법 이며, 추가 된 보너스로 일반적으로 정확도를 높입니다. 더 많은 데이터를 사용 하는 경우 모델이 정확한 패턴을 기억 하는 것이 더 어려워집니다. 더 많은 조건을 수용 하기에 더 유연 하 게 솔루션에 연결 해야 합니다. 또한 학습 데이터에 라이브 예측 데이터에 존재 하지 않는 격리 된 패턴이 포함 되지 않도록 **통계 바이어스**를 인식 하는 것이 중요 합니다. 이 시나리오는 학습 및 테스트 집합 간에 과도 하 게 맞지 않을 수 있기 때문에 해결 하기 어려울 수 있지만 라이브 테스트 데이터와 비교할 때 과도 한 맞춤이 있을 수 있습니다.

대상 누출은 학습/테스트 집합 간에 과도 한 맞춤이 표시 되지 않는 유사한 문제 이며, 대신 예측 시간에 표시 됩니다. 대상 누출은 일반적으로 예측 시간에 포함 되지 않는 데이터에 액세스 하 여 학습 중에 모델 "속이거나" 할 때 발생 합니다. 예를 들어 월요일에 어떤 주가 요금을 예측 하는 것이 문제가 되는 경우에는 목요일의 데이터를 실수로 포함 하는 데이터입니다 .이는 미래를 확인할 수 없기 때문에 모델이 예측 시간에 포함 되지 않습니다. 대상 누출은 쉬운 실수 이지만 문제에 대 한 비정상적으로 높은 정확도로 규정 되는 경우가 많습니다. 주식 가격을 예측 하 고 95% 정확도로 모델을 학습 하는 경우 기능을 대상으로 하는 누출 가능성이 있습니다.

기능을 제거 하면 특정 패턴을 기억 하는 데 너무 많은 필드가 포함 되지 않아 더 유연 하 게 만들 수 있으므로 과도 하 게 맞출 수도 있습니다. Quantitatively을 측정 하는 것은 어려울 수 있지만 기능을 제거 하 고 동일한 정확도를 유지할 수 있는 경우 모델을 더 유연 하 게 만들어 과도 하 게 연결 하는 위험을 줄일 수 있습니다.

### <a name="best-practices-automated-ml-implements"></a>자동화 된 ML 구현 모범 사례

정규화는 복잡 하 고 과도 하 게 조정 된 모델을 penalize 하는 비용 함수를 최소화 하는 프로세스입니다. 정규화 함수에는 여러 가지 형식이 있지만 일반적으로 모델 계수 크기, 분산 및 복잡성을 모두 penalize 합니다. 자동화 된 ML은 오버 맞춤을 제어 하는 다른 모델 하이퍼 매개 변수 설정을 사용 하 여 서로 다른 조합에서 L1 (올가미), L2 (볼록) 및 ElasticNet (L1 및 L2)를 동시에 사용 합니다. 간단히 말해, 자동화 된 ML은 모델의 규정 수준을 변경 하 고 최상의 결과를 선택 합니다.

또한 자동화 된 ML은 과도 한 맞춤을 방지 하기 위해 명시적 모델 복잡성 제한을 구현 합니다. 대부분의 경우이 구현은 개별 트리의 최대 깊이가 제한 되는 의사 결정 트리 또는 포리스트 알고리즘과 포리스트 또는 앙상블 기술에 사용 되는 총 트리 수가 제한 되어 있습니다.

CV (교차 유효성 검사)는 전체 학습 데이터의 여러 하위 집합을 가져오고 각 하위 집합에서 모델을 학습 하는 프로세스입니다. 모델은 "운이 많은" 것이 가능 하 고 한 하위 집합을 사용 하 여 정확도가 매우 우수 하지만 많은 하위 집합을 사용 하는 경우 모델은 매번 이러한 높은 정확도를 얻지 못합니다. CV를 수행할 때 유효성 검사 홀드 아웃 데이터 집합을 제공 하 고, CV 접기 (하위 집합 수)를 지정 하 고, 자동화 된 ML은 모델을 학습 하 고 하이퍼 매개 변수를 조정 하 여 유효성 검사 집합에서 오류를 최소화 합니다 하나의 CV 접기는 과도 하 게 일치 하지만 대부분의 기능을 사용 하면 최종 모델이 과도 하 게 일치 하는 확률을 줄일 수 있습니다. 모델을 한 번 학습 하는 대신 각 *n* 개의 cv 하위 집합에 대해 한 번씩 학습 하기 때문에 CV로 인해 학습 시간이 더 오래 걸릴 수 있으므로 비용이 더 많이 듭니다. 

> [!NOTE]
> 교차 유효성 검사는 기본적으로 사용 되지 않습니다. 자동 ML 설정에서 구성 해야 합니다. 그러나 교차 유효성 검사를 구성 하 고 유효성 검사 데이터 집합을 제공한 후에는 프로세스가 자동으로 수행 됩니다. 참조 항목 

<a name="imbalance"></a>

## <a name="identify-models-with-imbalanced-data"></a>불균형 데이터를 사용 하 여 모델 식별

불균형 데이터는 기계 학습 분류 시나리오에 대 한 데이터에 일반적으로 있으며 각 클래스에서 불균형 비율을 포함 하는 데이터를 참조 합니다. 이러한 불균형으로 인해 모델의 정확도가 잘못 인식 될 수 있습니다. 입력 데이터는 하나의 클래스를 기준으로 하기 때문에 학습 된 모델이 해당 바이어스를 모방 하 게 됩니다. 

분류 알고리즘은 일반적으로 정확도로 계산 되므로 모델의 정확도 점수를 확인 하는 것은 불균형 데이터의 영향을 받는 경우를 식별 하는 좋은 방법입니다. 특정 클래스에 대해 매우 높은 정확도 나 매우 낮은 정확도가 있나요?

또한 자동화 된 ML 실행은 다음 차트를 자동으로 생성 하며,이를 통해 모델 분류의 정확성을 이해 하 고 불균형 데이터의 영향을 받을 수 있는 모델을 식별할 수 있습니다.

차트| Description
---|---
[혼동 행렬](how-to-understand-automated-ml.md#confusion-matrix)| 데이터의 실제 레이블에 대해 올바르게 분류 된 레이블을 평가 합니다. 
[전체 자릿수-회수](how-to-understand-automated-ml.md#precision-recall-chart)| 데이터의 찾은 레이블 인스턴스 비율에 대해 올바른 레이블의 비율을 평가 합니다. 
[ROC 곡선](how-to-understand-automated-ml.md#roc)| 가양성 레이블의 비율에 대해 올바른 레이블의 비율을 평가 합니다.

## <a name="handle-imbalanced-data"></a>불균형 데이터 처리 

기계 학습 워크플로를 단순화 하는 목표의 일환으로, 자동화 된 ML은와 같은 불균형 데이터를 처리 하는 데 도움이 되는 기본 제공 기능을 제공 합니다. 

- **가중치 열**: 자동 ML은 가중치가 적용 된 열을 입력으로 지원 하 여 데이터의 행이 위쪽 또는 아래쪽으로 이동 하 여 클래스를 "중요" 하 게 만들 수 있습니다.

- 자동화 된 ML에서 사용 되는 알고리즘은 최대 20:1의 불균형을 적절히 처리할 수 있습니다. 즉, 가장 일반적인 클래스는 가장 일반적인 클래스 보다 데이터에서 20 배 더 많은 행을 가질 수 있습니다.

다음 기술에서는 자동화 된 ML 외부의 불균형 데이터를 처리 하는 추가 옵션을 설명 합니다. 

- 더 작은 클래스를 위로 샘플링 하거나 더 큰 클래스를 다운 샘플링 하 여 클래스 불균형에도 재샘플링 합니다. 이러한 방법에는를 처리 하 고 분석 하기 위한 전문 기술이 필요 합니다.

- 불균형 데이터에 대해 더 잘 처리 하는 성능 메트릭을 사용 합니다. 예를 들어 F1 점수는 전체 자릿수 및 회수의 가중치가 적용 된 평균입니다. 전체 자릿수는 분류자의 exactness을 측정 합니다. 낮은 정밀도는 분류자의 완전성을 측정 하는 동안 매우 많은 가양성--,를 나타냅니다. 낮은 회수는 매우 많은 가양성을 나타냅니다. 

## <a name="next-steps"></a>다음 단계

자동화 된 machine learning을 사용 하 여 모델을 작성 하는 방법 및 예제를 참조 하세요.

+ [자습서: 자동으로 회귀 모델 학습 Azure Machine Learning](tutorial-auto-train-models.md)

+ 자동 학습 실험의 설정 구성:
  + Azure Machine Learning studio에서 [다음 단계를 사용](how-to-use-automated-ml-for-ml-models.md)합니다.
  + Python SDK를 사용 하 여 [다음 단계를 수행](how-to-configure-auto-train.md)합니다.


