---
title: AutoML을 사용하여 & 불균형 한 데이터를 과도하게 사용하지 마십시오.
titleSuffix: Azure Machine Learning
description: Azure Machine Learning의 자동화된 기계 학습 솔루션을 사용하여 ML 모델의 일반적인 함정을 식별하고 관리합니다.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: conceptual
ms.reviewer: nibaccam
author: nibaccam
ms.author: nibaccam
ms.date: 04/09/2020
ms.openlocfilehash: 76f920ad6aae68defb567a7a6623d1ffd488af5f
ms.sourcegitcommit: 2d7910337e66bbf4bd8ad47390c625f13551510b
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 04/08/2020
ms.locfileid: "80874860"
---
# <a name="prevent-overfitting-and-imbalanced-data-with-automated-machine-learning"></a>자동화된 기계 학습으로 과적합 및 불균형 데이터 방지

기계 학습 모델을 구축할 때 과도하게 피팅되고 불균형한 데이터는 일반적인 함정입니다. 기본적으로 Azure Machine Learning의 자동화된 기계 학습은 이러한 위험을 식별하는 데 도움이 되는 차트 및 메트릭을 제공하고 이를 완화하는 데 도움이 되는 모범 사례를 구현합니다. 

## <a name="identify-over-fitting"></a>과도 피팅 식별

기계 학습에 과도하게 적합하면 모델이 학습 데이터에 너무 잘 맞을 때 발생하므로 보이지 않는 테스트 데이터를 정확하게 예측할 수 없습니다. 즉, 모델은 학습 데이터의 특정 패턴과 노이즈를 단순히 기억하지만 실제 데이터를 예측할 만큼 유연하지 는 않습니다.

다음과 같은 훈련된 모델과 해당 열차 및 테스트 정확도를 고려하십시오.

| 모델 | 열차 정확도 | 테스트 정확도 |
|-------|----------------|---------------|
| A | 99.9% | 95% |
| b | 87% | 87% |
| C | 99.9% | 45% |

모델 **A를**고려할 때 보이지 않는 데이터에 대한 테스트 정확도가 학습 정확도보다 낮으면 모델이 과도하게 장착된다는 일반적인 오해가 있습니다. 그러나 테스트 정확도는 항상 교육 정확도보다 낮아야 하며, 과적합과 적합에 대한 구별은 *정확도가 얼마나* 떨어집니다. 

모델 **A와** **B를**비교할 때 모델 **A는** 테스트 정확도가 높기 때문에 더 나은 모델이며 테스트 정확도는 95%로 약간 낮지만 과다 피팅이 있음을 시사하는 큰 차이는 아닙니다. 기차와 테스트 정확도가 더 가깝기 때문에 모델 **B를** 선택하지 않을 것입니다.

모델 **C는** 과적합의 명확한 케이스를 나타냅니다. 교육 정확도는 매우 높지만 테스트 정확도는 높지 않습니다. 이러한 구분은 주관적이지만 문제와 데이터에 대한 지식과 허용되는 오류의 크기에서 비롯됩니다.

## <a name="prevent-over-fitting"></a>과도 방지

가장 심각한 경우, 과도하게 장착된 모델은 학습 중에 보이는 피쳐 값 조합이 항상 대상에 대해 동일한 출력을 생성한다고 가정합니다.

과다 피팅을 방지하는 가장 좋은 방법은 다음을 포함한 ML 모범 사례를 따르는 것입니다.

* 더 많은 교육 데이터를 사용하고 통계적 편향을 제거합니다.
* 대상 누출 방지
* 더 적은 기능 사용
* **정규화 및 하이퍼매개 변수 최적화**
* **복잡성 제한 모델**
* **교차 유효성 검사**

자동화된 ML의 맥락에서 위의 처음 세 가지 항목은 **구현하는 모범 사례입니다.** 마지막 세 가지 굵은 항목은 기본적으로 과다 피팅으로부터 보호하기 위해 **자동화된 자동화된 ML 구현모범 사례입니다.** 자동화된 ML 이외의 설정에서는 과다 피팅 모델을 피하기 위해 6가지 모범 사례를 모두 따라야 합니다.

### <a name="best-practices-you-implement"></a>구현하는 모범 사례

**더 많은 데이터를** 사용하는 것이 과다 피팅을 방지하는 가장 간단하고 최선의 방법이며, 추가 보너스로 일반적으로 정확도가 높아진다. 더 많은 데이터를 사용하면 모델이 정확한 패턴을 기억하기가 더 어려워지고 더 많은 조건을 수용할 수 있는 보다 유연한 솔루션에 도달해야 합니다. 또한 학습 데이터에 실시간 예측 데이터에 존재하지 않는 격리된 패턴이 포함되지 않도록 **통계적 편향을**인식하는 것도 중요합니다. 이 시나리오는 기차와 테스트 세트 사이에 과도하게 적합하지 않을 수 있지만 라이브 테스트 데이터와 비교할 때 과도하게 피팅이 있을 수 있으므로 해결하기 어려울 수 있습니다.

대상 누설은 기차/테스트 세트 간에 과도하게 끼어있는 것을 볼 수 없지만 예측 시간에 나타나는 유사한 문제입니다. 대상 누설은 모델이 일반적으로 예측 시간에 가지고 있지 않아야 하는 데이터에 액세스하도록 하여 학습 중에 "치트"할 때 발생합니다. 예를 들어 월요일에 상품 가격이 금요일에 어떤 가격이 될지 예측하는 것이지만 기능 중 하나가 실수로 목요일의 데이터를 포함했다면, 이는 모델이 미래에 볼 수 없기 때문에 예측 시간에 없는 데이터입니다. 표적 누출은 놓치기 쉬운 실수이지만 종종 문제에 대해 비정상적으로 높은 정확도가 특징입니다. 주가를 예측하려고 시도하고 95%의 정확도로 모델을 학습한 경우 피처어딘가에 표적 누출이 발생할 수 있습니다.

피처를 제거하면 모델이 특정 패턴을 암기하는 데 사용할 필드가 너무 많지 않아 서투여 있는 것이 더 유연해질 수 있습니다. 정량적으로 측정하기는 어려울 수 있지만 피처를 제거하고 동일한 정확도를 유지할 수 있는 경우 모델을 보다 유연하게 만들고 과다 피팅의 위험을 줄일 수 있습니다.

### <a name="best-practices-automated-ml-implements"></a>모범 사례 자동화된 ML 구현

정규화는 복잡하고 과도하게 장착된 모델을 불이익을 주는 비용 기능을 최소화하는 프로세스입니다. 정규화 함수에는 여러 가지 유형이 있지만 일반적으로 모델 계수 크기, 분산 및 복잡성에 대한 불이익을 받습니다. 자동 ML은 오버 피팅을 제어하는 다양한 모델 하이퍼파라미터 설정과 서로 다른 조합으로 L1(올가미), L2(릿지) 및 ElasticNet(L1 및 L2)을 동시에 사용합니다. 간단히 말해서 자동화된 ML은 모델이 얼마나 규제되는지에 따라 달라지며 최상의 결과를 선택합니다.

또한 자동화ML은 명시적 모델 복잡성 제한을 구현하여 과도 피팅을 방지합니다. 대부분의 경우 이 구현은 개별 트리 최대 깊이가 제한되고 포리스트 또는 앙상블 기술에 사용되는 총 트리 수가 제한되는 의사 결정 트리 또는 포리스트 알고리즘을 위해 특별히 구현됩니다.

CV(교차 유효성 검사)는 전체 학습 데이터의 많은 하위 집합을 취하고 각 하위 집합에 대한 모델을 학습하는 프로세스입니다. 아이디어는 모델이 "운이 좋다"고 하나의 하위 집합으로 큰 정확도를 가질 수 있지만 많은 하위 집합을 사용하면 모델이 매번 이 높은 정확도를 달성하지 못한다는 것입니다. CV를 수행할 때 유효성 검사 홀드아웃 데이터 집합을 제공하고 CV 폴드(하위 집합 수)를 지정하고 자동화된 ML은 모델을 학습하고 하이퍼매개 변수를 조정하여 유효성 검사 집합의 오류를 최소화합니다. 하나의 CV 접기는 과도하게 맞을 수 있지만, 그 중 많은 것을 사용하면 최종 모델이 과도하게 맞을 확률이 줄어듭니다. 단점은 CV가 모델을 한 번 훈련하는 대신 각 *n CV* 하위 집합에 대해 한 번 학습하기 때문에 교육 시간이 길어지고 비용이 더 많이 든다는 것입니다. 

> [!NOTE]
> 교차 유효성 검사는 기본적으로 활성화되어 있지 않습니다. 자동화된 ML 설정에서 구성해야 합니다. 그러나 교차 유효성 검사를 구성하고 유효성 검사 데이터 집합이 제공된 후에는 프로세스가 자동화됩니다. 참조 

<a name="imbalance"></a>

## <a name="identify-models-with-imbalanced-data"></a>불균형 한 데이터로 모델 식별

불균형 데이터는 일반적으로 기계 학습 분류 시나리오의 데이터에서 발견되며 각 클래스의 관측값의 불균형 비율을 포함하는 데이터를 나타냅니다. 이러한 불균형은 입력 데이터가 한 클래스에 대한 바이어스를 가지므로 모델의 정확도에 대한 긍정적인 영향을 잘못 인식할 수 있으며, 이로 인해 학습된 모델이 해당 편향을 모방할 수 있습니다. 

분류 알고리즘은 일반적으로 정확도로 평가되므로 모델의 정확도 점수를 확인하는 것이 불균형한 데이터에 의해 영향을 받았는지 확인하는 좋은 방법입니다. 특정 병과에 대해 정확도가 높거나 정확도가 매우 낮았습니까?

또한 자동화된 ML 실행은 다음 차트를 자동으로 생성하므로 모델 분류의 정확성을 이해하고 불균형 데이터에 의해 영향을 받는 모델을 식별할 수 있습니다.

차트| Description
---|---
[혼란 매트릭스](how-to-understand-automated-ml.md#confusion-matrix)| 데이터의 실제 레이블에 대해 올바르게 분류된 레이블을 평가합니다. 
[정밀 리콜](how-to-understand-automated-ml.md#precision-recall-chart)| 데이터의 발견된 레이블 인스턴스 비율과 올바른 레이블의 비율을 평가합니다. 
[ROC 곡선](how-to-understand-automated-ml.md#roc)| 올바른 레이블의 비율을 가양성 레이블의 비율과 평가합니다.

## <a name="handle-imbalanced-data"></a>불균형 데이터 처리 

기계 학습 워크플로우를 단순화하는 목표의 일환으로 자동화된 ML은 이러한 불균형 데이터를 처리하는 데 도움이 되는 기능을 내장했습니다. 

- **가중치 열**: 자동화된 ML은 가중치가 있는 열을 입력으로 지원하므로 데이터의 행이 위 또는 아래로 가중치가 지정되어 클래스가 더 중요하거나 덜 중요해질 수 있습니다.

- 자동화된 ML에서 사용되는 알고리즘은 최대 20:1의 불균형을 적절하게 처리할 수 있으므로 가장 일반적인 클래스는 최소 공통 클래스보다 데이터에 20배 더 많은 행을 가질 수 있습니다.

다음 기술은 자동화된 ML 외부에서 불균형한 데이터를 처리하는 추가 옵션입니다. 

- 더 작은 클래스를 업샘플링하거나 더 큰 클래스를 다운 샘플링하여 클래스 불균형까지 리샘플링합니다. 이러한 방법을 처리하고 분석하려면 전문 지식이 필요합니다.

- 불균형 한 데이터를 더 잘 다루는 성능 메트릭을 사용합니다. 예를 들어 F1 점수는 정밀도와 리콜의 가중 평균입니다. 정밀도는 분류자의 정확성을 측정합니다- 낮은 정밀도는 높은 수의 거짓 긍정을 나타내고--, 리콜은 분류자의 완전성을 측정합니다. 

## <a name="next-steps"></a>다음 단계

예제를 참조하고 자동화된 기계 학습을 사용하여 모델을 빌드하는 방법을 알아봅니다.

+ 자습서 [따르기: Azure 기계 학습을 통해 회귀 모델을 자동으로 학습합니다.](tutorial-auto-train-models.md)

+ 자동 학습 실험에 대한 설정을 구성합니다.
  + Azure 기계 학습 스튜디오에서 [다음 단계를 사용합니다.](how-to-use-automated-ml-for-ml-models.md)
  + 파이썬 SDK를 [사용하여 다음 단계를 사용합니다.](how-to-configure-auto-train.md)


