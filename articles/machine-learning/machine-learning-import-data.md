<properties
	pageTitle="기계 학습 스튜디오로 데이터 가져오기 | Microsoft Azure"
	description="다양한 데이터 원본에서 Azure 기계 학습 스튜디오로 학습 데이터를 가져오는 방법. 지원되는 데이터 형식에 대해 알아봅니다."
	services="machine-learning"
	documentationCenter=""
	authors="garyericson"
	manager="paulettm"
	editor="cgronlun"/>

<tags
	ms.service="machine-learning"
	ms.workload="data-services"
	ms.tgt_pltfrm="na"
	ms.devlang="na"
	ms.topic="get-started-article"
	ms.date="05/19/2015"
	ms.author="garye" />


#다양한 데이터 원본에서 Azure 기계 학습 스튜디오로 학습 데이터를 가져오기

Azure 기계 학습 스튜디오에서 예측 분석 솔루션을 개발할 때 문제 공간의 대표 데이터를 사용하여 모델을 학습시킬 수 있습니다. 이 자습서에서는 기계 학습 스튜디오에서 모델을 학습하기 위해 다양한 데이터 원본에서 데이터를 가져오는 방법을 보여 줍니다. 또한 지원되는 데이터 형식에 대해 알아봅니다.

기계 학습 스튜디오에는 이 용도로 사용할 수 있는 샘플 데이터 집합이 많이 있습니다([Azure 기계 학습 스튜디오의 샘플 데이터 집합 사용](machine-learning-use-sample-datasets.md) 참조). 그러나 실험에 사용하도록 고유 데이터를 기계 학습 스튜디오에 가져올 수도 있습니다.

[AZURE.INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

기계 학습 스튜디오에서 고유 데이터를 사용하려면 로컬 하드 드라이브에서 미리 데이터 파일을 업로드하여 작업 영역에 데이터 집합 모듈을 생성할 수 있습니다. 또는 [판독기][reader] 모듈을 사용하여 실험을 실행하는 동안 여러 온라인 데이터 원본 중 하나의 데이터에 액세스할 수도 있습니다.

- Azure Blob 저장소, 테이블 또는 SQL 데이터베이스
- HiveQL을 사용하는 Hadoop
- HTTP을 사용하는 웹 URL
- 데이터 피드 공급자

기계 학습 스튜디오는 데이터베이스에서 구분되었거나 구조화된 데이터인 텍스트 데이터 등의 직사각형 또는 테이블 형식 데이터에 대해 작업하도록 설계되어 있습니다. 단, 경우에 따라 직사각형이 아닌 데이터도 사용할 수 있습니다.

데이터가 비교적 정리되어 있는 것이 좋습니다. 즉, 실험에 데이터를 업로드하기 전에 따옴표가 없는 문자열 등의 문제를 처리합니다.

그러나 기계 학습 스튜디오에는 실험에서 데이터를 조작할 수 있는 모듈도 있습니다. 사용할 기계 학습 알고리즘에 따라 누락된 값 및 스파스 데이터와 같은 데이터 구조 문제 해결 방법을 결정해야 하며, 이때 도움을 줄 수 있는 모듈이 있습니다. 모듈 팔레트의 **데이터 변환** 섹션에서 이러한 함수를 수행하는 모듈을 찾습니다.

실험을 수행하는 동안 언제든지 출력 포트를 마우스 오른쪽 단추로 클릭하여 모듈에서 생성한 데이터를 보거나 다운로드할 수 있습니다. 모듈에 따라 서로 다른 다운로드 옵션을 사용할 수 있습니다. 또는 기계 학습 스튜디오의 웹 브라우저에서 데이터를 볼 수도 있습니다.


## 데이터 형식

데이터를 가져오는 데 사용하는 메커니즘과 데이터의 출처에 따라 실험에 여러 데이터 형식을 가져올 수 있습니다.

- 일반 텍스트(.txt)
- 헤더가 있거나(.csv) 없는(.nh.csv) 쉼표로 구분된 값(CSV)
- 헤더가 있거나(.tsv) 없는(.nh.tsv) 탭으로 구분된 값(TSV)
- Hive 테이블
- SQL 데이터베이스 테이블
- OData 값
- SVMLight 데이터(.svmlight)(형식 정보는 [SVMLight 정의](http://svmlight.joachims.org/) 참조)
- 특성 관계 파일 형식(ARFF) 데이터(.arff)(형식 정보는 [ARFF 정의](http://weka.wikispaces.com/ARFF) 참조)
- Zip 파일(.zip)
- R 개체 또는 작업 영역 파일(. RData)

메타 데이터를 포함하는 ARFF와 같은 형식으로 데이터를 가져오는 경우, 기계 학습 스튜디오에서는 이 메타 데이터를 사용하여 각 열의 머리글과 데이터 형식을 정의합니다. 이 메타 데이터를 포함하지 않는 TSV 또는 CSV 형식과 같은 데이터를 가져오는 경우, 기계 학습에서는 데이터를 샘플링하여 각 열의 데이터 형식을 유추합니다. 데이터에 열 머리글이 없는 경우 기계 학습 스튜디오에서 기본 이름을 제공합니다. [메타 데이터 편집기][metadata-editor]를 사용하여 열의 머리글과 데이터 유형을 명시적으로 지정하거나 변경할 수 있습니다.

기계 학습 스튜디오에서 인식하는 데이터 유형은 다음과 같습니다.

- 문자열
- Integer
- double
- Boolean
- DateTime
- TimeSpan

기계 학습 스튜디오에서는 *데이터 테이블*이라는 내부 데이터 형식을 사용하여 모듈 간에 데이터를 전달합니다. [데이터 집합으로 변환][convert-to-dataset] 모듈을 사용하여 명시적으로 데이터를 데이터 테이블 형식으로 변환할 수 있습니다. 데이터 테이블 이외의 형식을 허용하는 모든 모듈에서는 다음 모듈에 데이터를 전달하기 전에 데이터를 데이터 테이블로 자동 변환합니다. 필요한 경우 다른 변환 모듈을 사용하여 데이터 테이블 형식을 다시 CSV, TSV, ARFF 또는 SVMLight 형식으로 변환할 수 있습니다. 모듈 팔레트의 **데이터 형식 변환** 섹션에서 이러한 함수를 수행하는 모듈을 찾습니다.


## 로컬 파일에서 데이터 가져오기

다음을 수행하여 로컬 하드 드라이브에서 데이터를 가져올 수 있습니다.

1. 기계 학습 스튜디오 창 하단에 있는 **+새로 만들기**를 클릭합니다.
2. **데이터 집합** 및 **로컬 파일에서**를 선택합니다.
3. **새 데이터 집합 업로드** 대화 상자에서 업로드할 파일을 찾아봅니다.
4. 이름을 입력하고, 데이터 형식을 식별하며, 선택적으로 설명을 입력합니다. 설명을 사용하면 나중에 데이터를 사용할 때 기억해야 할 데이터에 대한 특성을 기록할 수 있으므로 좋습니다.
5. **기존 데이터 집합의 새로운 버전** 확인란을 사용하면 새 데이터로 기존 데이터 집합을 업데이트할 수 있습니다. 이 확인란을 클릭한 다음 기존 데이터 집합의 이름을 입력하기만 하면 됩니다.

업로드 중에 파일이 업로드 중임을 나타내는 메시지가 표시됩니다. 업로드 시간은 데이터의 크기와 서비스에 대한 연결 속도에 따라 달라집니다. 파일이 오래 걸릴 것을 알고 있으면 기다리는 동안 기계 학습 스튜디오에서 다른 작업을 수행할 수 있습니다. 그러나 브라우저를 닫으면 데이터 업로드에 실패하게 됩니다.

데이터가 업로드되면 데이터 집합 모듈에 저장되고 작업 영역의 모든 실험에서 사용할 수 있습니다. 실험을 편집할 때 모듈 팔레트에 있는 **저장된 데이터 집합** 목록에서 사전에 로드된 샘플 데이터 집합과 함께 데이터 집합을 찾을 수 있습니다.


## 판독기 모듈을 사용하여 온라인 데이터에 액세스

실험에서 [판독기][reader] 모듈을 사용하여, 실험을 실행하는 동안 여러 온라인 원본의 데이터에 액세스할 수 있습니다. 실험이 실행 중인 동안 이 학습 데이터에 액세스하므로 한 실험에서만 사용할 수 있습니다(작업 영역의 모든 실험에서 사용 가능한 데이터 집합 모듈과 반대).

실험에 [판독기][reader] 모듈을 추가한 다음 **데이터 원본**을 추가하고 모듈 매개 변수를 사용하여 액세스 정보를 제공합니다. 예를 들어, **HTTP를 통한 웹 URL**을 선택하는 경우 원본 URL과 데이터 형식을 제공합니다. Azure 저장소 또는 HDInsight(Hive 쿼리 사용)의 학습 데이터에 액세스하는 경우 적절한 계정 정보와 데이터 위치를 제공합니다.

> [AZURE.NOTE]이 문서에서는 [판독기][reader] 모듈에 대한 일반 정보를 제공합니다. 액세스할 수 있는 데이터 형식, 형식, 매개변수 및 일반 질문의 응답에 대한 자세한 내용은 [판독기][reader] 모듈의 모듈 참조 항목을 참조하세요.


### Azure에서 데이터 가져오기

다음과 같은 세 가지 Azure 데이터 원본에서 데이터를 가져올 수 있습니다.

- **Azure Blob 저장소** - 저장소에 ARFF 형식을 사용하는 경우, 머리글 메타 데이터를 사용하여 열을 매핑합니다. TSV 또는 CSV 형식을 사용하는 경우 샘플링 열 데이터를 사용하여 매핑을 유추합니다.
- **Azure 테이블 저장소** - [판독기][reader] 모듈에서 데이터를 스캔하여 열 데이터 유형을 식별합니다. 데이터가 상당히 같으며 예측 가능한 경우 스캔하는 행 수를 제한할 수 있습니다.
- **Azure SQL 데이터베이스** - [판독기][reader] 모듈에서는 SQL Azure Transact 클라이언트 API를 사용하여 사용자가 제공하는 데이터베이스 쿼리를 통해 데이터를 가져옵니다.

Blob 및 테이블 저장소의 경우 SAS URI(공유 액세스 서명 URI) 또는 Azure 저장소 계정 정보를 사용하여 데이터 액세스 권한을 제공합니다. Azure SQL 데이터베이스의 경우, 데이터베이스와 계정 정보 외에도 가져올 데이터를 식별하는 데이터베이스 쿼리를 제공합니다.

### 웹에서 데이터 가져오기

[판독기][reader] 모듈을 사용하여 웹 또는 FTP 사이트에서 학습 데이터를 읽을 수 있습니다. 다음을 제공해야 합니다.

- 파일의 전체 HTTP URL 주소
- 파일(CSV, TSV, ARFF 또는 SvmLight)의 데이터 형식
- CSV 또는 TSV 파일의 경우, 파일의 첫 번째 줄이 헤더인지 표시

### Hadoop에서 데이터 가져오기

[판독기][reader] 모듈을 사용하여 HiveQL 쿼리 언어를 통해 분산 저장소에서 학습 데이터를 읽을 수 있습니다. Hive 데이터베이스 쿼리를 지정하고 HCatalog 서버에서 사용자 액세스 정보를 제공해야 합니다. 데이터가 저장된 위치가 HDFS(Hadoop 분산 파일 시스템)인지 아니면 Azure인지도 지정해야 하며, Azure인 경우 Azure 계정 정보를 지정해야 합니다.

### 데이터 피드 공급자로부터 데이터 가져오기

OData URL을 지정하여 데이터 피드 공급자로부터 직접 데이터를 읽을 수 있습니다. 원본 URL 및 데이터 콘텐츠 형식을 제공해야 합니다.


## 실험 데이터 저장


실험의 중간 결과를 다른 실험의 일부로 사용하려는 경우가 있습니다. 다음을 수행합니다.

1. 데이터 집합으로 저장할 모듈의 출력을 마우스 오른쪽 단추로 클릭합니다.

2. **데이터 집합으로 저장**을 클릭합니다.

3. 메시지가 표시되면 데이터 집합을 쉽게 식별할 수 있는 이름과 설명을 입력합니다.

4. **확인** 확인 표시를 클릭합니다.

저장이 완료되면 작업 영역의 모든 실험에서 데이터 집합을 사용할 수 있습니다. 모듈 팔레트의 **저장된 데이터 집합** 목록에서 찾을 수 있습니다.


<!-- Module References -->
[convert-to-dataset]: https://msdn.microsoft.com/library/azure/72bf58e0-fc87-4bb1-9704-f1805003b975/
[metadata-editor]: https://msdn.microsoft.com/library/azure/370b6676-c11c-486f-bf73-35349f842a66/
[reader]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/
 

<!---HONumber=July15_HO4-->