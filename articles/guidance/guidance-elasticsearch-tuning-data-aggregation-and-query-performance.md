<properties
   pageTitle="Azure에서 Elasticsearch로 데이터 집계 및 쿼리 성능 조정 | Microsoft Azure"
   description="Elasticsearch에 대한 쿼리 및 검색 성능을 최적화하는 경우 고려 사항의 요약입니다."
   services=""
   documentationCenter="na"
   authors="mabsimms"
   manager="marksou"
   editor=""
   tags=""/>

<tags
   ms.service="guidance"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="na"
   ms.date="02/29/2016"
   ms.author="masimms"/>
   
# Azure에서 Elasticsearch로 데이터 집계 및 쿼리 성능 조정


이 문서는 [시리즈의 일부](guidance-elasticsearch.md)입니다.

Elasticsearch를 사용하는 주된 이유는 데이터 검색을 지원하기 위해서입니다. 사용자가 찾고 있는 정보를 빠르게 찾을 수 있어야 합니다. 또한 시스템은 사용자가 데이터에 대해 질문하고, 상관 관계를 검색하며 비즈니스 의사 결정을 수행할 수 있는 결론을 얻도록 해야 합니다. 이 과정이 데이터가 정보와 다른 이유입니다.

이 문서는 시스템을 쿼리 및 검색 성능에 최적화하기 위한 가장 좋은 방법을 결정할 때 고려할 수 있는 옵션을 요약합니다.

모든 성능 권장 사항은 상황에 적용되는 시나리오, 인덱싱하는 데이터의 볼륨 및 응용 프로그램 및 사용자가 데이터를 쿼리하는 속도에 크게 의존합니다. 구성에서 모든 변경의 결과 또는 사용자 고유의 데이터 및 워크로드를 사용하는 인덱스 구조를 신중하게 테스트하여 특정 시나리오에 대한 이점을 평가해야 합니다. 이를 위해 이 문서는 다양한 구성을 사용하여 구현된 한 가지 특정 시나리오에 수행한 여러 벤치마크를 설명합니다. 고유한 시스템의 성능을 평가하기 위해 수행하는 방법을 적용할 수 있습니다. 이러한 테스트에 대한 세부 정보는 [부록](#appendix-the-query-and-aggregation-performance-test)에 나와 있습니다.

## 인덱스 및 쿼리 성능 고려 사항

이 섹션에서는 빠른 쿼리 및 검색을 지원해야 하는 인덱스를 디자인하는 경우 생각해야 할 몇 가지 일반적인 요인을 설명합니다.

### 인덱스에 여러 형식 저장

Elasticsearch 인덱스는 여러 형식을 포함할 수 있습니다. 이 방법을 사용하지 않고 각 형식에 대한 별도 인덱스를 만드는 것이 나을 수 있습니다. 다음 사항을 고려합니다.

- 다양한 형식은 다른 분석기를 지정하며 형식 수준이 아닌 인덱스 수준에서 쿼리를 수행하는 경우 사용해야 하는 분석기 Elasticsearch가 때로 명확하지 않습니다. 자세한 내용은 [형식 알려진 문제 방지](https://www.elastic.co/guide/en/elasticsearch/guide/current/mapping.html#_avoiding_type_gotchas)를 참조하세요.

- 여러 형식을 보유하는 인덱스의 분할된 데이터베이스는 단일 형식을 포함하는 인덱스에 대한 분할된 데이터베이스보다 큽니다. 분할된 데이터베이스가 클수록 쿼리를 수행할 때 데이터를 필터링하는 Elasticsearch에서 많은 노력이 필요합니다

- 형식에 대한 데이터 볼륨 간에 심각한 불일치가 있으면 이 데이터를 검색하는 검색의 효율을 줄이는 여러 분할된 데이터베이스에 한 형식에 대한 정보가 드물게 배포될 수 있습니다.

    ![](./media/guidance-elasticsearch/query-performance1.png)

    ***그림 1. 형식 간에 인덱스 공유의 효과***

    그림 1에서는 이 시나리오를 보여줍니다. 다이어그램의 위쪽에서 동일한 인덱스는 형식 A와 형식 B의 문서에서 공유됩니다. 형식 B보다 형식 A인 문서가 많습니다. 형식 A를 검색하면 네 개의 분할된 데이터베이스를 모두 쿼리하는 작업을 포함합니다. 각 형식에 대한 별도 인덱스를 만든 경우 다이어그램의 아래쪽은 효과를 보여줍니다. 이 경우에 형식 A에 대한 검색은 두 개의 분할된 데이터베이스에 액세스가 필요합니다.

- 작은 분할된 데이터베이스는 크게 분할된 데이터베이스보다 균등하게 분산될 수 있으며 이는 Elasticsearch가 노드 간에 부하를 고르게 분산할 수 있도록 합니다.

- 다른 형식에는 다른 보존 기간이 있을 수 있습니다. 활성 데이터로 분할된 데이터베이스를 공유하는 이전 데이터를 보관하기가 어려울 수 있습니다.


그러나 다음과 같은 경우 상황에 따라 형식 전체에서 인덱스를 공유하는 것이 효율적일 수 있습니다.

- 정기적으로 동일한 인덱스에 저장된 범위 형식을 검색합니다.

- 형식에는 각각 적은 수의 문서가 있으며 이 경우에 각 형식에 대한 분할된 데이터베이스의 별도 집합을 유지하는 작업은 상당한 오버 헤드될 수 있습니다.


### 인덱스 형식 최적화

Elasticsearch 인덱스는 이를 채우는 데 사용된 원래 JSON 문서의 복사본을 포함합니다. 이 정보는 각 인덱싱된 항목의 [*\_source*](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-source-field.html#mapping-source-field) 필드에 보유됩니다. 이 데이터를 검색할 수 없지만 기본적으로 *get* 및 *search* 요청에서 반환됩니다. 그러나 이 필드는 오버 헤드가 발생하며 저장소를 채우고 이는 분할된 데이터베이스를 더 크게 만들며 수행된 I/O의 볼륨을 증가시킵니다. 형식별로 *\_source* 필드를 사용하지 않도록 설정할 수 있습니다.

```http
PUT my_index
{
  "mappings": {
    "my_type": {
      "_source": {
        "enabled": false
      }
    }
  }
}
```
또한 이 필드를 사용하지 않도록 설정하면 다음 작업을 수행하는 기능을 제거합니다.

- *업데이트* API를 사용하여 인덱스의 데이터를 업데이트합니다.

- 강조 표시된 데이터를 반환하는 검색을 수행합니다.

- Elasticsearch 인덱스에서 직접 다른 인덱스로 다시 인덱싱합니다.

- 매핑 또는 분석 설정을 변경합니다.

- 원본 문서를 확인하여 쿼리를 디버깅합니다.


### 데이터 다시 인덱싱

인덱스에 사용할 수 있는 분할된 데이터베이스의 수는 궁극적으로 인덱스의 용량을 결정합니다. 필요한 분할된 데이터베이스를 초기(및 정보에 근거한)에 추측하는 데 시간이 걸리지만 항상 문서를 다시 인덱싱하도록 고려해야 합니다. 대부분의 경우에서 다시 인덱싱하는 작업은 데이터 증가할 때 의도된 태스크입니다. 검색 최적화를 위해 우선 많은 수의 분할된 데이터베이스를 인덱스에 할당하지 않으려고 하지만 데이터의 볼륨이 확장되면 새롭게 분할된 데이터베이스를 할당합니다. 다른 경우에 데이터 볼륨 증가에 대한 예측이 정확하지 않다는 것을 간단히 입증하면 다시 인덱싱하는 작업은 더 임시로 수행되어야 합니다.

> [AZURE.NOTE] 다시 인덱싱하는 작업은 빠르게 노화하는 데이터에 필요하지 않을 수 있습니다. 이 경우에 응용 프로그램은 각 기간에 대한 새 인덱스를 만들 수 있습니다. 예제가 성능 로그를 포함하거나 매일 새로 고침 인덱스에 저장할 수 있는 데이터를 감사합니다.

<!-- -->

다시 인덱싱하는 작업은 기존 인덱스의 데이터에서 새 인덱스를 만들고 이전 인덱스를 제거하는 작업을 효율적으로 포함합니다. 인덱스가 큰 경우 이 프로세스는 시간이 걸리고 이 기간 동안 데이터를 검색 가능하도록 해야 할 수 있습니다. 이러한 이유로 [각 인덱스에 대한 별칭](https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-aliases.html)을 만들어야 하며 쿼리는 이러한 별칭을 통해 데이터를 검색해야 합니다. 인덱싱을 다시 수행하는 동안 이전 인덱스를 가리키는 별칭을 유지한 다음 다시 인덱싱을 완료하면 새 인덱스를 참조하도록 전환합니다. 또한 이 방법은 매일 새 인덱스를 만드는 시간 기반 데이터에 액세스하는 데 도움이 됩니다. 현재 데이터에 액세스하려면 데이터가 만들어질 때 새 인덱스를 롤오버하는 별칭을 사용합니다.

### 매핑 관리

Elasticsearch는 매핑을 사용하여 문서에서 각 필드에 발생하는 데이터를 해석하는 방법을 알아봅니다. 각 형식에는 효과적으로 해당 형식에 대한 스키마를 정의하는 고유한 매핑이 있습니다. Elasticsearch는 이 정보를 사용하여 어떤 형식의 문서에 각 필드에 대한 반전된 인덱스를 생성합니다. 문서에서 각 필드에는 데이터 형식(예: *string*, *date* 또는 *long*) 및 값이 있습니다. 인덱스를 처음 만들 때 인덱스에 대한 매핑을 지정하거나 형식에 새 문서를 추가할 때 Elasticsearch로 유추할 수 있습니다. 그러나 다음 사항을 고려합니다.

- 동적으로 생성된 매핑은 문서를 인덱스에 추가할 경우 필드의 해석 방법에 따라 오류를 발생시킬 수 있습니다. 예를 들어 문서 1은 숫자를 보유하고 Elasticsearch를 발생시키는 필드 A를 포함하여 이 필드를 *long*으로 지정하는 매핑을 추가합니다. 다음 문서가 숫자가 아닌 데이터를 포함하는 필드 A에 추가되면 실패합니다. 이 경우에 필드 A는 아마도 첫 번째 문서를 추가할 때 문자열로 해석했어야 합니다. 인덱스를 만들 때 이 매핑 지정은 이러한 문제를 방지하는 데 도움을 줄 수 있습니다.

- 이처럼 아주 큰 매핑을 생성하지 않도록 문서를 디자인하면 검색을 수행하는 경우 상당한 오버헤드를 추가하고 많은 양의 메모리를 소비하며 쿼리에 데이터를 찾지 못하는 오류를 일으킬 수 있습니다. 동일한 형식을 공유하는 문서에서 필드에 대한 일관성 있는 명명 규칙을 적용합니다. 예를 들어 다른 문서에서 "first\_name", "FirstName" 및 "forename"과 같은 필드 이름을 사용하지 않고 각 문서에 동일한 필드 이름을 사용합니다. 또한 값을 키로 사용하려 하지 마세요(열 제품군 데이터베이스에서 일반적인 접근 방식이지만 Elasticsearch에 비효율성 및 실패를 발생시킬 수 있음). 자세한 내용은 [매핑 급증](https://www.elastic.co/blog/found-crash-elasticsearch#mapping-explosion)을 참조하세요.

- *not\_analyzed*를 사용하여 적절한 위치에서 토큰화를 방지합니다. 예를 들어 문서가 "ABC-DEF" 값을 보유하는 *데이터*라는 문자열 필드를 포함하는 경우 값이 다음과 같이 일치하는 모든 문서를 검색해 볼 수 있습니다.

  ```http
  GET /myindex/mydata/_search
  {
    "query" : {
      "filtered" : {
        "filter" : {
          "term" : {
            "data" : "ABC-DEF"
          }
        }
      }
    }
  }
  ```

    However, this search will fail to return the expected results due to the way in which the string ABC-DEF is tokenized when it is indexed; it will be effectively split into two tokens, ABC and DEF, by the hyphen. This feature is designed to support full text searching, but if you want the string to be interpreted as a single atomic item you should disable tokenization when the document is added to the index. You can use a mapping such as this:

  ```http
  PUT /myindex
  {
    "mappings" : {
      "mydata" : {
        "properties" : {
          "data" : {
            "type" : "string",
            "index" : "not_analyzed"
          }
        }
      }
    }
  }
  ```

  자세한 내용은 [정확한 값 찾기](https://www.elastic.co/guide/en/elasticsearch/guide/current/_finding_exact_values.html#_term_filter_with_text)를 참조하세요.


### Doc 값 사용

많은 쿼리 및 집계는 검색 작업의 일환으로 정렬되어 있어야 합니다. 정렬 문서 목록에 하나 이상의 단어를 매핑할 수 있는 기능이 필요합니다. 이 프로세스를 지원하기 위해 Elasticsearch는 메모리에 정렬 키로 사용된 필드에 대한 값을 모두 로드할 수 있습니다. 이 정보는 *fielddata*라고 합니다. 메모리의 캐싱 필드 데이터가 I/O가 감소시키면 디스크에서 동일한 데이터를 반복적으로 읽는 것보다 빠를 수 있습니다. 그러나 필드에 높은 카디널리티가 있는 경우 필드 데이터를 메모리에 저장하는 작업이 힙 공간을 많이 사용할 수 있으며 다른 동시 작업을 수행하는 기능에 영향을 미치거나 Elasticsearch에 실패를 유발하는 저장소를 남용할 수 있습니다.

대체 방법으로 Elasticsearch도 *doc 값*을 지원합니다. doc 값은 디스크에 저장하며 데이터가 인덱스에 저장될 때 만들어진다는 점을 제외하고 메모리 내 필드 데이터의 항목과 비슷합니다(필드 데이터는 쿼리를 수행할 때 동적으로 생성됨). Doc 값은 힙 공간을 사용하지 않고 많은 고유한 값을 포함할 수 있는 필드에 데이터를 정렬 또는 집계하는 쿼리에 유용합니다. 또한 힙에 압력이 감소하면 디스크에서 데이터를 검색하고 메모리에서 읽는 작업 간의 성능 차이를 오프셋하는 데 도움이 될 수 있습니다. 가비지 수집은 발생할 가능성이 줄고 메모리를 활용하는 다른 동시 작업은 영향을 받을 가능성이 적습니다.

다음 예제에서와 같이 *doc\_values* 특성을 사용하여 인덱스에서 속성별로 doc 값을 사용하거나 사용하지 않도록 설정합니다.

```http
PUT /myindex
{
  "mappings" : {
    "mydata" : {
      "properties" : {
        "data" : {
          ...
          "doc_values": true
        }
      }
    }
  }
}
```
> [AZURE.NOTE] doc 값은 기본적으로 Elasticsearch 버전 2.0.0 이상으로 활성화됩니다.

doc 값을 사용하는 경우 사용자 고유의 데이터 및 쿼리 시나리오에 특정될 가능성이 매우 높습니다. 따라서 유용성을 설정하는 성능 테스트를 수행할 준비를 합니다. 또한 doc 값이 분석된 문자열 필드로 작동하지 않는 점에 유의해야 합니다. 자세한 내용은 [Doc 값](https://www.elastic.co/guide/en/elasticsearch/guide/current/doc-values.html#doc-values)을 참조하세요.

### 복제본을 사용하여 쿼리 경합 축소

쿼리의 성능을 향상시키는 일반적인 전략은 각 인덱스의 여러 복제본을 만드는 것입니다. 복제본에서 데이터를 가져오면 데이터 검색 작업을 처리할 수 있습니다. 그러나 이 전략은 데이터 수집 작업의 성능에 심각하게 영향을 줄 수 있으므로 혼합된 워크로드를 포함하는 시나리오에서 주의하여 사용해야 합니다. 또한 복제본이 노드에 분산되고 동일한 인덱스의 일부인 기본 분할된 데이터베이스를 사용하여 리소스에서 서로 충돌하지 않는 경우 이 전략은 장점만 발휘됩니다. 인덱스에 대한 복제본의 수를 동적으로 늘리거나 줄일 수 있습니다.

### 분할된 데이터베이스 요청 캐시 사용

Elasticsearch는 메모리에서 분할된 데이터베이스의 쿼리에 의해 요청된 로컬 데이터를 캐시할 수 있습니다. 이를 통해 보다 신속하게 실행할 동일한 데이터를 가져오는 검색을 사용할 수 있습니다. 데이터는 디스크 저장소가 아닌 메모리에서 읽어올 수 있습니다. 이러한 방식으로 데이터를 캐싱하므로 동시에 수행되는 다른 작업에 사용 가능한 메모리 비용을 줄이면서 일부 검색 작업의 성능을 향상시킬 수 있습니다. 또한 캐시에서 제공되는 데이터가 오래될 위험이 있습니다. 분할된 데이터베이스를 새로 고치고 데이터가 변경된 경우 캐시의 데이터만 무효화됩니다. 새로 고침 주기는 인덱스의 *refresh\_interval* 설정 값에 의해 제어됩니다.

기본적으로 인덱스에 대한 요청 캐시는 사용할 수 없지만 다음과 같이 사용할 수 있습니다.

```http
PUT /myindex/_settings
{
  "index.requests.cache.enable": true
}
```

분할된 데이터베이스 요청 캐시는 기록 또는 로깅 데이터와 같이 상대적으로 정적인 정보에 가장 적합합니다.

### 클라이언트 노드 사용

모든 쿼리는 먼저 요청을 수신하는 노드에 의해 처리됩니다. 이 노드는 쿼리된 인덱스에 대한 분할된 데이터베이스를 포함하는 다른 모든 노드에 추가 요청을 보낸 다음 응답을 반환하는 결과를 누적합니다. 쿼리가 데이터를 집계하거나 복잡한 계산을 수행하는 작업을 포함하는 경우 초기 노드는 적절한 처리를 수행합니다. 시스템이 상대적으로 적은 수의 복잡한 쿼리를 지원해야 하는 경우 데이터 노드의 부하를 완화하기 위해 클라이언트 노드의 풀을 만드는 것이 좋습니다. 반대로, 시스템이 많은 수의 간단한 쿼리를 처리하는 경우 이러한 요청 데이터 노드에 직접 제출하고 부하 분산 장치를 사용하여 요청을 균등하게 분산합니다.

### 쿼리 튜닝

다음 사항은 Elasticsearch 쿼리의 성능을 극대화하기 위한 팁을 요약합니다.

- 가능한 경우 와일드 카드를 포함하는 쿼리를 피합니다.

- 동일한 필드에 전체 텍스트 검색 및 정확한 일치가 적용되는 경우 분석 및 분석되지 않는 형태로 필드에 대한 데이터를 저장하는 것이 좋습니다. 분석된 필드에 대해 전체 텍스트 검색을 수행하고 분석되지 않는 필드에 대해 정확한 일치를 수행합니다.

- 필요한 데이터만 반환합니다. 큰 문서가 있지만 응용 프로그램에 필드의 하위 집합에 저장된 정보만 필요한 경우 전체 문서보다는 쿼리에서 이 하위 집합을 반환합니다. 이 전략은 클러스터의 네트워크 대역폭 요구 사항을 줄일 수 있습니다.

- 가능하다면 데이터를 검색할 때 쿼리 대신 필터를 사용하세요. 필터는 단순히 문서가 지정된 조건과 일치하는지 여부를 결정하는 반면 쿼리는 문서가 얼마나 근접하게 일치하는지도 계산합니다(점수 매기기). 내부적으로 필터에 의해 생성된 값은 각 문서에 대한 일치/불일치를 나타내는 비트맵으로 저장되며 Elasticsearch로 캐싱할 수 있습니다. 이후에 동일한 필터 조건이 발생하는 경우 캐시에서 비트맵을 검색하고 일치하는 문서를 신속하게 가져오는 데 사용할 수 있습니다. 자세한 내용은 [내부 필터 작업](https://www.elastic.co/guide/en/elasticsearch/guide/current/_finding_exact_values.html#_internal_filter_operation)을 참조하세요.

- 정적 비교를 수행하는 데 *bool* 필터를 사용하고 스크립팅 또는 *geo-** 필터를 포함하는 동적으로 계산된 필터에는 *and*, *or* 및 *not* 필터만 사용하세요.

- 쿼리에서 *bool* 필터와 *and*, *or* 또는 *not*이 있는 *geo-** 필터를 결합하는 경우 *and*/*or*/*not geo-** 필터를 마지막에 배치하여 가능한 가장 작은 데이터 집합에서 작동하도록 할 수 있습니다.

    마찬가지로 *post\_filter*를 사용하여 비용이 많이 드는 필터 작업을 실행합니다. 이러한 필터는 마지막으로 수행됩니다.

- 패싯보다는 집계를 사용합니다. 분석되거나 가능한 많은 값을 포함하는 집계를 계산하는 것은 지양합니다.

    > **참고**: 패싯은 Elasticsearch 버전 2.0.0에서 제거되었습니다.

- 응용 프로그램에서 정확한 일치 항목 수를 필요로 하지 않는 경우 *value\_count*에 대한 기본 설정에서 *카디널리티* 집계를 사용합니다. 정확한 개수는 금방 구식이 될 수 있으며 많은 응용 프로그램에 적절한 근사값만 필요합니다.

- 스크립팅을 피하세요. 쿼리 및 필터의 스크립트는 비용이 많이 들 수 있으며 결과가 캐시되지 않습니다. 장기 실행 스크립트는 검색 스레드를 무기한으로 사용할 수 있으며 후속 요청이 큐에 대기됩니다. 큐가 채워지면 추가 요청은 거부됩니다.

## 집계 및 검색 성능 테스트 및 분석

이 섹션에서는 다양한 클러스터 및 인덱스 구성에 대해 수행된 테스트에 대한 일련의 결과를 설명합니다. 다음과 같이 두 유형의 테스트가 수행되었습니다.

- ***수집 및 쿼리* 테스트**. 이 테스트는 대량 삽입 작업을 수행하여 진행하는 테스트로 채워진 빈 인덱스를 시작합니다(각 작업은 1000개의 문서를 추가함). 동시에 이전 15분 기간 동안 추가된 문서를 검색하고 집계를 생성하도록 디자인된 많은 쿼리가 5초 간격으로 반복되었습니다. 일반적으로 이 테스트는 실시간에 가까운 쿼리와 대규모 데이터 수집으로 구성된 까다로운 워크로드의 효과를 재현하기 위해 24시간 동안 실행하도록 허용되었습니다.

- ***쿼리 전용* 테스트**. 이 테스트는 수집 부분이 생략된 것을 제외하고 *수집 및 쿼리* 테스트와 유사하며 각 노드의 인덱스는 1억 개의 문서로 미리 채워집니다. 수정된 쿼리 집합이 수행됩니다. 데이터가 정적이므로 문서를 최근 15분 동안 추가된 것으로 제한하는 시간 요소는 제거되었습니다. 테스트는 90분 동안 실행되었습니다. 데이터 양이 고정되었으므로 성능 패턴을 설정하는 데 필요한 시간이 줄어듭니다.

---

인덱스의 각 문서는 동일한 스키마를 가집니다. 이 테이블에서는 스키마의 필드를 요약합니다.

이름 | 형식 | 참고 사항 |
  ----------------------------- | ------------ | -------------------------------------------------------- |
 조직 | String | 테스트는 200개의 고유한 조직을 생성합니다. |
 CustomField1 - CustomField5 |String |빈 문자열로 설정되는 다섯 개의 문자열 필드입니다.|
 DateTimeRecievedUtc |Timestamp |문서 추가된 날짜 및 시간입니다.|
 호스트 |문자열 |이 필드는 빈 문자열로 설정됩니다.|
 HttpMethod |String |이 필드는 "POST", "GET", "PUT" 값 중 하나로 설정됩니다.|
 HttpReferrer |String |이 필드는 빈 문자열로 설정됩니다.|
 HttpRequest |문자열 |이 필드는 10자에서 200자 사이인 임의의 텍스트로 채워집니다.|
 HttpUserAgent |문자열 |이 필드는 빈 문자열로 설정됩니다.|
 HttpVersion |문자열 |이 필드는 빈 문자열로 설정됩니다.|
 OrganizationName |문자열 |이 필드는 조직 필드와 동일한 값으로 설정됩니다.|
 SourceIp |IP |이 필드는 데이터의 "출처"를 나타내는 IP 주소를 포함합니다. |
 SourceIpAreaCode |Long |이 필드는 0으로 설정됩니다.|
 SourceIpAsnNr |문자열 |이 필드는 "AS#####"으로 설정됩니다.|
 SourceIpBase10 |Long |이 필드는 500으로 설정됩니다.|
 SourceIpCountryCode |문자열 |이 필드는 2자인 국가 코드를 포함합니다. |
 SourceIpCity |String |이 필드는 국가에서 도시를 식별하는 문자열을 포함합니다. |
 SourceIpLatitude |Double |이 필드는 임의의 값을 포함합니다.|
 SourceIpLongitude |Double |이 필드는 임의의 값을 포함합니다.|
 SourceIpMetroCode |Long |이 필드는 0으로 설정됩니다.|
 SourceIpPostalCode |문자열 |이 필드는 빈 문자열로 설정됩니다.|
 SourceLatLong |지역 지점 |이 필드는 임의의 지역 지점으로 설정됩니다.|
 SourcePort |문자열 |이 필드는 임의의 수인 문자열 표현으로 채워집니다.|
 TargetIp |IP |0\.0.100.100에서 255.9.100.100 범위에서 임의의 IP 주소로 채워집니다.|
 SourcedFrom |문자열 |이 필드는 문자열 "MonitoringCollector"로 설정됩니다.|
 TargetPort |String |이 필드는 임의의 수인 문자열 표현으로 채워집니다.|
 등급 |문자열 |이 필드는 임의로 선택한 20개의 다른 문자열 값 중 하나로 채워집니다.|
 UseHumanReadableDateTimes |Boolean |이 필드는 false로 설정됩니다.|
 
다음 쿼리는 테스트의 각 반복에 의해 배치로 수행되었습니다. 기울임꼴로 표시된 이름은 이 문서의 나머지 부분에서 이러한 쿼리를 나타내는 데 사용됩니다. 시간 기준(최근 15분 동안 추가된 문서)은 *쿼리 전용* 테스트에서 생략되었습니다.

- 최근 15분 동안 입력된 *등급* 값별 문서 수는(*등급별 수*)?

- 최근 15분 동안 5분 간격으로 추가된 문서 수는(*시간에 따른 수*)?

- 최근 15분 동안 각 국가에 추가된 *등급* 값별 문서 수는(*국가별 횟수*)?

- 최근 15분 동안 문서에 가장 자주 추가된 15개의 조직은(*상위 15개 조직*)?

- 최근 15분 동안 문서에 추가된 다른 조직은(*고유한 조직 수*)?

- 최근 15분 동안 추가된 문서 수는(*총 횟수*)?

- 최근 15분 동안 문서에 추가된 *SourceIp* 값은(*고유한 IP 수*)?


인덱스 정의 및 쿼리에 대한 세부 정보는 [부록](#appendix-the-query-and-aggregation-performance-test)에 설명되어 있습니다.

다음 변수의 효과를 이해하기 위해 테스트가 설계되었습니다.

- **디스크 유형**. 테스트는 표준 저장소(HDD)를 사용하는 D4 VM의 6-노드 클러스터에서 수행되고 프리미엄 저장소(SSD)를 사용하는 DS4 VM의 6-노드 클러스터에서 반복되었습니다.

- **컴퓨터 크기 - 강화**. DS3 VM을 구성하는 6-노드 클러스터(*작은* 클러스터로 지정됨)에서 테스트를 수행하고 DS4 VM의 클러스터(*중간* 클러스터)에서 반복하며 DS14 컴퓨터의 클러스터(*큰* 클러스터)에서 다시 반복했습니다. 다음 테이블은 각 VM SKU의 주요 특징을 요약합니다.

 프로비전 | VM SKU | 코어 수 | 데이터 디스크 수 | RAM(GB) |
---------|---------------|-----------------|----------------------|----------|
 작음 | 표준 DS3 | 4 | 8 | 14 |
 중간 | 표준 DS4 | 8 | 16 | 28 |
 큼 | 표준 DS14 | 16 | 32 | 112 |

- **클러스터 크기 - 규모 확장**. 1개, 3개 및 6개 노드로 구성되는 DS14 VM 클러스터에서 테스트가 수행되었습니다.

- **인덱스 복제본 수**. 1개 및 2개 복제본으로 구성된 인덱스를 사용하여 테스트가 수행되었습니다.

- **Doc 값**. 우선 *doc\_values*를 *true*(기본값)로 설정한 인덱스를 사용하여 테스트를 수행했습니다. *doc\_values*를 *false*로 설정하여 선택된 테스트를 반복했습니다.

- **캐싱**. 인덱스에 사용하도록 설정된 분할된 데이터베이스 캐시로 테스트가 수행되었습니다.

- **분할된 데이터베이스 수**. 큰 분할된 데이터베이스를 적은 수 포함하거나 작은 분할된 데이터베이스를 많이 포함하는 인덱스 중에 어떤 것에서 쿼리가 보다 효율적으로 실행되는지를 설정하기 위해 분할된 데이터베이스 수를 다양하게 사용하여 테스트를 반복했습니다.


## 성능 결과 – 디스크 유형

D4 VM의 6-노드 클러스터(HDD 사용) 및 DS4 VM의 6-노드 클러스터(SSD 사용)에서 *수집 및 쿼리* 테스트를 실행하여 디스크 성능을 평가했습니다. 두 클러스터 모두에서 Elasticsearch의 구성은 동일했습니다. 각 노드에서 16개의 디스크 간에 데이터를 분산했고 각 노드에는 JVM을 실행하는 Elasticsearch에 할당된 14GB RAM이 있습니다. 남은 메모리(14GB)는 운영 체제를 위해 남겨두었습니다. 각 테스트는 24시간 동안 실행되었습니다. 데이터 볼륨의 증가 효과가 명확해지고 시스템을 안정화할 수 있도록 이 기간을 선택했습니다. 다음 표는 테스트를 비교하기 위해 다양한 작업의 응답 시간을 강조하여 결과를 요약합니다.

 프로비전 | 작업/쿼리 | 평균 응답 시간(밀리초) |
---------|----------------------------|----------------------------|
 D4 | 수집 | 978 |
 | 등급별 수 | 103 |
 | 시간에 따른 수 | 134 |
 | 국가별 횟수 | 199 |
 | 상위 15개 조직 | 137 |
 | 고유한 조직 수 | 139 |
 | 고유한 IP 수 | 510 |
 | 총 횟수 | 89
 DS4 | 수집 | 511 |
 | 등급별 수 | 187 |
 | 시간에 따른 수 | 411 |
 | 국가별 횟수 | 402 |
 | 상위 15개 조직 | 307 |
 | 고유한 조직 수 | 320 |
 | 고유한 IP 수 | 841 |
 | 총 횟수 | 236 |

언뜻 보기에 때때로 응답 시간이 두 배(이상)로 DS4 클러스터가 D4 클러스터보다 쿼리를 잘 수행하지 못하는 것처럼 보입니다. 하지만 전부를 알려주지는 않습니다. 다음 테이블에서는 각 클러스터에서 수행된 수집 작업의 수를 보여줍니다(각 작업이 1000개의 문서를 로드함).

 프로비전 | 수집 작업 수 |
---------|-------------------------|
 D4 | 264769 |
 DS4 | 503157 |

DS4 클러스터는 테스트하는 동안 D4 클러스터보다 거의 두 배 많은 데이터를 로드할 수 있었습니다. 따라서 각 작업에 대한 응답 시간을 분석하는 경우 각 쿼리가 스캔해야 하는 문서 수 및 반환되는 문서 수를 고려해야 합니다. 다음은 인덱스의 문서 볼륨이 지속적으로 성장하는 경우 동적 수치입니다. 수집 작업에서 동시에 수행되는 I/O의 양을 무시하는 경우 비교 정보를 제공하기 위해 503137을 264769(각 클러스터에서 수행된 수집 작업의 수)로 나눌 수 없으며 결과를 D4 클러스터에서 수행한 각 쿼리에 대한 평균 응답 시간으로 곱할 수 없습니다. 대신에 기록되는 데이터의 실제 크기를 측정하고 테스트의 진행에 따라 디스크에서 읽어야 합니다. JMeter 테스트 계획은 각 노드에 대한 이 정보를 캡처합니다. 요약된 결과는 다음과 같습니다.

 프로비전 | 각 작업에 의해 작성된/읽은 평균 바이트 |
---------|----------------------------------------------|
 D4 | 13471557 |
 DS4 | 24643470 |

이 데이터는 DS4 클러스터가 D4 클러스터의 1.8 배 정도로 I/O 비율을 유지할 수 있음을 보여줍니다. 디스크의 특성 외에도 다른 모든 리소스가 동일하다는 점을 볼 때 HDD 대신 SSD를 사용으로 인한 차이가 분명합니다.

이 결론을 증명하기 위해 다음과 같은 그래프는 시간에 따라 각 클러스터에서 수행된 I/O를 보여줍니다.

![](./media/guidance-elasticsearch/query-performance2.png)

<!-- -->

***그림 2. D4 및 DS4 클러스터 디스크 작업***

D4 클러스터에 대한 그래프는 테스트의 첫 번째 절반 중에 특히 중요한 변형을 표시합니다. I/O 속도를 줄이기 위한 제한 때문일 가능성이 있었습니다. 테스트의 초기 단계에서 쿼리는 데이터를 거의 분석하지 않기에 신속하게 실행할 수 있습니다. 따라서 D4 클러스터의 디스크는 IOPS 용량에 근접하게 작동될 수 있지만 각 I/O 작업은 많은 데이터를 반환할 수 없을 것입니다. DS4 클러스터는 높은 IOPS 속도를 지원할 수 있고 동일한 수준의 제한 문제가 발생하지 않습니다. I/O 속도는 일반적입니다. 이 이론을 지원하기 위해 그래프의 다음 쌍은 시간에 따라 디스크 I/O에 의해 차단된 CPU를 보여줍니다(그래프에 표시된 디스크 대기 시간은 CPU가 I/O를 기다리는 데 사용한 시간의 비율임).

![](./media/guidance-elasticsearch/query-performance3.png)

***그림 3. D4 및 DS4 클러스터에 대한 CPU 디스크 I/O 대기 시간***

CPU를 차단하기 위해 I/O 작업에 널리 사용되는 다음 두 가지 원인을 이해해야 합니다.

- I/O 하위 시스템은 디스크 간에 데이터를 읽거나 쓸 수 있습니다.

- I/O 하위 시스템은 호스트 환경에 의해 제한될 수 있습니다. HDD를 사용하여 구현된 Azure 디스크는 최대 500 IOPS의 처리량을 포함하며 SSD는 최대 5000 IOPS의 처리량을 포함합니다.


D4 클러스터의 경우 테스트의 상반기 동안 I/O를 기다리는 데 소요된 시간은 I/O 속도를 보여주는 그래프와 반전된 방식과 밀접한 상관 관계가 있습니다. 낮은 I/O의 기간은 CPU의 사용이 차단된 상당한 시간에 해당합니다. I/O가 제한되고 있음을 나타냅니다. 상황이 변경한 클러스터에 더 많은 데이터가 추가되면 I/O 대기 시간에서 테스트 최대치의 두 번째 절반이 I/O 처리량의 최고에 해당합니다. 이 시점에서 실제 I/O를 수행하는 동안 CPU가 차단됩니다. 다시 DS4 클러스터를 사용하면 I/O 대기 시간이 훨씬 고르고 각각의 최대치는 최저치보다 I/O 성능의 동등한 최대치와 일치합니다. 이는 제한이 발생하지 않거나 거의 발생하지 않는다는 것을 의미합니다.

한 가지 고려해야 할 기타 요소가 있습니다. 테스트하는 동안 D4 클러스터는 10584 수집 오류 및 21 쿼리 오류를 생성했습니다. DS4 클러스터에서 테스트는 오류를 생성하지 않았습니다.

## 성능 결과 – 강화

강화 테스트는 DS3, DS4 및 DS14 VM의 6-노드 클러스터에 대해 테스트를 실행하여 수행되었습니다. 이러한 SKU는 DS4 VM이 DS3보다 두 배 많은 CPU 코어 및 메모리를 제공하므로 선택되었으며 DS14 컴퓨터는 4배의 메모리 양을 제공하면서 CPU 리소스를 다시 두 배로 늘립니다. 아래 표에서는 각 SKU의 핵심적인 측면을 비교합니다.

 SKU | CPU 코어 수 | 메모리(GB) | 최대 디스크 IOPS | 최대 대역폭(MB/s)|
------|-------------|-------------|---------------|--------------|
 DS3 | 4 | 14 | 12,800| 128 |
 DS4 | 8 | 28 | 25,600| 256 |
 DS14 | 16 | 112 | 50,000| 512 |

아래 표에서는 작음(DS3), 중간(DS4) 및 큰(DS14) 클러스터에서 실행한 테스트의 결과를 요약합니다. 각 VM은 데이터를 저장하는 데 SSD를 사용했습니다. 각 테스트는 24시간 동안 실행되었습니다.

> **참고**: 이 표는 각 쿼리 유형에 대해 성공한 요청 수를 보고합니다(오류는 포함되지 않음). 각 쿼리 유형에 대해 시도한 요청 수는 테스트 실행 중에 대략 동일합니다. JMeter 테스트 계획은 *테스트 트랜잭션*이라는 단일 단위로 각 쿼리(등급별 수, 시간에 따른 수, 국가별 횟수, 상위 15개 조직, 고유한 조직 수, 고유한 IP 수 및 총 횟수)의 단일 항목을 함께 실행하기 때문입니다(이 트랜잭션은 별도의 스레드로 실행되는 수집 작업을 수행하는 태스크와 별개입니다). 테스트 계획의 각 반복은 단일 테스트 트랜잭션을 수행합니다. 따라서 완료된 테스트 트랜잭션 수는 각 트랜잭션에서 가장 느린 쿼리의 응답 시간에 대한 측정입니다.

| 프로비전 | 작업/쿼리 | 요청 수 | 평균 응답 시간(밀리초) |
|--------------|----------------------------|--------------------|----------------------------|
| 작음(DS3) | 수집 | 207284 | 3328 |
| | 등급별 수 | 18444 | 268 |
| | 시간에 따른 수 | 18444 | 340 |
| | 국가별 횟수 | 18445 | 404 |
| | 상위 15개 조직 | 18439 | 323 |
| | 고유한 조직 수 | 18437 | 338 |
| | 고유한 IP 수 | 18442 | 468 |
| | 총 횟수 | 18428 | 294   
|||||
| 중간(DS4) | 수집 | 503157 | 511 |
| | 등급별 수 | 6958 | 187 |
| | 시간에 따른 수 | 6958 | 411 |
| | 국가별 횟수 | 6958 | 402 |
| | 상위 15개 조직 | 6958 | 307 |
| | 고유한 조직 수 | 6956 | 320 |
| | 고유한 IP 수 | 6955 | 841 |
| | 총 횟수 | 6958 | 236 |
|||||
| 큼(DS14) | 수집 | 502714 | 511 |
| | 등급별 수 | 7041 | 201 |
| | 시간에 따른 수 | 7040 | 298 |
| | 국가별 횟수 | 7039 | 363 |
| | 상위 15개 조직 | 7038 | 244 |
| | 고유한 조직 수 | 7037 | 283 |
| | 고유한 IP 수 | 7037 | 681 |
| | 총 횟수 | 7038 | 200 |

이러한 수치는 이 테스트에서 DS4 및 DS14 클러스터의 성능이 비슷하다는 것을 보여 줍니다. DS3 클러스터의 쿼리 작업에 대한 응답 시간도 알맞게 비교 표시되며 수행된 쿼리 작업 수는 DS4 및 DS14 클러스터에 대한 값을 훨씬 초과합니다. 그러나 수집 속도 및 그에 따라 검색되는 문서 수에 특별히 주목해야 합니다. DS3 클러스터에서는 수집이 훨씬 제한되며 테스트 끝에서 데이터베이스는 다른 두 클러스터 각각에서 읽은 문서의 불과 40%로 제한됩니다. DS4 또는 DS14 VM에 비해 DS3 VM에서 사용 가능한 처리 리소스, 네트워크 및 디스크 대역폭 때문일 수 있습니다. DS4 VM에 DS3 VM보다 2배 많은 가용 리소스가 있고 DS14에 DS4 VM보다 2배의 리소스(메모리는 4배)가 있다는 점을 고려할 때 DS4 및 DS14 클러스터 간에 수집 속도 차이가 DS3 및 DS4 클러스터 간에 발생하는 것보다 매우 적은 이유에 대한 의문이 남습니다. 이것은 Azure VM의 대역폭 제한 및 네트워크 사용률 때문일 수 있습니다. 다음 그래프는 3개 클러스터 모두에 대한 이 데이터를 보여 줍니다.

![](./media/guidance-elasticsearch/query-performance4.png)

***그림 4. *수집 및 쿼리* 테스트를 수행하는 DS3, DS4 및 DS14 클러스터에 대한 네트워크 사용률***

<!-- -->

Azure VM에 사용 가능한 네트워크 대역폭 제한은 게시되지 않으며 다양할 수 있지만 DS4 및 DS14 테스트 모두에 대해 네트워크 작업이 평균 약 2.75GBps에서 안정되는 것으로 나타나는 것을 통해 제한에 도달했으며 처리량을 제한하는 주요 요소임을 알 수 있습니다. DS3 클러스터의 경우 네트워크 작업은 상당히 느리므로 기타 리소스의 가용성에 대한 제한 때문에 성능이 저하될 가능성이 높습니다.

수집 작업의 영향을 격리하고 노드 강화에 따라 쿼리 성능이 어떻게 달라지는지를 보여 주기 위해 동일한 노드를 사용하여 쿼리 전용 테스트 집합을 수행했습니다. 다음 표는 각 클러스터에서 얻은 결과를 요약합니다.

> [AZURE.NOTE] *쿼리 전용* 테스트의 쿼리에 의해 실행된 성능 및 요청 수와 *수집 및 쿼리* 테스트로 실행된 성능 및 요청 수를 비교하지 않아야 합니다. 쿼리가 수정되었고 포함된 문서 볼륨이 다르기 때문입니다.

| 프로비전 | 작업/쿼리 | 요청 수 | 평균 응답 시간(밀리초) |
|--------------|----------------------------|--------------------|----------------------------|
| 작음(DS3) | 등급별 수 | 464 | 11758 |
| | 시간에 따른 수 | 464 | 14699 |
| | 국가별 횟수 | 463 | 14075 |
| | 상위 15개 조직 | 464 | 11856 |
| | 고유한 조직 수 | 462 | 12314 |
| | 고유한 IP 수 | 461 | 19898 |
| | 총 횟수 | 462 | 8882  
|||||
| 중간(DS4) | 등급별 수 | 1045 | 4489 |
| | 시간에 따른 수 | 1045 | 7292 |
| | 국가별 횟수 | 1053 | 7564 |
| | 상위 15개 조직 | 1055 | 5066 |
| | 고유한 조직 수 | 1051 | 5231 |
| | 고유한 IP 수 | 1051 | 9228 |
| | 총 횟수 | 1051 | 2180 |
|||||
| 큼(DS14) | 등급별 수 | 1842 | 1927 |
| | 시간에 따른 수 | 1839 | 4483 |
| | 국가별 횟수 | 1838 | 4761 |
| | 상위 15개 조직 | 1842 | 2117 |
| | 고유한 조직 수 | 1837 | 2393 |
| | 고유한 IP 수 | 1837 | 7159 |
| | 총 횟수 | 1837 | 642 |

이번에는 서로 다른 클러스터 간 평균 응답 시간에 대한 추세가 더 명확합니다. 네트워크 사용률은 DS4 및 DS14 클러스터에서 이전에 필요로 했던 2.75GBps(수집 및 쿼리 테스트에서 네트워크 포화 상태)보다 훨씬 낮으며, DS3 클러스터의 경우 1.5GBps보다 훨씬 낮습니다. 실제로 아래 그래프에 표시된 대로 모든 경우에 200MBps에 가깝습니다.

![](./media/guidance-elasticsearch/query-performance5.png)

***그림 5. *쿼리 전용* 테스트를 수행하는 DS3, DS4 및 DS14 클러스터에 대한 네트워크 사용률***

이제 DS3 및 DS4 클러스터에서 제한 요소는 CPU 사용률로 표시되며 이는 대부분 100%에 근접합니다. DS14 클러스터에서 CPU 사용량은 평균적으로 80%보다 약간 넘습니다. 이것은 여전히 높은 비율이지만 사용 가능한 CPU 코어 수가 많을 때의 장점이 명확하게 강조됩니다. 다음 그림은 DS3, DS4 및 DS14 클러스터에 대한 CPU 사용 패턴을 보여 줍니다.

![](./media/guidance-elasticsearch/query-performance6.png)

***그림 6. *쿼리 전용* 테스트를 수행하는 DS3 및 DS14 클러스터에 대한 CPU 사용률***

## 성능 결과 – 규모 확장

노드 수로 시스템 규모를 확장하는 방법을 보여 주기 위해 1개, 3개 및 6개 노드로 구성되는 DS14 클러스터를 사용하여 테스트를 실행했습니다. 이번에는 1억 개의 문서를 사용하고 90분 동안 실행하여 *쿼리 전용* 테스트만 수행했습니다.

> [AZURE.NOTE] 규모 확장이 데이터 수집 작업의 동작에 어떻게 영향을 주는지에 대한 자세한 내용은 [Azure에서 Elasticsearch로 데이터 수집 성능 최대화](https://github.com/mspnp/azure-guidance/blob/master/Elasticsearch-Data-Ingestion-Performance.md) 문서를 참조하세요.

| 프로비전 | 작업/쿼리 | 요청 수 | 평균 응답 시간(밀리초) |
|---------|----------------------------|--------------------|----------------------------|
| 노드 1개 | 등급별 수 | 288 | 6216 |
| | 시간에 따른 수 | 288 | 28933 |
| | 국가별 횟수 | 288 | 29455 |
| | 상위 15개 조직 | 288 | 9058 |
| | 고유한 조직 수 | 287 | 19916 |
| | 고유한 IP 수 | 284 | 54203 |
| | 총 횟수 | 287 | 3333 |
|||||
| 노드 3개 | 등급별 수 | 1194 | 3427 |
| | 시간에 따른 수 | 1194 | 5381 |
| | 국가별 횟수 | 1191 | 6840 |
| | 상위 15개 조직 | 1196 | 3819 |
| | 고유한 조직 수 | 1190 | 2938 |
| | 고유한 IP 수 | 1189 | 12516 |
| | 총 횟수 | 1191 | 1272 |
|||||
| 노드 6개 | 등급별 수 | 1842 | 1927 |
| | 시간에 따른 수 | 1839 | 4483 |
| | 국가별 횟수 | 1838 | 4761 |
| | 상위 15개 조직 | 1842 | 2117 |
| | 고유한 조직 수 | 1837 | 2393 |
| | 고유한 IP 수 | 1837 | 7159 |
| | 총 횟수 | 1837 | 642 |

비선형 방식이기는 하지만, 노드 수에 따라 클러스터의 쿼리 성능이 크게 달라집니다. 3노드 클러스터는 단일 노드 클러스터보다 약 4배 많은 쿼리를 완료하는 반면 6노드 클러스터는 6배까지 처리합니다. 이 비선형성을 설명하기 위해 다음 그래프는 3개 클러스터에서 CPU가 어떻게 사용되는지를 보여 줍니다.

![](./media/guidance-elasticsearch/query-performance7.png)

***그림 7. *쿼리 전용* 테스트를 수행하는 1, 3 및 6-노드 클러스터에 대한 CPU 사용률***

단일 노드 및 3-노드 클러스터는 CPU 바인딩되며 CPU 사용률이 6-노드 클러스터에서 높기는 하지만 사용 가능한 예비 처리 용량이 있습니다. 이 경우 다른 요소는 처리량을 제한할 가능성이 있습니다. 9개 및 12개 노드를 사용한 테스트로 확인할 수 있으며 추가 예비 처리 용량을 보여 줄 수 있습니다.

위 표의 데이터는 쿼리에 대한 평균 응답 시간이 어떻게 달라지는지도 보여 줍니다. 시스템이 특정 유형의 쿼리에 대해 어떻게 확장되는지 테스트할 때 가장 유용합니다. 일부 검색은 다른 검색보다 더 많은 노드로 확장할 때 확실히 훨씬 효율적입니다. 클러스터 증가 시 노드 수와 문서 수 간의 비율 때문일 수 있으며 각 클러스터는 1억 개의 문서를 포함합니다. 데이터 집계와 관련된 검색을 수행할 때 Elasticsearch는 각 노드의 메모리에서 집계 과정의 일부로 검색된 데이터를 처리 및 버퍼링합니다. 더 많은 노드가 있으면 각 노드에서 검색, 버퍼링 및 처리할 데이터가 줄어듭니다.

## 성능 결과 - 복제본 수

*수집 및 쿼리* 테스트는 단일 복제본이 있는 인덱스에 대해 실행되었습니다. 두 개의 복제본으로 구성된 인덱스를 사용하여 6-노드 DS4 및 DS14 클러스터에서 테스트를 반복했습니다. 24시간 동안 모든 테스트를 실행했습니다. 아래 표는 하나 및 두 개의 복제본에 대한 비교 결과를 보여 줍니다.

| 프로비전 | 작업/쿼리 | 평균 응답 시간(밀리초) - 복제본 1개 | 평균 응답 시간(밀리초) - 복제본 2개 | 응답 시간 차이(%) |
|---------|----------------------------|----------------------------------------|-----------------------------------------|-------------------------------|
| DS4 | 수집 | 511 | 655 | +28% |
| | 등급별 수 | 187 | 168 | -10% |
| | 시간에 따른 수 | 411 | 309 | -25% |
| | 국가별 횟수 | 402 | 562 | +40% |
| | 상위 15개 조직 | 307 | 366 | +19% |
| | 고유한 조직 수 | 320 | 378 | +18% |
| | 고유한 IP 수 | 841 | 987 | +17% |
| | 총 횟수 | 236 | 236 | +0% |
||||||
| DS14 | 수집 | 511 | 618 | +21% |
| | 등급별 수 | 201 | 275 | +37% |
| | 시간에 따른 수 | 298 | 466 | +56% |
| | 국가별 횟수 | 363 | 529 | +46% |
| | 상위 15개 조직 | 244 | 407 | +67% |
| | 고유한 조직 수 | 283 | 403 | +42% |
| | 고유한 IP 수 | 681 | 823 | +21% |
| | 총 횟수 | 200 | 221 | +11% |

복제본 수가 증가함에 따라 수집 속도가 감소합니다. Elasticsearch가 각 문서의 추가 복사본을 작성하고 추가 디스크 I/O를 생성 중인 것으로 예상됩니다. 아래 이미지에 표시된 1개 및 2개 복제본이 있는 인덱스에 대한 DS14 클러스터의 그래프로 반영됩니다. 1개 복제본이 있는 인덱스의 경우 평균 I/O 속도는 16896573바이트/초였습니다. 2개의 복제본이 있는 인덱스의 경우 평균 I/O 속도는 33986843바이트/초였으며 이는 2배가 넘는 속도입니다.

![](./media/guidance-elasticsearch/query-performance8.png)

***그림 8. *수집 및 쿼리* 테스트를 수행하는 1개 및 2개 복제본이 있는 노드에 대한 디스크 I/O 속도***

| 프로비전 | 쿼리 | 평균 응답 시간(밀리초) - 복제본 1개 | 평균 응답 시간(밀리초) - 복제본 2개 |
|---------|----------------------------|----------------------------------------|-----------------------------------------|
| DS4 | 등급별 수 | 4489 | 4079 |
| | 시간에 따른 수 | 7292 | 6697 |
| | 국가별 횟수 | 7564 | 7173 |
| | 상위 15개 조직 | 5066 | 4650 |
| | 고유한 조직 수 | 5231 | 4691 |
| | 고유한 IP 수 | 9228 | 8752 |
| | 총 횟수 | 2180 | 1909 |
|||||
| DS14 | 등급별 수 | 1927 | 2330 |
| | 시간에 따른 수 | 4483 | 4381 |
| | 국가별 횟수 | 4761 | 5341 |
| | 상위 15개 조직 | 2117 | 2560 |
| | 고유한 조직 수 | 2393 | 2546 |
| | 고유한 IP 수 | 7159 | 7048 |
| | 총 횟수 | 642 | 708 |

이러한 결과는 DS4 클러스터에 대한 평균 응답 시간이 개선되었지만 DS14 클러스터의 경우 증가했음을 보여 줍니다. 이러한 결과를 해석하는 데 도움이 되도록 각 테스트에 의해 수행된 쿼리 수도 고려해야 합니다.

| 프로비전 | 쿼리 | 수행된 수 - 복제본 1개 | 수행된 수 - 복제본 2개 |
|---------|----------------------------|------------------------------|-------------------------------|
| DS4 | 등급별 수 | 1054 | 1141 |
| | 시간에 따른 수 | 1054 | 1139 |
| | 국가별 횟수 | 1053 | 1138 |
| | 상위 15개 조직 | 1055 | 1141 |
| | 고유한 조직 수 | 1051 | 1136 |
| | 고유한 IP 수 | 1051 | 1135 |
| | 총 횟수 | 1051 | 1136 |
|||||
| DS14 | 등급별 수 | 1842 | 1718 |
| | 시간에 따른 수 | 1839 | 1716 |
| | 국가별 횟수 | 1838 | 1714 |
| | 상위 15개 조직 | 1842 | 1718 |
| | 고유한 조직 수 | 1837 | 1712 |
| | 고유한 IP 수 | 1837 | 1712 |
| | 총 횟수 | 1837 | 1712 |

이 데이터는 평균 응답 시간 감소에 따라 DS4 클러스터에 의해 수행된 쿼리 수가 증가했으나 DS14 클러스터의 경우 그 반대임을 보여 줍니다. 한 가지 중요한 요소는 1-복제본 및 2-복제본 테스트에서 DS4 클러스터의 CPU 사용률이 균등하지 않게 분산되었으며 일부 노드는 100%에 근접한 사용률을 나타내는 반면 일부는 예비 처리 용량을 포함했습니다. 성능 향상은 클러스터 노드 간에 처리를 분산하는 기능이 향상되었기 때문일 가능성이 큽니다. 다음 이미지는 가장 많이 및 적게 사용된 VM(노드 4 및 3) 간에 CPU 처리가 변화된 모습을 보여 줍니다.

![](./media/guidance-elasticsearch/query-performance9.png)

***그림 9. *쿼리 전용* 테스트를 수행하는 DS4 클러스터에서 가장 적게 및 가장 많이 사용된 노드의 CPU 사용률***

DS14 클러스터의 경우 해당되지 않습니다. 두 테스트에 대한 CPU 사용률은 모든 노드에서 낮았으며 두 번째 복제본의 가용성은 장점은 줄고 오버헤드는 늘었습니다.

![](./media/guidance-elasticsearch/query-performance10.png)

***그림 10. *쿼리 전용* 테스트를 수행하는 DS14 클러스터에서 가장 적게 및 가장 많이 사용된 노드의 CPU 사용률***

이러한 결과는 여러 복제본을 사용할 것인지 결정할 때 시스템을 신중하게 벤치마킹해야 함을 보여 줍니다. 각 인덱스에 대한 복제본을 하나 이상 항상 포함해야 하지만(노드가 실패할 경우 데이터 손실 위험을 감수하지 않으려는 경우) 클러스터에 사용 가능한 워크로드 및 하드웨어 리소스에 따라 추가 복제본은 혜택은 적고 시스템에 부담만 줄 수 있습니다.

## 성능 결과 – Doc 값

*수집 및 쿼리* 테스트는 doc 값이 활성화된 상태로 수행되었으며 Elasticsearch가 디스크에 필드를 정렬하는 데 사용되는 데이터를 저장하도록 합니다. 테스트는 비활성화된 doc 값으로 반복되었으므로 Elasticsearch가 필드 데이터를 동적으로 생성하고 메모리에 캐시했습니다. 24시간 동안 모든 테스트를 실행했습니다. 아래 표는 D4, DS4 및 DS14 VM을 사용하여 빌드된 6개 노드의 클러스터에 대해 테스트 실행에 대한 응답 시간을 비교합니다(D4 클러스터는 일반 하드 디스크를 사용하는 반면 DS4 및 DS14 클러스터는 SSD를 사용합니다).

| 프로비전 | 작업/쿼리 | 평균 응답 시간(밀리초) - Doc 값 활성화 | 평균 응답 시간(밀리초) - Doc 값 비활성화 | 응답 시간 차이(%) |
|---------|----------------------------|-------------------------------------------------|--------------------------------------------------|-------------------------------|
| D4 | 수집 | 978 | 835 | -15% |
| | 등급별 수 | 103 | 132 | +28% |
| | 시간에 따른 수 | 134 | 189 | +41% |
| | 국가별 횟수 | 199 | 259 | +30% |
| | 상위 15개 조직 | 137 | 184 | +34% |
| | 고유한 조직 수 | 139 | 197 | +42% |
| | 고유한 IP 수 | 510 | 604 | +18% |
| | 총 횟수 | 89 | 134 | +51% |
||||||
| DS4 | 수집 | 511 | 581 | +14% |
| | 등급별 수 | 187 | 190 | +2% |
| | 시간에 따른 수 | 411 | 409 | -0.5% |
| | 국가별 횟수 | 402 | 414 | +3% |
| | 상위 15개 조직 | 307 | 284 | -7% |
| | 고유한 조직 수 | 320 | 313 | -2% |
| | 고유한 IP 수 | 841 | 955 | +14% |
| | 총 횟수 | 236 | 281 | +19% |
||||||
| DS14 | 수집 | 511 | 571 | +12% |
| | 등급별 수 | 201 | 232 | +15% |
| | 시간에 따른 수 | 298 | 341 | +14% |
| | 국가별 횟수 | 363 | 457 | +26% |
| | 상위 15개 조직 | 244 | 338 | +39% |
| | 고유한 조직 수 | 283 | 350 | +24% |
| | 고유한 IP 수 | 681 | 909 | +33% |
| | 총 횟수 | 200 | 245 | +23% |

다음 표에서는 테스트에 의해 수행된 수집 작업 수를 비교합니다.

| 프로비전 | 수집 작업 수 - Doc 값 활성화 | 수집 작업 수 - Doc 값 비활성화 | 수집 작업 수 차이(%) |
|---------|----------------------------------------------|-----------------------------------------------|-----------------------------------------|
| D4 | 264769 | 408690 | +54% |
| DS4 | 503137 | 578237 | +15% |
| DS14 | 502714 | 586472 | +17% |

문서가 삽입됨에 따라 디스크에 기록되는 데이터가 줄어들어 비활성화된 doc 값으로 수집 속도가 향상됩니다. 성능 향상은 HDD를 사용하여 데이터를 저장하는 D4 VM에서 특히 눈에 띕니다. 이 경우 수집 작업에 대한 응답 시간도 15%까지 감소합니다(이 섹션의 첫 번째 표 참조). doc 값이 활성화된 테스트에서 IOPS 제한 가까이 실행될 가능성 있는 HDD에 대한 압력이 감소했기 때문일 수 있습니다. 자세한 내용은 디스크 유형 테스트를 참조하세요. 다음 그래프는 D4 VM의 I/O 성능을 doc 값이 활성화(값은 디스크에 보관됨)된 경우와 비활성화(값은 메모리에 보관됨)된 경우를 비교합니다.

![](./media/guidance-elasticsearch/query-performance11.png)

***그림 11. doc 값이 활성화 및 비활성화된 D4 클러스터에 대한 디스크 작업***

반면에 SSD를 사용하는 VM에 대한 수집 값은 문서 수가 소량 증가하고 수집 작업의 응답 시간도 증가하는 것으로 나타납니다. 한두 가지의 작은 예외가 있지만 쿼리 응답 시간도 나빠졌습니다. SSD는 doc 값이 활성화된 상태로 IOPS 제한 가까이에 실행될 가능성이 적으므로 성능 변경은 처리 작업이 증가하고 JVM 힙 관리 시 오버헤드가 증가했기 때문일 가능성이 높습니다. doc 값이 활성화된 경우와 비활성화된 경우 CPU 사용률을 비교해 보면 분명히 알 수 있습니다. 다음 그래프는 DS4 클러스터에 대한 이 데이터를 강조 표시합니다. 여기서 CPU 사용률의 대부분은 30%-40% 대역(doc 값 활성화)에서 40%-50% 대역(doc 값 비활성화)으로 이동합니다(DS14 클러스터는 유사한 추세를 나타냄).

![](./media/guidance-elasticsearch/query-performance12.png)

***그림 12. doc 값이 활성화 및 비활성화된 DS4 클러스터에 대한 CPU 사용률***

쿼리 성능에서 doc 값의 효과를 데이터 수집과 구분하기 위해 doc 값이 활성화 및 비활성화된 상태로 DS4 및 DS14 클러스터에 대해 쿼리 전용 테스트 쌍을 수행했습니다. 아래 표는 이러한 테스트 결과를 요약하여 보여 줍니다.

| 프로비전 | 작업/쿼리 | 평균 응답 시간(밀리초) - Doc 값 활성화 | 평균 응답 시간(밀리초) - Doc 값 비활성화 | 응답 시간 차이(%) |
|---------|----------------------------|-------------------------------------------------|--------------------------------------------------|-------------------------------|
| DS4 | 등급별 수 | 4489 | 3736 | -16% |
| | 시간에 따른 수 | 7293 | 5459 | -25% |
| | 국가별 횟수 | 7564 | 5930 | -22% |
| | 상위 15개 조직 | 5066 | 3874 | -14% |
| | 고유한 조직 수 | 5231 | 4483 | -2% |
| | 고유한 IP 수 | 9228 | 9474 | +3% |
| | 총 횟수 | 2180 | 1218 | -44% |
||||||
| DS14 | 등급별 수 | 1927 | 2144 | +11% |
| | 시간에 따른 수 | 4483 | 4337 | -3% |
| | 국가별 횟수 | 4761 | 4840 | +2% |
| | 상위 15개 조직 | 2117 | 2302 | +9% |
| | 고유한 조직 수 | 2393 | 2497 | +4% |
| | 고유한 IP 수 | 7159 | 7639 | +7% |
| | 총 횟수 | 642 | 633 | -1% |

doc 값은 기본적으로 Elasticsearch 버전 2.0 이상으로 활성화됩니다. DS4 클러스터를 다루는 테스트에서 doc 값을 비활성화하면 전체적으로 긍정적인 효과를 주는 것으로 파악되지만 DS14 클러스터(doc 값이 비활성화된 경우 두 사례에서 극히 미미하게 성능 향상됨)의 경우 일반적으로 그렇지 않습니다.

DS4 클러스터의 경우 두 경우에서 CPU 사용률은 두 테스트 기간 동안 100%에 근접했으며 이는 클러스터가 CPU 바인딩되었음을 나타냅니다. 그러나 처리된 쿼리 수는 7369에서 5894(20%)로 감소했습니다. 아래 표를 참조하세요. doc 값이 비활성화된 경우 Elasticsearch는 메모리에 동적으로 필드 데이터를 생성하고 이 경우 CPU 능력을 사용합니다. 이 구성은 디스크 I/O 속도를 줄이지만 이미 최대 기능 가까이 실행 중인 CPU에 부담을 증가시키므로 이 경우 doc 값을 비활성화하면 쿼리가 빨라지지만 극히 일부입니다.

doc 값을 사용 및 사용하지 않는 DS14 테스트에서 CPU 작업은 높지만 100%는 아닙니다. 수행된 쿼리 수는 doc 값이 활성화된 테스트에서 약간 높습니다(약 4%).

| 프로비전 | 쿼리 | 수행된 수 - Doc 값 활성화 | 수행된 수 - Doc 값 비활성화 |
|---------|----------------------------|---------------------------------------|----------------------------------------|
| DS4 | 등급별 수 | 1054 | 845 |
| | 시간에 따른 수 | 1054 | 844 |
| | 국가별 횟수 | 1053 | 842 |
| | 상위 15개 조직 | 1055 | 846 |
| | 고유한 조직 수 | 1051 | 839 |
| | 고유한 IP 수 | 1051 | 839 |
| | 총 횟수 | 1051 | 839  
||||| |
| DS14 | 등급별 수 | 1772 | 1842 |
| | 시간에 따른 수 | 1772 | 1839 |
| | 국가별 횟수 | 1770 | 1838 |
| | 상위 15개 조직 | 1773 | 1842 |
| | 고유한 조직 수 | 1769 | 1837 |
| | 고유한 IP 수 | 1768 | 1837 |
| | 총 횟수 | 1769 | 1837 |

## 성능 결과 - 분할된 데이터베이스 요청 캐시

각 노드의 메모리에서 캐싱 인덱스 데이터가 성능에 어떻게 영향을 줄 수 있는지 보여 주기 위해 인덱스 캐싱이 활성화된 상태로 DS4 및 DS14 6노드 클러스터에서 *쿼리 및 수집* 테스트를 수행했습니다. 자세한 내용은 [분할된 데이터베이스 요청 캐시 사용](#using-the-shard-request-cache) 섹션을 참조하세요. 이 결과는 동일한 인덱스를 사용하지만 인덱스 캐싱이 비활성화된 이전 테스트에서 생성한 결과와 비교하였습니다. 아래 표는 결과를 요약하여 보여 줍니다. 데이터는 테스트의 처음 90분만 포함하도록 단축되었으며 이 시점에 추세 비교가 명확해졌고 테스트를 계속 진행하면 더 많은 정보를 얻을 수 있을 것입니다.

| 프로비전 | 작업/쿼리 | 평균 응답 시간(밀리초) - 인덱스 캐시 비활성화 | 평균 응답 시간(밀리초) - 인덱스 캐시 활성화 | 응답 시간 차이(%) |
|---------|----------------------------|---------------------------------------------------|--------------------------------------------------|-------------------------------|
| DS4 | 수집 | 504 | 3260 | +547% |
| | 등급별 수 | 218 | 273 | +25% |
| | 시간에 따른 수 | 450 | 314 | -30% |
| | 국가별 횟수 | 447 | 397 | -11% |
| | 상위 15개 조직 | 342 | 317 | -7% |
| | 고유한 조직 수 | 370 | 324 | -12%% |
| | 고유한 IP 수 | 760 | 355 | -53% |
| | 총 횟수 | 258 | 291 | +12% |
||||||
| DS14 | 수집 | 503 | 3365 | +569% |
| | 등급별 수 | 234 | 262 | +12% |
| | 시간에 따른 수 | 357 | 298 | -17% |
| | 국가별 횟수 | 416 | 383 | -8% |
| | 상위 15개 조직 | 272 | 324 | -7% |
| | 고유한 조직 수 | 330 | 321 | -3% |
| | 고유한 IP 수 | 674 | 352 | -48% |
| | 총 횟수 | 227 | 292 | +29% |

이 데이터는 두 개의 관심 지점을 보여 줍니다.

-  데이터 수집 속도는 인덱스 캐싱을 활성화하면 크게 감소하는 것으로 파악되었습니다.

-  인덱스 캐싱으로 반드시 모든 유형의 쿼리에서 응답 시간이 향상되는 것은 아니며 등급별 수 및 총 횟수 쿼리로 수행된 작업처럼 특정 집계 작업에서 악영향을 줄 수 있습니다.
 

시스템에서 이러한 동작이 나타나는 이유를 이해하려면 테스트 실행 동안 각 사례에서 성공적으로 수행된 쿼리 수를 고려해야 합니다. 다음 표에서는 이 데이터를 요약합니다.

| 프로비전 | 작업/쿼리 | 쿼리당 작업 수 - 인덱스 캐시 비활성화 | 쿼리당 작업 수 - 인덱스 캐시 활성화 |
|---------|----------------------------|-------------------------------------------------|------------------------------------------------|
| DS4 | 수집 | 38611 | 13232 |
| | 등급별 수 | 524 | 18704 |
| | 시간에 따른 수 | 523 | 18703 |
| | 국가별 횟수 | 522 | 18702 |
| | 상위 15개 조직 | 521 | 18706 |
| | 고유한 조직 수 | 521 | 18700 |
| | 고유한 IP 수 | 521 | 18699 |
| | 총 횟수 | 521 | 18701  
|||| |
| DS14 | 수집 | 38769 | 12835 |
| | 등급별 수 | 528 | 19239 |
| | 시간에 따른 수 | 528 | 19239 |
| | 국가별 횟수 | 528 | 19238 |
| | 상위 15개 조직 | 527 | 19240 |
| | 고유한 조직 수 | 524 | 19234 |
| | 고유한 IP 수 | 524 | 19234 |
| | 총 횟수 | 527 | 19236 |

캐싱이 활성화되었을 때 수집 속도는 캐싱이 비활성화되었을 때의 약 1/3이지만 수행된 쿼리 수는 34배 증가한 것을 볼 수 있습니다. 디스크 I/O 만큼 쿼리가 더 이상 발생하지 않으며 디스크 리소스를 두고 경쟁할 필요가 없습니다. 아래 그림 13에 있는 그래프에 이 내용이 반영되어 있으며 여기서 4가지 모든 사례에 대해 I/O 작업을 비교합니다.

![](./media/guidance-elasticsearch/query-performance13.png)

***그림 13. 인덱스 캐싱이 비활성화 및 활성화된 *수집 및 쿼리* 테스트에 대한 디스크 I/O 작업***

디스크 I/O 감소는 I/O가 완료되는 데 소요되는 CPU의 대기 시간이 감소됨을 의미합니다. 이 내용은 그림 14에 강조 표시되어 있습니다.

![](./media/guidance-elasticsearch/query-performance14.png)

***그림 14. 인덱스 캐싱이 비활성화 및 활성화된 *수집 및 쿼리* 테스트에 대해 디스크 I/O가 완료되는 데 소요되는 CPU의 대기 시간***

디스크 I/O 감소는 Elasticsearch에서 메모리에 보관된 데이터에서 쿼리를 서비스하는 데 훨씬 많은 시간을 소요할 수 있음을 의미합니다. 따라서 CPU 사용률이 증가하며 4가지 모든 사례에 CPU 사용률을 확인해 보면 명확하게 나타납니다. 아래 그래프는 캐싱이 활성화되었을 때 CPU 사용률이 더 지속됨을 보여 줍니다.

![](./media/guidance-elasticsearch/query-performance15.png)

***그림 15. 인덱스 캐싱이 비활성화 및 활성화된 *수집 및 쿼리* 테스트에 대한 CPU 사용률***

두 시나리오에서 테스트 기간 동안 네트워크 I/O의 볼륨은 대체로 유사했습니다. 캐싱을 사용하지 않는 테스트는 테스트 기간 중에 점진적인 저하를 나타냈지만 이러한 테스트를 더 오래 24시간 동안 실행한 결과 이 통계 정보가 약 2.75GBps에서 안정되는 것으로 나타났습니다. 아래 이미지는 DS4 클러스터에 대해 이 데이터를 보여 줍니다(DS14 클러스터에 대한 데이터와 매우 유사했음).

![](./media/guidance-elasticsearch/query-performance16.png)

***그림 16. 인덱스 캐싱이 비활성화 및 활성화된 *수집 및 쿼리* 테스트에 대한 네트워크 트래픽 볼륨***

[강화](#performance-results-scaling-up) 테스트에 설명된 대로 Azure VM의 네트워크 대역폭 제한은 게시되지 않으며 다양할 수 있지만 보통 수준의 CPU 및 디스크 작업은 네트워크 사용률이 이 시나리오에서 제한 요소일 수 있음을 제안합니다.

캐싱은 데이터가 가끔 변경되는 시나리오에 보다 적합합니다. 이 시나리오에서는 캐싱의 영향을 강조 표시하기 위해 캐싱이 활성화된 *쿼리 전용* 테스트를 수행했습니다. 결과가 아래에 표시됩니다(이 테스트는 약 90분 동안 실행되었으며 테스트되는 인덱스에는 1억 개의 문서가 포함되었음).

| 프로비전 | 쿼리 | 평균 응답 시간(밀리초) | 수행된 쿼리 수 |
|---------|----------------------------|----------------------------|-------------------------|
| | | **캐시 사용 안 함** | **캐시 사용함** |
| DS4 | 등급별 수 | 4489 | 210 |
| | 시간에 따른 수 | 7292 | 211 |
| | 국가별 횟수 | 7564 | 231 |
| | 상위 15개 조직 | 5066 | 211 |
| | 고유한 조직 수 | 5231 | 211 |
| | 고유한 IP 수 | 9228 | 218 |
| | 총 횟수 | 2180 | 210  
|||| |
| DS14 | 등급별 수 | 1927 | 211 |
| | 시간에 따른 수 | 4483 | 219 |
| | 국가별 횟수 | 4761 | 236 |
| | 상위 15개 조직 | 2117 | 212 |
| | 고유한 조직 수 | 2393 | 212 |
| | 고유한 IP 수 | 7159 | 220 |
| | 총 횟수 | 642 | 211 |

캐시되지 않은 테스트의 성능이 달라지는 것은 DS4 및 DS14 VM 간에 사용 가능한 리소스가 다르기 때문입니다. 두 경우의 캐시된 테스트에서 데이터가 메모리에서 직접 검색됨에 따라 평균 응답 시간이 크게 떨어졌습니다. 캐시되지 않은 결과에서는 상당한 차이가 나타나는 반면 캐시된 DS4 및 DS14 클러스터 테스트에 대한 응답 시간은 매우 유사한 것 또한 주목할 가치가 있습니다. 또한 각 테스트 내에서 각 쿼리에 대한 응답 시간 간에 차이가 매우 적으며 모두 약 220ms 소요됩니다. 일단 모든 데이터가 메모리에 있고 적은 I/O 또는 처리가 필요하므로 두 클러스터에 대한 디스크 I/O 속도 및 CPU 사용률은 매우 낮았습니다. 네트워크 I/O 속도는 캐시되지 않은 테스트와 유사했으며 이 테스트에서 네트워크 대역폭이 제한 요소일 수 있음을 확인해 줍니다. 다음 그래프는 DS4 클러스터에 대해 이 정보를 표시합니다. DS14 클러스터의 프로필이 매우 유사했습니다.

![](./media/guidance-elasticsearch/query-performance17.png)

***그림 17. 인덱스 캐싱이 활성화된 *쿼리 전용* 테스트에 대한 디스크 I/O, CPU 사용률 및 네트워크 사용률***

위 표에 있는 수치는 DS14 아키텍처를 사용할 경우 DS4를 사용할 때보다 약간의 이점이 있음을 보여 줍니다. 실제로 DS14 클러스터에 의해 생성된 샘플 수는 DS4 클러스터의 것보다 5% 미만이지만 이는 시간에 따라 약간 달라질 수 있는 네트워크 제한 때문일 수 있습니다.

## 성능 결과 - 분할된 데이터베이스 수

이 테스트의 목적은 인덱스에 대해 생성된 분할된 데이터베이스 수가 해당 인덱스의 쿼리 성능에 어떤 영향을 주는지 여부를 결정하는 것입니다.

이전에 수행한 별도의 테스트에서는 인덱스의 분할된 데이터베이스 구성이 데이터 수집 속도에 영향을 줄 수 있는 것으로 나타냈습니다. 이 테스트는 [Azure에서 Elasticsearch로 데이터 수집 성능 최대화](https://github.com/mspnp/azure-guidance/blob/master/Elasticsearch-Data-Ingestion-Performance.md) 문서에 설명되어 있습니다. 쿼리 성능을 확인하기 위해 수행된 테스트는 유사한 방법론을 따랐으나 DS14 하드웨어에서 실행 중인 6-노드 클러스터로 제한되었습니다. 이 방법은 변수 수를 최소화하는 데 도움이 되므로 성능상 차이는 분할된 데이터베이스 볼륨으로 인한 것입니다.

*쿼리 전용* 테스트는 7, 13, 23, 37 및 61개의 기본 분할된 데이터베이스로 구성된 동일한 인덱스의 복사본에서 수행되었습니다. 인덱스는 1억 개의 문서와 단일 복제본을 포함하며 클러스터 간 분할된 데이터베이스 수는 2배입니다. 각 테스트는 90분 동안 실행되었습니다. 다음 표에서는 이 결과를 요약합니다. 표시된 평균 응답 시간은 JMeter 테스트 트랜잭션에 대한 응답 시간으로, 테스트의 각 반복으로 수행된 전체 쿼리 집합을 포함합니다. 자세한 내용은 [성능 결과 - 강화](#performance-results-scaling-up) 섹션의 참고를 참조하세요.

| 분할된 데이터베이스 수 | 분할된 데이터베이스 레이아웃(노드당 분할된 데이터베이스. 복제본 포함) | 수행된 쿼리 수 | 평균 응답 시간(밀리초) |
|---------------------------|----------------------------------------------------|-----------------------------|------------------------|
| 7(복제본을 포함하면 14) | 3-2-2-2-2-3 | 7461 | 40524 |
| 13(26) | 5-4-5-4-4-4 | 7369 | 41055 |
| 23(46) | 7-8-8-7-8-8 | 14193 | 21283 |
| 37(74) | 13-12-12-13-12-12 | 13399 | 22506 |
| 61(122) | 20-21-20-20-21-20 | 14743 | 20445 |

이러한 결과는 13(26)개 분할된 데이터베이스 클러스터와 23(46)개 분할된 데이터베이스 클러스터 간에 성능상의 상당한 차이가 있음을 나타냅니다. 처리량은 거의 두 배이며 응답 시간은 반으로 줄어듭니다. 이것은 VM 구성 및 Elasticsearch에서 검색 요청을 처리하는 데 사용하는 구조 때문일 가능성이 높습니다. 검색 요청은 큐에 대기되고 각 검색 요청은 단일 검색 스레드로 처리됩니다. Elasticsearch 노드에 의해 생성된 검색 스레드 수는 노드를 호스팅하는 컴퓨터에서 사용 가능한 프로세서 수에 따라 결정됩니다. 이 결과는 한 노드에서 4개 또는 5개의 분할된 데이터베이스만 있고 처리 리소스가 완전히 활용되지 않음을 보여 줍니다. 이 테스트를 실행하는 동안 CPU 사용률을 살펴보면 알 수 있습니다. 다음 이미지는 13(26)개 분할된 데이터베이스 테스트를 수행하는 동안 Marvel에서 가져온 스냅숏입니다.

![](./media/guidance-elasticsearch/query-performance18.png)

***그림 18. 7(14)개 분할된 데이터베이스 클러스터에서 *쿼리 전용* 테스트에 대한 CPU 사용률***

이 수치를 23(46)개 분할된 데이터베이스 테스트와 비교합니다.

![](./media/guidance-elasticsearch/query-performance19.png)

***그림 19. 23(46)개 분할된 데이터베이스 클러스터에서 *쿼리 전용* 테스트에 대한 CPU 사용률***

23(46)개 분할된 데이터베이스 테스트에서 CPU 사용률이 훨씬 높습니다. 각 노드는 7 또는 8개의 분할된 데이터베이스를 포함합니다. DS14 아키텍처는 16개의 프로세서를 제공하고 추가 분할된 데이터베이스로 Elasticsearch는 이 코어 수를 보다 잘 활용할 수 있습니다. 위의 표에 있는 수치는 분할된 데이터베이스 수를 이 지점을 이상으로 늘리면 성능이 약간 개선될 수 있음을 보여 주지만 많은 분할된 데이터베이스를 유지 관리하는 추가 오버헤드가 발생할 수 있으므로 이를 감안해야 합니다. 이러한 테스트에 대한 최적 지점은 노드당 최적의 분할된 데이터베이스 수가 각 노드에 사용 가능한 프로세서 코어 수의 절반일 경우를 의미합니다. 단, 이러한 결과는 쿼리를 실행할 경우만 얻을 수 있음을 유의합니다. 시스템에서 데이터를 가져오는 경우 분할이 데이터 수집 작업의 성능에 어떻게 영향을 줄 수 있는지도 고려해야 합니다. 이에 대한 자세한 내용은 [Azure에서 Elasticsearch로 데이터 수집 성능 최대화](https://github.com/mspnp/azure-guidance/blob/master/Elasticsearch-Data-Ingestion-Performance.md) 문서를 참조하세요.

## 요약

Elasticsearch는 인덱스를 구성하고 대규모 쿼리 작업을 지원하도록 튜닝하는 데 사용할 수 있는 다양한 옵션을 제공합니다. 이 문서에서는 쿼리 용도로 데이터베이스를 튜닝하는 데 사용할 수 있는 몇 가지 일반적인 구성 및 기술을 요약합니다. 그러나 빠른 검색을 지원하도록 데이터베이스를 최적화하는 것과 대용량 데이터 수집을 지원하는 것 간에 균형을 유지해야 한다는 것을 알아야 합니다. 경우에 따라 쿼리에 좋은 것이 삽입 작업에는 나쁜 영향을 줄 수 있으며 그 반대의 경우도 있습니다. 혼합된 워크로드에 노출된 시스템에서 어디에 균형을 둘지 평가하고 시스템 매개 변수를 적절히 조정해야 합니다.

또한 다양한 구성 및 기술의 적용 가능 여부는 데이터 구조 및 시스템이 구성된 하드웨어 제한(또는 기타)에 따라 다를 수 있습니다. 이 문서에 표시된 많은 테스트에서는 어떤 하드웨어 플랫폼을 선택하는지에 따라 처리량에 어떤 영향을 줄 수 있으며 특정 사례에서 일부 전략이 도움이 될 수 있지만 다른 요소에는 나쁜 영향을 줄 수 있음을 보여 줍니다. 중요한 점은 사용할 수 있는 옵션을 이해한 후 사용자 고유의 데이터를 사용하여 철저히 벤치마킹을 수행하여 최적의 조합을 찾아내는 것입니다.

마지막으로, Elasticsearch 데이터베이스는 반드시 정적 항목은 아니라는 것을 기억하세요. 시간이 지남에 따라 증가할 가능성이 있으며 데이터를 구성하는 데 사용된 전략을 정기적으로 수정해야 할 수 있습니다. 예를 들어, 추가 분할된 데이터베이스로 데이터를 강화, 규모 확장 또는 다시 인덱싱해야 할 수 있습니다. 시스템의 크기와 복잡성이 증가함에 따라 지속적으로 성능을 테스트를 준비하여 고객에게 보증하는 SLA를 계속 충족하는지 확인해야 합니다.

## 부록: 쿼리 및 집계 성능 테스트

이 부록에서는 Elasticsearch 클러스터에 대해 수행하는 성능 테스트를 설명합니다. 별도의 VM 집합에서 실행되는 JMeter를 사용하여 테스트를 실행했습니다. 테스트 환경 구성에 대한 자세한 내용은 방법: Elasticsearch에 대한 성능 테스트 환경 만들기 문서에 설명되어 있습니다. 직접 테스트를 수행하려면 이 부록의 지침에 따라 고유한 JMeter 테스트 계획을 수동으로 만들거나 별도로 제공되는 자동화된 테스트 스크립트를 사용할 수 있습니다. 자세한 내용은 방법: 자동화된 Elasticsearch 쿼리 테스트 실행을 참조하세요.

대규모 문서 업로드를 동시에 수행하는 동안 데이터 쿼리 워크로드에서 아래 설명된 쿼리 집합을 수행했습니다(데이터는 JUnit 테스트를 사용하여 업로드했으며 [Azure에서 Elasticsearch로 데이터 수집 성능 최대화](https://github.com/mspnp/azure-guidance/blob/master/Elasticsearch-Data-Ingestion-Performance.md) 문서에 설명된 데이터 수집 테스트와 동일한 방법을 따름). 이 워크로드의 목적은 검색이 수행되는 동안 새 데이터가 계속 추가되는 프로덕션 환경을 시뮬레이션하는 것이었습니다. 쿼리는 문서에서 최근 15분 동안 추가된 가장 최근 데이터만 검색하도록 구성되었습니다.

각 문서는 이름이 *idx*인 단일 인덱스에 저장되며 형식은 *doc*입니다. 인덱스를 만드는 데 다음 HTTP 요청을 사용할 수 있습니다. 많은 테스트에서 *number\_of\_replicas* 및 *number\_of\_shards* 설정은 아래 표시된 값에서 다양하게 설정할 수 있습니다. 또한 doc 값보다는 fielddata를 사용한 테스트에서 각 속성은 *"doc\_values" : false* 특성으로 주석이 지정되어 있습니다.

> **중요**. 각 테스트가 실행되기 전에 인덱스가 삭제되고 다시 작성되었습니다.

``` http
PUT /idx
{  
    "settings" : {
        "number_of_replicas": 1,
        "refresh_interval": "30s",
        "number_of_shards": "5",
        "index.translog.durability": "async"    
    },
    "doc": {
        "mappings": {
            "event": {
                "_all": {
                    "enabled": false
                },
                "_timestamp": {
                    "enabled": true,
                    "store": true,
                    "format": "date_time"
                },
                "properties": {
                    "Organization": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "CustomField1": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "CustomField2": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "CustomField3": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "CustomField4": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "CustomField5": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "DateTimeReceivedUtc": {
                        "type": "date",
                        "format": "dateOptionalTime"
                    },
                    "Host": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "HttpMethod": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "HttpReferrer": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "HttpRequest": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "HttpUserAgent": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "HttpVersion": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "OrganizationName": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "SourceIp": {
                        "type": "ip"
                    },
                    "SourceIpAreaCode": {
                        "type": "long"
                    },
                    "SourceIpAsnNr": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "SourceIpBase10": {
                        "type": "long"
                    },
                    "SourceIpCity": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "SourceIpCountryCode": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "SourceIpLatitude": {
                        "type": "double"
                    },
                    "SourceIpLongitude": {
                        "type": "double"
                    },
                    "SourceIpMetroCode": {
                        "type": "long"
                    },
                    "SourceIpPostalCode": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "SourceIpRegion": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "SourceLatLong": {
                        "type": "geo_point",
                        "doc_values": true,
                        "lat_lon": true,
                        "geohash": true
                    },
                    "SourcePort": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "SourcedFrom": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "TargetIp": {
                        "type": "ip"
                    },
                    "TargetPort": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "Rating": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "UseHumanReadableDateTimes": {
                        "type": "boolean"
                    }
                }
            }
        }
    }
}
```

다음 쿼리가 테스트로 수행되었습니다.
* 최근 15분 동안 각 등급 값을 가진 문서가 입력된 수는?

  ```http
  GET /idx/doc/_search
  {
    "query": {
      "bool": {
        "must": [
          {
            "range": {
              "DateTimeReceivedUtc": {
                "gte": "now-15m",
                "lte": "now"
              }
            }
          }
        ],
        "must_not": [],
        "should": []
      }
    },
    "from": 0,
    "size": 0,
    "aggs": {
      "2": {
        "terms": {
          "field": "Rating",
          "size": 5,
          "order": {
            "_count": "desc"
          }
        }
      }
    }
  }
  ```

* 최근 15분 동안 5분 간격으로 추가된 문서 수는?

  ```http
  GET /idx/doc/_search
  {
    "query": {
      "bool": {
        "must": [
          {
            "range": {
              "DateTimeReceivedUtc": {
                "gte": "now-15m",
                "lte": "now"
              }
            }
          }
        ],
        "must_not": [],
        "should": []
      }
    },
    "from": 0,
    "size": 0,
    "sort": [],
    "aggs": {
      "2": {
        "date_histogram": {
          "field": "DateTimeReceivedUtc",
          "interval": "5m",
          "time_zone": "America/Los_Angeles",
          "min_doc_count": 1,
          "extended_bounds": {
            "min": "now-15m",
            "max": "now"
          }
        }
      }
    }
  }
  ```

* 최근 15분 동안 각 국가에 추가된 등급별 문서 수는?

  ```HTTP
  GET /idx/doc/_search
  {
    "query": {
      "filtered": {
        "query": {
          "query_string": {
            "query": "*",
            "analyze_wildcard": true
          }
        },
        "filter": {
          "bool": {
            "must": [
              {
                "query": {
                  "query_string": {
                    "query": "*",
                    "analyze_wildcard": true
                  }
                }
              },
              {
                "range": {
                  "DateTimeReceivedUtc": {
                    "gte": "now-15m",
                    "lte": "now"
                  }
                }
              }
            ],
            "must_not": []
          }
        }
      }
    },
    "size": 0,
    "aggs": {
      "2": {
        "terms": {
          "field": "Rating",
          "size": 5,
          "order": {
            "_count": "desc"
          }
        },
        "aggs": {
          "3": {
            "terms": {
              "field": "SourceIpCountryCode",
              "size": 15,
              "order": {
                "_count": "desc"
              }
            }
          }
        }
      }
    }
  }
  ```

* 최근 15분 동안 문서에 자주 추가된 15개의 조직은?

  ```http
  GET /idx/doc/_search
  {
    "query": {
      "filtered": {
        "query": {
          "query_string": {
            "query": "*",
            "analyze_wildcard": true
          }
        },
        "filter": {
          "bool": {
            "must": [
              {
                "query": {
                  "query_string": {
                    "query": "*",
                    "analyze_wildcard": true
                  }
                }
              },
              {
                "range": {
                  "DateTimeReceivedUtc": {
                    "gte": "now-15m",
                    "lte": "now"
                  }
                }
              }
            ],
            "must_not": []
          }
        }
      }
    },
    "size": 0,
    "aggs": {
      "2": {
        "terms": {
          "field": "Organization",
          "size": 15,
          "order": {
            "_count": "desc"
          }
        }
      }
    }
  }
  ```

* 최근 15분 동안 문서에 추가된 다른 조직은?

  ```http
  GET /idx/doc/_search
  {
    "query": {
      "filtered": {
        "query": {
          "query_string": {
            "query": "*",
            "analyze_wildcard": true
          }
        },
        "filter": {
          "bool": {
            "must": [
              {
                "query": {
                  "query_string": {
                    "query": "*",
                    "analyze_wildcard": true
                  }
                }
              },
              {
                "range": {
                  "DateTimeReceivedUtc": {
                    "gte": "now-15m",
                    "lte": "now"
                  }
                }
              }
            ],
            "must_not": []
          }
        }
      }
    },
    "size": 0,
    "aggs": {
      "2": {
        "cardinality": {
          "field": "Organization"
        }
      }
    }
  }
  ```

* 최근 15분 동안 추가된 문서 수는?

  ```http
  GET /idx/doc/_search
  {
    "query": {
      "filtered": {
        "query": {
          "query_string": {
            "query": "*",
            "analyze_wildcard": true
          }
        },
        "filter": {
          "bool": {
            "must": [
              {
                "query": {
                  "query_string": {
                    "analyze_wildcard": true,
                    "query": "*"
                  }
                }
              },
              {
                "range": {
                  "DateTimeReceivedUtc": {
                    "gte": "now-15m",
                    "lte": "now"
                  }
                }
              }
            ],
            "must_not": []
          }
        }
      }
    },
    "size": 0,
    "aggs": {}
  }
  ```

* 최근 15분 동안 문서에 추가된 SourceIp 값은?

  ```http
  GET /idx/doc/_search
  {
    "query": {
      "filtered": {
        "query": {
          "query_string": {
            "query": "*",
            "analyze_wildcard": true
          }
        },
        "filter": {
          "bool": {
            "must": [
              {
                "query": {
                  "query_string": {
                    "query": "*",
                    "analyze_wildcard": true
                  }
                }
              },
              {
                "range": {
                  "DateTimeReceivedUtc": {
                    "gte": "now-15m",
                    "lte": "now"
                  }
                }
              }
            ],
            "must_not": []
          }
        }
      }
    },
    "size": 0,
    "aggs": {
      "2": {
        "cardinality": {
          "field": "SourceIp"
        }
      }
    }
  }
  ```

<!---HONumber=AcomDC_0302_2016-->