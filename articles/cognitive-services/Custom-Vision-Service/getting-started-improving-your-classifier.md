---
title: 분류자 개선 - Custom Vision Service
titlesuffix: Azure Cognitive Services
description: 분류자의 품질을 개선하는 방법을 알아봅니다.
services: cognitive-services
author: PatrickFarley
manager: cgronlun
ms.service: cognitive-services
ms.component: custom-vision
ms.topic: conceptual
ms.date: 07/05/2018
ms.author: pafarley
ms.openlocfilehash: 2bee7f0af98bf03a13e376dea9dbf083b3f61815
ms.sourcegitcommit: 1aacea6bf8e31128c6d489fa6e614856cf89af19
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 10/16/2018
ms.locfileid: "49340293"
---
# <a name="how-to-improve-your-classifier"></a>분류자 개선 방법

Custom Vision Service 분류자의 품질을 개선하는 방법을 알아봅니다. 분류자의 품질은 분류자에 제공하는, 레이블이 지정된 데이터의 수량, 품질 및 다양성과 데이터 세트가 적절한 균형을 이루는지에 따라 결정됩니다. 일반적으로 좋은 분류자에는 분류자에 제출될 데이터를 대표하는 균형 잡힌 학습 데이터 세트가 들어 있습니다. 이러한 분류자를 빌드하는 프로세스는 종종 반복적입니다. 예상 결과에 도달하기 위해 몇 차례의 학습을 진행하는 것이 일반적입니다.

분류자를 개선하기 위해 수행되는 일반적인 단계는 다음과 같습니다. 다음 단계는 엄격한 규칙이 아니지만 더 나은 분류자를 빌드하는 데 도움되는 추론이 될 수 있습니다.

1. 1차 학습
1. 더 많은 이미지 추가 및 데이터 균형 유지
1. 다시 학습
1. 다양한 배경, 조명, 개체 크기, 카메라 각도 및 스타일을 사용하여 이미지 추가
1. 예측을 위해 이미지 다시 학습 및 공급
1. 예측 결과 검사
1. 기존 학습 데이터 수정

## <a name="data-quantity-and-data-balance"></a>데이터 양 및 데이터 균형

가장 중요한 점은 분류자를 학습시키기 위한 충분한 이미지를 업로드하는 것입니다. 처음에는 학습 집합으로 레이블당 50개 이상의 이미지를 사용하는 것이 좋습니다. 더 적은 수의 이미지를 사용하면 과잉 맞춤이 진행될 위험이 높아집니다. 성능 수치가 높은 품질을 암시할 수 있지만 실제 데이터를 사용하는 데는 문제가 있을 수 있습니다. 더 많은 이미지를 사용해서 분류자를 학습하게 되면 일반적으로 예측 결과의 정확도가 높아집니다.

또 다른 고려 사항은 데이터 균형을 유지하는 것입니다. 예를 들어, 하나의 레이블에 대해 500개 이미지가 있고, 또 다른 레이블에 대해 50개 이미지가 있는 경우 학습 데이터 세트가 균형을 이루지 못하므로 특정 레이블을 예측할 때 모델이 더 정확해집니다. 가장 적은 이미지가 있는 레이블과 가장 많은 이미지가 있는 레이블 간의 비율을 적어도 1:2로 유지해야만 더 나은 결과를 얻을 수 있습니다. 예를 들어, 이미지 수가 가장 많은 레이블에 500개 이미지가 있으면 이미지 수가 가장 적은 레이블의 이미지 수를 250개 이상으로 유지해야 학습 효과가 높아집니다.

## <a name="train-more-diverse-images"></a>좀 더 다양한 이미지 학습

일반적인 사용 중에 분류자에 제출될 항목을 대표하는 이미지를 제공합니다. 예를 들어, "apple" 분류자를 학습하는 경우, 접시에 놓여 있는 사과 사진만 학습하고 사과 나무에 달린 사과 사진으로 예측을 할 경우 분류자가 별로 정확하지 않을 수 있습니다. 다양한 이미지를 포함하면 분류자가 편향되지 않고 잘 일반화될 수 있습니다. 학습 집합을 좀 더 다양하게 만들 수 있는 몇 가지 방법은 다음과 같습니다.

__배경:__ 다양한 배경을 사용하여 물체 이미지를 제공합니다(즉, 접시 위의 과일 및 시장 바구니 앞의 과일). 문맥별 사진은 분류자에게 더 많은 정보를 제공하므로 중립 배경을 사용한 사진보다 더 효과적입니다.

![배경 샘플 이미지](./media/getting-started-improving-your-classifier/background.png)

__조명:__ 예측에 사용되는 이미지의 조명이 다양한 경우에 특히, 다양한 조명을 사용하여 이미지를 제공합니다(즉, 플래시를 켜거나 높은 노출 등으로 촬영). 또한 다양한 채도, 색상 및 밝기를 적용한 이미지를 포함하는 것이 유용합니다.

![조명 샘플 이미지](./media/getting-started-improving-your-classifier/lighting.png)

__물체 크기:__ 물체의 다양한 부분을 다양한 크기로 캡처한 이미지를 제공합니다. 예를 들어, 바나나 다발 사진과 바나나 1개를 클로즈업한 사진을 사용할 수 있습니다. 크기가 다르면 분류자가 일반화를 더 잘 수행할 수 있습니다.

![크기 샘플 이미지](./media/getting-started-improving-your-classifier/size.png)

__카메라 각도:__ 여러 카메라 각도로 촬영한 이미지를 제공합니다. 모든 사진을 고정된 카메라 설정으로 촬영하면(예: 감시 카메라) 같은 물체를 캡처하더라도 모든 카메라에 다른 레이블을 할당하여 관련 없는 물체(예: 가로등 기둥)를 주요 대상으로 모델링하는 과잉 맞춤이 발생하지 않도록 합니다.

![각도 샘플 이미지](./media/getting-started-improving-your-classifier/angle.png)

__스타일:__ 같은 과일 클래스에 속하지만 다른 스타일을 갖는 이미지를 제공합니다(즉, 다양한 종류의 감귤류). 그러나 물체 이미지가 완전히 다른 스타일을 갖는 경우(즉, 미키마우스와 실제 시궁창 쥐) 별도 클래스로 레이블을 지정하여 고유한 대상을 대표하도록 하는 것이 더 좋습니다.

![스타일 샘플 이미지](./media/getting-started-improving-your-classifier/style.png)

## <a name="use-images-submitted-for-prediction"></a>예측을 위해 제출된 이미지 사용

Custom Vision Service는 예측 엔드포인트에 제출된 이미지를 저장합니다. 이러한 이미지를 사용하여 분류자를 개선하려면 다음 단계를 사용합니다.

1. 분류자에 제출된 이미지를 보려면 [Custom Vision 웹 페이지](https://customvision.ai)를 열고 프로젝트로 이동한 후 __예측__ 탭을 선택합니다. 기본 보기에는 현재 반복의 이미지가 표시됩니다. __반복__ 드롭다운 필드를 사용하여 이전 반복 중에 제출된 이미지를 볼 수 있습니다.

    ![예측 탭 이미지](./media/getting-started-improving-your-classifier/predictions.png)

2. 이미지를 마우스로 가리키면 분류자가 예측한 태그가 표시됩니다. 분류자를 가장 개선할 수 있는 이미지가 맨 위에 오도록 이미지에 순위가 지정됩니다. 다른 정렬을 선택하려면 __정렬__ 섹션을 사용합니다. 기존 학습 데이터에 이미지를 추가하려면 이미지를 선택하고, 올바른 태그를 선택한 후 __저장 후 닫기__를 클릭합니다. 이미지가 __예측__에서 제거되고 학습 이미지에 추가됩니다. __학습 이미지__ 탭을 선택하면 해당 이미지를 볼 수 있습니다.

    ![태그 지정 페이지 이미지](./media/getting-started-improving-your-classifier/tag.png)

3. __학습__ 단추를 사용하여 분류자를 다시 학습합니다.

## <a name="visually-inspect-predictions"></a>시각적 예측 검사

이미지 예측을 검사하려면 __학습 이미지__ 탭을 선택하고 __반복 기록__을 선택합니다. 빨간색 상자가 표시된 이미지는 잘못 예측된 이미지입니다.

![반복 기록 이미지](./media/getting-started-improving-your-classifier/iteration.png)

때로는 시각적 검사를 통해 학습 데이터를 더 추가하거나 기존 학습 데이터를 수정하여 수정할 수 있는 패턴을 식별할 수 있습니다. 예를 들어, 사과와 라임에 대한 분류자는 모든 녹색 사과를 라임으로 잘못 레이블링할 수 있습니다. 태그가 지정된 파란색 사과 이미지가 포함된 학습 데이터를 추가하고 제공하면 이 문제를 해결할 수 있습니다.

## <a name="unexpected-classification"></a>예기치 않은 분류

분류자가 이미지에 공통적인 특성을 잘못 학습하는 경우도 있습니다. 예를 들어, 사과와 감귤류에 대한 분류자를 만들려고 하며 손에 들고 있는 사과 이미지와 흰색 접시에 올려 놓은 감귤류 이미지가 제공될 경우 분류자는 사과와 감귤류 대신, 손과 흰색 접시를 학습할 수 있습니다.

![예기치 않은 분류 이미지](./media/getting-started-improving-your-classifier/unexpected.png)

이 문제를 해결하려면 위 지침에 따라 보다 다양한 이미지로 학습을 진행하고, 다양한 각도, 배경, 물체 크기, 그룹 및 기타 변형이 적용된 이미지를 제공합니다.

## <a name="negative-image-handling"></a>음화 이미지 처리

Custom Vision Service는 몇 가지 자동 음화 이미지 처리를 지원합니다. 사과와 바나나 분류자를 빌드 중이며 예측을 위해 신발 이미지를 제출하는 경우, 분류자는 해당 이미지의 점수를 사과와 바나나 둘 다에 대해 0%에 가깝게 지정해야 합니다.

반면에 부정 이미지가 학습에 사용된 이미지 변형에 불과한 경우, 모델이 뛰어난 유사성 때문에 부정 이미지를 레이블이 지정된 클래스로 분류할 수 있습니다. 예를 들어, 오렌지와 포도 분류자가 있으며 귤 이미지를 제공할 경우 귤이 오렌지로 점수가 매겨질 수 있습니다. 귤의 많은 특성(색, 모양, 질감, 자연적인 특성 등)이 오렌지와 유사하기 때문에 이러한 결과가 나타날 수 있습니다.  부정 이미지가 이러한 특성을 가질 경우, 학습하는 동안 하나 이상의 별도 태그("기타")를 만들고 부정 이미지에 이 태그를 레이블로 지정하여 모델이 이러한 클래스 간을 보다 잘 구분하도록 할 수 있습니다.

## <a name="next-steps"></a>다음 단계

해당 모델을 Prediction API에 제출하여 프로그래밍 방식으로 이미지를 테스트하는 방법을 알아봅니다.

> [!div class="nextstepaction"]
[예측 API 사용](use-prediction-api.md)
