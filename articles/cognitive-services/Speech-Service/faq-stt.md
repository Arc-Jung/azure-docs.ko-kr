---
title: Azure의 음성 텍스트 변환 서비스에 대한 FAQ(질문과 대답)
titleSuffix: Azure Cognitive Services
description: 음성 텍스트 변환에 대해 가장 자주 묻는 질문에 대한 답변을 얻습니다.
services: cognitive-services
author: PanosPeriorellis
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 07/05/2019
ms.author: panosper
ms.openlocfilehash: bde68a70ac047433e86b7e06bc5f4a56bdd28595
ms.sourcegitcommit: 11265f4ff9f8e727a0cbf2af20a8057f5923ccda
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 10/08/2019
ms.locfileid: "72028499"
---
# <a name="speech-to-text-frequently-asked-questions"></a>음성 텍스트 변환에 대한 질문과 대답

이 FAQ에서 질문에 대한 답변을 찾을 수 없는 경우 [다른 지원 옵션](support.md)을 확인하세요.

## <a name="general"></a>일반

**Q: 기준 모델과 사용자 지정 음성 텍스트 변환 모델의 차이는 무엇인가요?**

**A**: 기준 모델은 Microsoft가 소유한 데이터를 사용하여 학습이 되었으며 클라우드에 이미 배포되어 있습니다.  사용자 지정 모델을 사용하면 특정한 주변 소음이나 언어가 있는 특정 환경에 적합하게 모델을 적응시킬 수 있습니다. 공장 현장, 자동차 또는 소음이 많은 거리에 적응형 음향 모델이 필요합니다. 생물학, 물리학, 방사선, 제품 이름 등의 주제와 사용자 지정 약어에 적응형 언어 모델이 필요합니다.

**Q: 기준 모델 사용을 시작하려면 어떻게 해야 하나요?**

**A**: 먼저 [구독 키](get-started.md)를 가져옵니다. 미리 배포된 기준 모델을 REST 방식으로 호출하려면 [REST API](rest-apis.md)를 참조하세요. WebSocket을 사용하려면 [SDK를 다운로드](speech-sdk.md)합니다.

**Q: 사용자 지정 음성 모델을 항상 작성해야 하나요?**

**A**: 아니요. 애플리케이션에서 일반적인 일상 언어를 사용하는 경우라면 모델을 사용자 지정할 필요가 없습니다. 배경 소음이 거의 또는 전혀 없는 환경에서 애플리케이션을 사용하는 경우 모델을 사용자 지정할 필요가 없습니다.

포털에서 기준 모델 및 사용자 지정 모델을 배포하고 그에 대한 정확도 테스트를 실행할 수 있습니다. 이러한 기능을 사용하여 기준 모델과 사용자 지정 모델의 정확성을 측정할 수 있습니다.

**Q: 데이터 세트나 모델의 처리가 완료되면 어떻게 알 수 있나요?**

**A**: 현재 처리 완료를 확인하는 방법은 테이블에 있는 모델이나 데이터 세트의 상태를 확인하는 것뿐입니다. 처리가 완료되면 **성공** 상태가 됩니다.

**Q: 모델을 여러 개 만들 수 있나요?**

**A**: 컬렉션에 포함할 수 있는 모델 수에는 제한이 없습니다.

**Q: 모델을 잘못 만든 경우 데이터 가져오기 또는 모델 만들기를 진행 중인 경우 어떻게 취소하나요?**

**A**: 현재는 음향 적응 또는 언어 적응 프로세스를 롤백할 수 없습니다. 종료 상태에 있을 때 가져온 데이터와 모델을 삭제할 수 있습니다.

**Q: 검색 및 받아쓰기 모델과 대화형 모델의 차이는 무엇인가요?**

**A**: Speech Service 내의 여러 기준 모델 중에서 선택할 수 있습니다. 대화형 모델은 대화 스타일로 통용되는 음성을 인식하는 데 유용합니다. 이 모델은 전화 통화를 기록하는 데 적합합니다. 검색 및 받아쓰기 모델은 음성 트리거 앱에 적합합니다. 유니버설 모델이 두 시나리오를 모두 해결하기 위한 새 모델입니다. 유니버설 모델의 품질은 현재 대부분의 로캘에서 대화형 모델의 품질 수준 이상입니다.

**Q: 기존 모델(모델 스태킹)을 업데이트할 수 있나요?**

**A**: 기존 모델을 업데이트할 수는 없습니다. 해결 방안은 이전 데이터 세트를 새 데이터 세트와 결합하여 다시 적응시키는 것입니다.

이전 데이터 세트 및 새 데이터 세트를 단일 .zip 파일(음향 데이터) 또는 .txt 파일(언어 데이터)에 결합해야 합니다. 적응이 완료된 후에는 새로 업데이트된 모델을 다시 배포하여 새 엔드포인트를 확보해야 합니다.

**Q: 새 기준 버전을 사용할 수 있게 되면 배포가 자동으로 업데이트되나요?**

**A**: 배포는 자동으로 업데이트되지 않습니다.

기준 V1.0의 모델을 적응시키고 배포하면 배포는 원래 상태를 유지합니다. 고객은 배포 된 모델의 서비스를 해제 하 고, 최신 버전의 기준선을 다시 적용 하 고, 다시 배포할 수 있습니다.

**Q: 배포된 모델이 포털에서 제공되는 값보다 더 많은 수의 작업을 동시에 수행해야 하는 경우에는 어떻게 해야 하나요?**

**A**: 동시 요청을 20개씩 추가하여 모델을 강화할 수 있습니다.

더 높은 규모를 요구 하는 경우 [음성 지원](mailto:speechsupport@microsoft.com?subject=Request%20for%20higher%20concurrency%20for%20Speech-to-text) 에 문의 하세요.

**Q: 모델을 다운로드하여 로컬에서 실행할 수 있나요?**

**A**: 모델을 다운로드하여 로컬에서 실행할 수는 없습니다.

**Q: 요청은 기록되나요?**

**A**: 배포를 만들 때 추적을 해제하는 옵션을 선택할 수 있습니다. 이 경우 오디오 또는 전사는 기록되지 않습니다. 그렇지 않으면 일반적으로 Azure에서 보안 스토리지에 요청이 기록됩니다.

**Q: 요청에 제한이 있나요?**

**A**: REST API에서는 요청이 5초당 25개로 제한됩니다. 자세한 내용은 [음성을 텍스트로 변환](speech-to-text.md)에 대한 페이지에서 찾을 수 있습니다.

**Q: 이중 채널 오디오에 대 한 요금은 어떻게 청구 되나요?**

**A**: 각 채널을 별도로 제출 하는 경우 (각 채널은 자체 파일에) 각 파일의 기간에 따라 요금이 청구 됩니다. 각 채널이 함께 멀티플렉싱 단일 파일을 제출 하면 단일 파일의 기간에 대 한 요금이 청구 됩니다.

> [!IMPORTANT]
> 그 밖의 개인 정보 보호 문제로 인해 Custom Speech Service를 사용할 수 없는 경우에는 지원 채널 중 한 곳에 문의하세요.

## <a name="importing-data"></a>데이터 가져오기

**Q: 데이터 세트의 크기 제한은 얼마나 되며 크기가 제한되는 이유는 무엇인가요?**

**A**: 데이터 세트의 현재 제한은 2GB입니다. 이러한 제한은 HTTP 업로드용 파일 크기가 제한되기 때문에 발생합니다. 

**Q: 더 큰 텍스트 파일을 업로드하기 위해 텍스트 파일을 압축할 수 있나요?** 

**A**: 아니요. 현재는 압축되지 않은 텍스트 파일만 허용됩니다.

**Q: 데이터 보고서에 발화 실패가 기록되어 있습니다. 문제가 무엇인가요?**

**A**: 파일의 발화가 모두 업로드되지 않는다고 해서 문제가 있는 것은 아닙니다. 음향 데이터 세트나 언어 데이터 세트에서 대부분의 음성을(예: 95% 초과) 가져온 경우에는 데이터 세트를 사용할 수 있습니다. 단, 음성이 실패한 이유를 이해하고 문제 해결을 시도하는 것이 좋습니다. 가장 일반적인 문제(예: 서식 오류)는 쉽게 해결할 수 있습니다. 

## <a name="creating-an-acoustic-model"></a>음향 모델 만들기

**Q: 음향 데이터는 어느 정도나 필요한가요?**

**A**: 처음에는 30분에서 1시간 분량의 음향 데이터를 준비하는 것이 좋습니다.

**Q: 어떤 데이터를 수집해야 하나요?**

**A**: 애플리케이션 시나리오 및 사용 사례와 최대한 유사한 데이터를 수집합니다. 데이터 컬렉션은 디바이스, 환경 및 화자 유형과 관련하여 대상 애플리케이션 및 사용자와 일치해야 합니다. 일반적으로 최대한 광범위한 화자의 데이터를 수집해야 합니다. 

**Q: 음향 데이터는 어떻게 수집해야 하나요?**

**A**: 독립 실행형 데이터 수집 애플리케이션을 만들거나 기존 오디오 녹음 소프트웨어를 사용하면 됩니다. 오디오 데이터를 기록한 다음, 해당 데이터를 사용하는 버전의 애플리케이션을 만들 수도 있습니다. 

**Q: 적응 데이터를 직접 전사해야 하나요?**

**A**: 예! 직접 전사하거나 전문적인 전사 서비스를 사용할 수 있습니다. 크라우드소싱을 사용하거나 전사를 직접 수행해야 하는 사용자도 있고 전사 전문가를 선호하는 사용자도 있습니다.

## <a name="accuracy-testing"></a>정확도 테스트

**Q: 사용자 지정 언어 모델을 사용하여 사용자 지정 음향 모델의 오프라인 테스트를 수행할 수 있나요?**

**A**: 예, 오프라인 테스트를 설정할 때 드롭다운 메뉴에서 사용자 지정 언어 모델을 선택하면 됩니다.

**Q: 사용자 지정 음향 모델을 사용하여 사용자 지정 언어 모델의 오프라인 테스트를 수행할 수 있나요?**

**A**: 예, 오프라인 테스트를 설정할 때 드롭다운 메뉴에서 사용자 지정 음향 모델을 선택하면 됩니다.

**Q: 단어 오류 비율이란 무엇이며 어떻게 계산되나요?**

**A**: WER은 음성 인식을 위한 평가 메트릭입니다. WER은 삽입, 삭제 및 대체를 포함하는 총 오류 수를 참조 전사에 포함된 총 단어 수로 나누어 계산됩니다. 자세한 내용은 [단어 오류율](https://en.wikipedia.org/wiki/Word_error_rate)을 참조하세요.

**Q: 정확도 테스트의 결과가 양호한지 여부는 어떻게 판단하나요?**

**A**: 결과에는 기준 모델과 사용자 지정 모델을 비교한 내용이 표시됩니다. 사용자 지정이 빛을 발하려면 기준 모델보다 우수해야 합니다.

**Q: 개선 여부 확인을 위해 베이스 모델의 WER을 확인하려면 어떻게 해야 하나요?** 

**A**: 오프라인 테스트 결과에는 사용자 지정 모델의 기준 정확도와 기준 모델에 비해 사용자 지정 모델에서 개선된 부분이 표시됩니다.

## <a name="creating-a-language-model"></a>언어 모델 만들기

**Q: 텍스트 데이터는 어느 정도나 업로드해야 하나요?**

**A**: 애플리케이션에서 사용되는 어휘/구문과 시작 언어 모델의 어휘/구문 간 차이 정도에 따라 다릅니다. 모든 새 단어에 대해 예제를 가능한 한 많이 제공하는 것이 유용합니다. 애플리케이션에서 사용되는 일반적인 문구의 경우 언어 데이터의 문구도 포함하면 유용합니다. 이러한 단어도 경청하도록 시스템에 지시하기 때문입니다. 언어 데이터 세트에 적어도 100개, 일반적으로 수백 개 또는 그 이상의 발언이 있는 것이 일반적입니다. 또한 일부 유형의 쿼리가 다른 쿼리 유형보다 일반적일 것으로 예상되는 경우 데이터 세트에 일반적인 쿼리의 복사본을 여러 개 삽입할 수 있습니다.

**Q: 단어 목록만 업로드할 수 있나요?**

**A**: 단어 목록을 업로드하면 단어가 어휘에 추가되기는 하지만 해당 단어가 일반적으로 사용되는 방식을 시스템이 학습하지는 않습니다. 전체 또는 부분 음성(사용자가 말하려는 문장이나 문구)을 제공하면 언어 모델이 새 단어를 학습하고 이 단어가 어떻게 사용되는지 학습할 수 있습니다. 사용자 지정 언어 모델은 시스템에 새 단어를 추가하는 것뿐만 아니라 애플리케이션에서 알려진 단어가 나타날 가능성을 조정하는 데에도 적합합니다. 전체 음성을 제공하면 시스템 학습 성능이 좋아집니다. 

## <a name="next-steps"></a>다음 단계

* [문제 해결](troubleshooting.md)
* [릴리스 정보](releasenotes.md)
