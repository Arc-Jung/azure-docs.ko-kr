---
title: '자습서: 음성 서비스를 사용하여 어쿠스틱 모델 만들기'
titlesuffix: Azure Cognitive Services
description: Azure Cognitive Services에서 음성 서비스를 사용하여 어쿠스틱 모델을 만드는 방법을 알아봅니다.
services: cognitive-services
author: PanosPeriorellis
manager: cgronlun
ms.service: cognitive-services
ms.component: speech-service
ms.topic: tutorial
ms.date: 06/25/2018
ms.author: panosper
ms.openlocfilehash: 70fc9c34599f27eb5d67b79ef823f8037ae55ba9
ms.sourcegitcommit: 6e09760197a91be564ad60ffd3d6f48a241e083b
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 10/29/2018
ms.locfileid: "50215245"
---
# <a name="tutorial-create-a-custom-acoustic-model"></a>자습서: 사용자 지정 어쿠스틱 모델 만들기

응용 프로그램이 차량 등의 특정 환경, 특정 녹음 장치나 상황 또는 특정 사용자 집단에서 사용하도록 설계된 경우 사용자 지정 어쿠스틱 모델을 만드는 것이 유용합니다. 액센트가 있는 음성, 특정 배경 소음, 레코딩에 특정 마이크 사용 등을 예로 들 수 있습니다.

이 문서에서는 다음 방법을 설명합니다.
> [!div class="checklist"]
> * 데이터 준비
> * 어쿠스틱 데이터 세트 가져오기
> * 사용자 지정 어쿠스틱 모델 만들기

Azure Cognitive Services 계정이 아직 없는 경우 시작하기 전에 [무료 계정](https://azure.microsoft.com/try/cognitive-services)을 만듭니다.

## <a name="prerequisites"></a>필수 조건

[Cognitive Services 구독](https://cris.ai/Subscriptions) 페이지를 열어 Cognitive Services 계정이 구독에 연결되어 있는지 확인합니다.

**기존 구독 연결**을 선택하여 Azure Portal에서 만든 Search Service 구독에 연결할 수 있습니다.

Azure Portal에서 음성 서비스 구독 만들기에 대한 자세한 내용은 [무료로 음성 서비스 사용해 보기](get-started.md)를 참조하세요.

## <a name="prepare-the-data"></a>데이터 준비

특정 도메인에 어쿠스틱 모델을 사용자 지정하려면 음성 데이터의 컬렉션이 필요합니다. 이 컬렉션의 범위는 음성 두 마디에서 수백 시간에 이를 수 있습니다. 이 컬렉션은 음성 데이터의 오디오 파일 집합과 각 오디오 파일의 전사에 대한 텍스트 파일로 구성됩니다. 오디오 데이터는 인식기를 사용하고자 하는 시나리오를 대표해야 합니다.

예: 

* 시끄러운 공장 환경에서 음성을 더 잘 식별하려면 오디오 파일은 시끄러운 공장에서 말하는 사람으로 구성되어야 합니다.
* 단일 화자에 대해 성능을 최적화하려면, &mdash;예를 들어 모든 FDR의 노변 대화를 전사하려면&mdash; 오디오 파일은 해당 화자의 많은 예로 구성되어야 합니다.

어쿠스틱 모델을 사용자 지정하기 위한 어쿠스틱 데이터 세트는 (1) 음성 데이터를 포함하는 오디오 파일 집합 및 (2) 모든 오디오 파일의 전사를 포함하는 파일의 두 부분으로 구성됩니다.

### <a name="audio-data-recommendations"></a>오디오 데이터 권장 사항

* 데이터 세트의 모든 오디오 파일은 WAV(RIFF) 오디오 형식으로 저장되어야 합니다.
* 오디오는 샘플링 속도가 8 KHz 또는 16 KHz이어야 하며 샘플 값은 압축되지 않은 PCM(펄스 코드 변조) 16비트 부호 있는 정수(짧은)로 저장되어야 합니다.
* 단일 채널(모노) 오디오 파일만 지원됩니다.
* 오디오 파일의 길이는 100마이크로초에서 1분 사이가 될 수 있지만 10~12초 정도가 적당합니다. 각 오디오 파일은 최소 100ms의 휴지가 있도록 시작 및 종료하는 것이 이상적이며, 500ms ~ 1초 범위가 일반적입니다.
* 데이터에 배경 소음이 있는 경우 데이터에 더 긴 휴지 세그먼트(음성 콘텐츠 앞 및/또는 뒤에 &mdash;예를 들어 몇 초&mdash;)를 포함하는 몇몇 예제를 갖는 것이 좋습니다.
* 각 오디오 파일은 단일 발언&mdash;(예: 단일 받아쓰기 문장, 단일 쿼리 또는 대화 시스템의 단일 회차)으로 구성되어야 합니다.
* 데이터 세트의 각 오디오 파일에는 고유한 파일 이름 및 .wav 확장명이 있어야 합니다.
* 오디오 파일 집합은 하위 디렉터리 없이 단일 폴더 안에 있어야 하며 오디오 파일의 전체 집합은 단일 Zip 파일 보관으로 패키징되어야 합니다.

> [!NOTE]
> 웹 포털을 통한 데이터 가져오기는 현재 2GB로 제한되므로 이것이 어쿠스틱 데이터 세트의 최대 크기입니다. 이 크기는 대략 16KHz로 기록된 오디오 17시간 또는 8KHz로 기록된 오디오 34시간에 해당합니다. 오디오 데이터에 대한 기본 요구 사항이 다음 표에 요약되어 있습니다.
>

| 자산 | 값 |
|---------- |----------|
| 파일 형식 | RIFF(WAV) |
| 샘플링 레이트 | 8,000헤르츠(Hz) 또는 16,000 Hz |
| 채널 | 1(mono) |
| 샘플 형식 | PCM, 16비트 정수 |
| 파일 지속 기간 | 0.1초 < 기간 < 12초 | 
| 무음 목걸이 | 0.1초 초과 |
| 보관 형식 | .zip |
| 최대 보관 크기 | 2GB |

> [!NOTE]
> 파일 이름은 라틴 문자만 사용하고 'filename.extention' 형식을 따라야 합니다.

## <a name="language-support"></a>언어 지원

사용자 지정 **음성을 텍스트로 변환** 언어 모델에 대해 지원되는 전체 언어 목록은 [음성 서비스에 지원되는 언어](language-support.md#speech-to-text)를 참조하세요.

### <a name="transcriptions-for-the-audio-dataset"></a>오디오 데이터 세트의 전사

모든 WAV 파일에 대한 전사는 단일 일반 텍스트 파일에 포함되어야 합니다. 전사 파일의 각 줄은 오디오 파일 중 하나의 이름을 포함하고 그 뒤에 해당 전사가 와야 합니다. 파일 이름과 전사는 탭(\t)으로 구분 해야 합니다.

  예: 
```
  speech01.wav  speech recognition is awesome
  speech02.wav  the quick brown fox jumped all over the place
  speech03.wav  the lazy dog was not amused
```
> [!NOTE]
> 전사는 UTF-8 BOM으로 인코딩해야 합니다.

전사는 시스템에서 처리할 수 있도록 텍스트로 정규화됩니다. 그러나 데이터를 사용자 지정 음성 서비스에 업로드하기 _전에_ 사용자가 수행해야 하는 몇몇 중요한 정규화 작업이 있습니다. 전사를 준비할 때 사용하기에 적절한 언어는 [음성 서비스를 사용하기 위한 전사 지침](prepare-transcription.md)을 참조하세요.

[음성 서비스 포털](https://cris.ai)을 사용하여 다음 섹션의 단계를 수행합니다.

## <a name="import-the-acoustic-dataset"></a>어쿠스틱 데이터 세트 가져오기

오디오 파일 및 전사를 준비한 후 서비스 웹 포털로 가져올 수 있습니다.

가져오려면 먼저 [음성 서비스 포털](https://cris.ai)에 로그인해야 합니다. 그런 다음 리본의 **사용자 지정 음성** 드롭다운 목록에서 **적응 데이터**를 선택합니다. Custom Speech Service에 처음으로 데이터를 업로드하는 경우 **데이터 세트**라는 빈 테이블이 표시됩니다. 

**어쿠스틱 데이터 집합** 행에서 **가져오기** 단추를 선택하면 사이트에 새 데이터 집합을 업로드하기 위한 페이지가 표시됩니다.

![어쿠스틱 데이터 가져오기 페이지](media/stt/speech-acoustic-datasets-import.png)

**이름** 및 **설명** 상자에 적절 한 정보를 입력합니다. 업로드한 다양한 데이터 세트를 기억하려면 친숙한 이름이 유용합니다. 

**전사 파일(.txt)** 및 **오디오 파일(.zip)** 상자에서 **찾아보기**를 선택한 다음, 일반 텍스트 전사 파일 및 WAV 파일의 zip 보관 파일을 선택합니다. 준비가 완료되면 **가져오기**를 클릭하여 데이터를 업로드합니다. 데이터가 업로드됩니다. 더 큰 데이터 세트의 경우 가져오기 프로세스에 몇 분이 걸릴 수 있습니다.

업로드가 완료되면 **어쿠스틱 데이터 세트** 테이블로 돌아갑니다. 어쿠스틱 데이터 세트에 해당하는 항목이 표시됩니다. 고유 ID(GUID)가 할당되었음에 유의합니다. 데이터는 현재 상태를 표시합니다. 처리하기 위해 쿼리하는 경우 *NotStarted*, 유효성 검사를 실행하는 경우 *실행 중* 및 사용 준비가 된 경우 *완료*.

데이터 유효성에는 파일 형식, 길이 및 샘플링 주기를 확인하는 오디오 파일에 대한 검사와, 파일 형식을 확인하고 몇 가지 텍스트 정규화를 수행하는 전사 파일에 대한 검사가 포함됩니다.

상태가 *성공*이면 **세부 정보**를 선택하여 어쿠스틱 데이터 확인 보고서를 볼 수 있습니다. 확인을 통과하고 실패한 발언 수가 실패한 발언에 대한 세부 정보와 함께 표시됩니다. 다음 이미지의 예제에서 WAV 파일 두 개는 부적절한 오디오 형식 때문에 확인에 실패했습니다. 이 데이터 세트에서 파일 한 개는 잘못된 샘플링 속도를 포함하며 다른 한 개는 파일 형식이 잘못되었습니다.

![데이터 세부 정보의 적응 페이지](media/stt/speech-acoustic-datasets-report.png)

데이터 세트의 이름 또는 설명을 변경하려면 **편집** 링크를 선택하고 해당 항목을 변경할 수 있습니다. 전사 또는 오디오 파일 항목은 수정할 수 없습니다.

## <a name="create-a-custom-acoustic-model"></a>사용자 지정 어쿠스틱 모델 만들기

어쿠스틱 데이터 세트의 상태가 *완료*이면 데이터 세트를 사용하여 사용자 지정 어쿠스틱 모델을 만들 수 있습니다. 그렇게 하려면 **사용자 지정 음성** 드롭다운 목록에서 **어쿠스틱 모델**을 선택합니다. **사용자의 모델**이라는 테이블에 모든 사용자 지정 어쿠스틱 모델이 나열됩니다. 이 테이블은 처음 사용할 경우 비어 있습니다. 테이블 제목에 현재 로캘이 표시됩니다. 현재 미국 영어에 대해서만 어쿠스틱 모델을 만들 수 있습니다.

새 모델을 만들려면 테이블 제목 아래의 **새로 만들기**를 클릭합니다. 앞에서와 같이, 이 모델을 식별할 수 있는 이름과 설명을 입력합니다. 예를 들어 **설명** 필드를 사용하여 모델을 만드는 데 사용한 시작 모델 및 어쿠스틱 데이터 세트를 기록할 수 있습니다. 

다음으로 **기본 어쿠스틱 모델** 드롭 다운 목록에서 기본 모델을 선택합니다. 기본 모델은 사용자 지정에 대한 시작점입니다. 두 가지 기본 어쿠스틱 모델 중에서 선택할 수 있습니다.
* **Microsoft 검색 및 받아쓰기 AM** 모델은 명령, 검색 쿼리 또는 받아쓰기 등 응용 프로그램에서 지시하는 음성에 적합합니다. 
* **Microsoft 대화형 모델**은 대화 스타일로 말하는 음성을 인식하는 데 적합합니다. 이런 유형의 음성은 일반적으로 다른 사람을 대상으로 지시하며 콜센터나 회의에서 사용됩니다. 

대화형 모델의 부분 결과 대기 시간은 검색 및 받아쓰기 모델보다 깁니다.

> [!NOTE]
> 현재 모든 시나리오에 부합할 목적으로 새로운 **범용** 모델을 출시 중입니다. 앞서 언급한 모델도 계속 공개적으로 제공됩니다.

다음으로 **어쿠스틱 데이터** 드롭 다운 목록에서 사용자 지정을 수행하는 데 사용하려는 어쿠스틱 데이터를 선택합니다.

![어쿠스틱 모델 만들기 페이지](media/stt/speech-acoustic-models-create2.png)

선택적으로, 처리가 완료되면 새 모델의 정확도 테스트를 수행하기 위해 선택할 수 있습니다. 이 테스트는 사용자 지정 어쿠스틱 모델을 사용하여 지정된 어쿠스틱 데이터 세트에 대해 음성을 텍스트로 변환 평가를 실행한 다음, 결과를 보고합니다. 이 테스트를 수행하려면 **정확도 테스트** 확인란을 선택합니다. 그런 다음, 드롭다운 목록에서 언어 모델을 선택합니다. 사용자 지정 언어 모델을 만들지 않은 경우 기본 언어 모델만 드롭다운 목록에 표시됩니다. 가장 적합한 언어 모델을 선택하려면 [자습서: 사용자 지정 언어 모델 만들기](how-to-customize-language-model.md)를 참조하세요.

마지막으로 사용자 지정 모델을 평가하는 데 사용하려는 어쿠스틱 데이터 세트를 선택합니다. 정확도 테스트를 수행하는 경우 모델의 성능에 대한 사실적인 감각을 얻기 위해 모델 만들기에 사용한 것과 다른 어쿠스틱 데이터 세트를 선택해야 합니다. 교육 데이터에 대한 정확도 테스트를 통해 실제 조건에서 수정된 모델이 수행하는 방법을 평가할 수는 없습니다. 이 결과는 지나치게 긍정적입니다. 정확도 테스트는 발성 1,000건으로 제한됩니다. 테스트를 위한 어쿠스틱 데이터 세트가 이보다 크면 처음 1,000건만 평가됩니다.

사용자 지정 프로세스 실행을 시작할 준비가 되면 **만들기**를 누릅니다.

어쿠스틱 모델 테이블은 새 모델에 해당하는 새 항목을 표시합니다. 또한 프로세스의 상태 *대기 중*, *처리 중* 또는 *완료*를 표시합니다.

![어쿠스틱 모델 페이지](media/stt/speech-acoustic-models-creating.png)

## <a name="next-steps"></a>다음 단계

- [Speech Service 평가판 구독 가져오기](https://azure.microsoft.com/try/cognitive-services/)
- [C#에서 음성 인식](quickstart-csharp-dotnet-windows.md)
- [Git 샘플 데이터](https://github.com/Microsoft/Cognitive-Custom-Speech-Service)
