---
title: Custom Speech-Speech service에 대 한 데이터 준비
titleSuffix: Azure Cognitive Services
description: Microsoft 음성 인식의 정확도를 테스트 하거나 사용자 지정 모델을 학습 하는 경우 오디오 및 텍스트 데이터가 필요 합니다. 이 페이지에서는 데이터 형식, 사용 방법 및 관리 방법에 대해 다룹니다.
services: cognitive-services
author: trevorbye
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 02/12/2021
ms.author: trbye
ms.openlocfilehash: 8546201d21e68fbcf1e519c8fe9ba0de1dc38a96
ms.sourcegitcommit: d4734bc680ea221ea80fdea67859d6d32241aefc
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 02/14/2021
ms.locfileid: "100367982"
---
# <a name="prepare-data-for-custom-speech"></a>Custom Speech에 대한 데이터 준비

Microsoft 음성 인식의 정확도를 테스트 하거나 사용자 지정 모델을 학습 하는 경우 오디오 및 텍스트 데이터가 필요 합니다. 이 페이지에서는 사용자 지정 음성 모델에 필요한 데이터 형식을 다룹니다.

## <a name="data-diversity"></a>데이터 다양성

사용자 지정 모델을 테스트 하 고 학습 하는 데 사용 되는 텍스트와 오디오는 다양 한 스피커 집합의 샘플과 모델에서 인식 해야 하는 시나리오를 포함 해야 합니다.
사용자 지정 모델 테스트 및 학습을 위해 데이터를 수집할 때 다음 요소를 고려 합니다.

* 텍스트 및 음성 오디오 데이터는 사용자가 모델과 상호 작용할 때 사용자가 수행 하는 다양 한 종류의 문을 포함 해야 합니다. 예를 들어 온도를 발생 시키고 낮추는 모델은 사용자가 이러한 변경을 요청 하기 위해 수행할 수 있는 문의 학습을 요구 합니다.
* 데이터에는 모델에서 인식 해야 하는 모든 음성 분산이 포함 되어야 합니다. 강조, 언어, 언어 혼합, 연령, 성별, 음성 피치, 스트레스 수준 및 시간을 포함 하 여 많은 요인이 음성을 다를 수 있습니다.
* 모델을 사용할 다른 환경 (실내, 실외,도로 노이즈)의 샘플을 포함 해야 합니다.
* 프로덕션 시스템에서 사용 하는 하드웨어 장치를 사용 하 여 오디오를 수집 해야 합니다. 모델에서 다양 한 품질의 장치를 기록 하는 데 기록 된 음성을 식별 해야 하는 경우 모델 학습을 위해 제공 하는 오디오 데이터는 이러한 다양 한 시나리오를 나타내야 합니다.
* 나중에 더 많은 데이터를 모델에 추가할 수 있지만, 데이터 집합을 다양 하 게 유지 하 고 프로젝트 요구 사항에 대 한 정보를 가져올 수 있습니다.
* 사용자 지정 모델 인식에 포함 *되지* 않은 데이터를 포함 하 여 전체 인식 품질을 손상 시킬 수 있으므로 모델이 높여줄 필요가 없는 데이터는 포함 하지 마세요.

시나리오의 하위 집합에 대해 학습 된 모델은 해당 시나리오 에서만 제대로 수행할 수 있습니다. 사용자 지정 모델이 인식 해야 하는 시나리오의 전체 범위를 나타내는 데이터를 신중 하 게 선택 합니다.

> [!TIP]
> 모델에서 발생 하는 언어 및 acoustics 일치 하는 작은 샘플 데이터 집합으로 시작 합니다.
> 예를 들어 동일한 하드웨어와 동일한 하드웨어에 있는 오디오의 대표적인 샘플을 기록 하 고 프로덕션 시나리오에서 모델이 찾을 수 있는 것과 동일한 음향 환경에 기록 합니다.
> 대표 데이터의 작은 데이터 집합은 교육을 위해 훨씬 더 큰 데이터 집합을 수집 하는 데 투자 하기 전에 문제를 노출할 수 있습니다.

## <a name="data-types"></a>데이터 형식

다음 표에서는 허용 되는 데이터 형식, 각 데이터 형식을 사용 해야 하는 경우 및 권장 수량을 나열 합니다. 모델을 만드는 데 모든 데이터 형식이 필요 하지는 않습니다. 데이터 요구 사항은 테스트를 만들거나 모델을 학습 하는지에 따라 달라 집니다.

| 데이터 형식 | 테스트에 사용 됨 | 권장 수량 | 학습에 사용 됨 | 권장 수량 |
|-----------|-----------------|----------|-------------------|----------|
| [오디오](#audio-data-for-testing) | Yes<br>시각적 검사에 사용 됨 | 5 + 오디오 파일 | 예 | 해당 없음 |
| [오디오 + 사람이 레이블 지정 된 성적 증명서](#audio--human-labeled-transcript-data-for-testingtraining) | Yes<br>정확도를 평가 하는 데 사용 됩니다. | 0.5-오디오의 5 시간 | Yes | 1-20 시간 (오디오) |
| [관련 텍스트](#related-text-data-for-training) | 예 | 해당 사항 없음 | Yes | 1-200 MB의 관련 텍스트 |

새 모델을 학습 하는 경우 [관련 텍스트로](#related-text-data-for-training)시작 합니다. 이 데이터는 이미 특수 한 사용 약관의 인식을 향상 시킵니다. 텍스트를 사용한 교육은 오디오 학습 보다 훨씬 빠릅니다 (몇 분 및 며칠).

파일은 형식에 따라 데이터 집합으로 그룹화 되 고 .zip 파일로 업로드 되어야 합니다. 각 데이터 집합은 단일 데이터 형식만 포함할 수 있습니다.

> [!TIP]
> 빠르게 시작 하려면 샘플 데이터를 사용 하는 것이 좋습니다. <a href="https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/sampledata/customspeech" target="_target">샘플 Custom Speech 데이터 <span class="docon docon-navigate-external x-hidden-focus"></span> </a> 는이 GitHub 리포지토리를 참조 하세요.

> [!NOTE]
> 모든 기본 모델에서 오디오로의 학습을 지원 하지는 않습니다. 기본 모델이 지원 하지 않는 경우 음성 서비스는 성적 증명서의 텍스트만 사용 하 고 오디오는 무시 합니다. 오디오 데이터로 학습을 지 원하는 기본 모델 목록은 [언어 지원](language-support.md#speech-to-text) 을 참조 하세요.

> [!NOTE]
> 학습에 사용 되는 기본 모델을 변경 하 고 학습 데이터 집합에 오디오가 있는 경우 선택한 새 기본 모델에서 [오디오 데이터로 학습을 지원](language-support.md#speech-to-text)하는지 *항상* 확인 합니다. 이전에 사용 된 기본 모델에서 오디오 데이터에 대 한 학습을 지원 하지 않고 학습 데이터 집합에 오디오가 포함 된 경우 새 기본 모델의 학습 시간이 **크게** 증가 하 고 몇 시간에서 며칠 이상으로 쉽게 이동할 수 있습니다. 음성 서비스 구독이 교육용 [전용 하드웨어가 있는 지역](custom-speech-overview.md#set-up-your-azure-account) 에 **있지 않은** 경우에 특히 그렇습니다.
>
> 위의 단락에 설명 된 문제를 직면 하는 경우 데이터 집합의 오디오 양을 줄이거나 텍스트를 완전히 제거 하 여 학습 시간을 빠르게 줄일 수 있습니다. 두 번째 옵션은 음성 서비스 구독이 교육용 [전용 하드웨어가 있는 지역](custom-speech-overview.md#set-up-your-azure-account) 에 **있지 않은** 경우에 매우 권장 됩니다.

## <a name="upload-data"></a>데이터 업로드

데이터를 업로드 하려면 <a href="https://speech.microsoft.com/customspeech" target="_blank">Speech Studio <span class="docon docon-navigate-external x-hidden-focus"></span> </a>로 이동 합니다. 포털에서 **데이터 업로드** 를 클릭 하 여 마법사를 시작 하 고 첫 번째 데이터 집합을 만듭니다. 데이터를 업로드 하기 전에 데이터 집합에 대 한 음성 데이터 형식을 선택 하 라는 메시지가 표시 됩니다.

![음성 포털에서 오디오 업로드 옵션을 강조 표시 하는 스크린샷](./media/custom-speech/custom-speech-select-audio.png)

업로드 하는 각 데이터 집합은 사용자가 선택 하는 데이터 형식에 대 한 요구 사항을 충족 해야 합니다. 데이터를 업로드 하기 전에 올바른 형식으로 지정 해야 합니다. 올바른 형식의 데이터를 사용 하면 Custom Speech 서비스에서 정확 하 게 처리 됩니다. 요구 사항은 다음 섹션에 나열 되어 있습니다.

데이터 집합을 업로드 한 후에는 몇 가지 옵션을 사용할 수 있습니다.

* **테스트** 탭으로 이동 하 여 오디오 전용 또는 오디오 + 사람 레이블이 지정 된 기록 데이터를 시각적으로 검사할 수 있습니다.
* **학습** 탭으로 이동 하 여 오디오 + 인간 기록 데이터 또는 관련 텍스트 데이터를 사용 하 여 사용자 지정 모델을 학습 시킬 수 있습니다.

## <a name="audio-data-for-testing"></a>테스트용 오디오 데이터

오디오 데이터는 Microsoft의 기본 음성 텍스트 모델 또는 사용자 지정 모델의 정확도를 테스트 하는 데 가장 적합 합니다. 오디오 데이터는 특정 모델의 성능과 관련 하 여 음성의 정확도를 검사 하는 데 사용 됩니다. 모델의 정확도를 수량화 하려는 경우 [오디오 + 사람 레이블이 지정](#audio--human-labeled-transcript-data-for-testingtraining)된 기록 데이터를 사용 합니다.

이 표를 사용 하 여 Custom Speech에서 사용 하기 위해 오디오 파일의 형식이 올바르게 지정 되었는지 확인 합니다.

| 속성                 | 값                 |
|--------------------------|-----------------------|
| 파일 형식              | RIFF(WAV)            |
| 샘플 속도              | 8000 hz 또는 16000 Hz |
| 채널                 | 1(mono)              |
| 오디오 당 최대 길이 | 2시간               |
| 샘플 형식            | PCM, 16비트           |
| 보관 형식           | .zip                  |
| 최대 보관 크기     | 2GB                  |

[!INCLUDE [supported-audio-formats](includes/supported-audio-formats.md)]

> [!TIP]
> 학습 및 테스트 데이터를 업로드할 때 .zip 파일 크기는 2gb를 초과할 수 없습니다. 학습에 더 많은 데이터를 요구 하는 경우 여러 개의 .zip 파일로 나누고 별도로 업로드 합니다. 나중에 *여러* 데이터 집합에서 학습 하도록 선택할 수 있습니다. 그러나 *단일* 데이터 집합 에서만 테스트할 수 있습니다.

<a href="http://sox.sourceforge.net" target="_blank" rel="noopener">SoX <span class="docon docon-navigate-external x-hidden-focus"></span> </a> 를 사용 하 여 오디오 속성을 확인 하거나 기존 오디오를 적절 한 형식으로 변환 합니다. 다음은 이러한 각 활동을 SoX 명령줄을 통해 수행할 수 있는 방법에 대 한 몇 가지 예입니다.

| 작업 | Description | SoX 명령 |
|----------|-------------|-------------|
| 오디오 형식 확인 | 다음 명령을 사용 하 여 확인 합니다.<br>오디오 파일 형식입니다. | `sox --i <filename>` |
| 오디오 형식 변환 | 다음 명령을 사용 하 여 변환 합니다.<br>단일 채널에 대 한 오디오 파일 (16 비트, 16 KHz)입니다. | `sox <input> -b 16 -e signed-integer -c 1 -r 16k -t wav <output>.wav` |

## <a name="audio--human-labeled-transcript-data-for-testingtraining"></a>테스트/학습을 위해 오디오 + 사람이 레이블 지정 된 성적 증명서 데이터

오디오 파일을 처리할 때 Microsoft의 음성-텍스트 정확도 정확도를 측정 하려면 비교를 위해 사용자에 게 레이블이 지정 된 음성-텍스트 (word)를 제공 해야 합니다. 사람이 레이블 지정 된 기록을 사용 하는 경우가 종종 있지만 정확성을 평가 하 고 사용 사례에 맞게 모델을 학습 해야 합니다. 인식의 향상 된 기능은 제공 된 데이터 만큼만 적절 합니다. 따라서 고품질의 증명서만 업로드 하는 것이 중요 합니다.

오디오 파일은 기록의 시작과 끝에 소리가 있을 수 있습니다. 가능 하면 각 샘플 파일에서 음성 앞과 뒤에 소리 하나 이상을 포함 합니다. 녹음 볼륨이 낮거나 배경 노이즈가 심한 오디오는 유용 하지 않지만 사용자 지정 모델을 사용 하면 안 됩니다. 오디오 샘플을 수집 하기 전에 항상 마이크 및 신호 처리 하드웨어를 업그레이드 하는 것이 좋습니다.

| 속성                 | 값                               |
|--------------------------|-------------------------------------|
| 파일 형식              | RIFF(WAV)                          |
| 샘플 속도              | 8000 hz 또는 16000 Hz               |
| 채널                 | 1(mono)                            |
| 오디오 당 최대 길이 | 2 시간 (테스트)/60 s (교육) |
| 샘플 형식            | PCM, 16비트                         |
| 보관 형식           | .zip                                |
| 최대 zip 크기         | 2GB                                |

[!INCLUDE [supported-audio-formats](includes/supported-audio-formats.md)]

> [!NOTE]
> 학습 및 테스트 데이터를 업로드할 때 .zip 파일 크기는 2gb를 초과할 수 없습니다. *단일* 데이터 집합 에서만 테스트할 수 있으며, 적절 한 파일 크기 내에서 유지 해야 합니다. 또한 각 학습 파일은 60 초를 초과할 수 없습니다. 그렇지 않으면 오류가 발생 합니다.

단어 삭제 또는 대체와 같은 문제를 해결 하기 위해 많은 양의 데이터가 필요 하므로 인식 기능을 향상 시킬 수 있습니다. 일반적으로 약 10 ~ 20 시간의 오디오에 대해 word를 통해 word를 제공 하는 것이 좋습니다. 모든 WAV 파일에 대한 전사는 단일 일반 텍스트 파일에 포함되어야 합니다. 전사 파일의 각 줄은 오디오 파일 중 하나의 이름을 포함하고 그 뒤에 해당 전사가 와야 합니다. 파일 이름과 전사는 탭(\t)으로 구분 해야 합니다.

예를 들면 다음과 같습니다.

<!-- The following example contains tabs. Don't accidentally convert these into spaces. -->

```input
speech01.wav    speech recognition is awesome
speech02.wav    the quick brown fox jumped all over the place
speech03.wav    the lazy dog was not amused
```

> [!IMPORTANT]
> 전사는 UTF-8 BOM으로 인코딩해야 합니다.

전사는 시스템에서 처리할 수 있도록 텍스트로 정규화됩니다. 그러나 데이터를 Speech Studio로 업로드 하기 전에 수행 해야 하는 몇 가지 중요 한 normalizations 있습니다. 사용자를 준비할 때 사용할 적절 한 언어는 [사람이 레이블 지정 된 기록을 만드는 방법](how-to-custom-speech-human-labeled-transcriptions.md) 을 참조 하세요.

오디오 파일 및 해당 하는 해당 하는 항목을 수집한 후에는 <a href="https://speech.microsoft.com/customspeech" target="_blank">음성 스튜디오 <span class="docon docon-navigate-external x-hidden-focus"></span> </a>에 업로드 하기 전에 단일 .zip 파일로 패키지 합니다. 다음은 3 개의 오디오 파일과 사람이 레이블이 지정 된 기록 파일이 있는 예제 데이터 집합입니다.

> [!div class="mx-imgBorder"]
> ![음성 포털에서 오디오를 선택 합니다.](./media/custom-speech/custom-speech-audio-transcript-pairs.png)

음성 서비스 구독에 대해 권장 되는 지역 목록은 [Azure 계정 설정](custom-speech-overview.md#set-up-your-azure-account) 을 참조 하세요. 이러한 지역 중 하나에서 음성 구독을 설정 하면 모델을 학습 하는 데 걸리는 시간이 줄어듭니다. 이러한 지역에서 교육은 하루에 약 10 시간의 오디오를 하루에 한 시간에 한 번만 다른 지역에서 처리할 수 있습니다. 모델 학습을 일주일 내에 완료할 수 없는 경우에는 모델이 실패로 표시 됩니다.

모든 기본 모델에서 오디오 데이터로의 학습을 지 원하는 것은 아닙니다. 기본 모델에서이를 지원 하지 않는 경우 서비스는 오디오를 무시 하 고, 바로 텍스트를 사용 하 여 학습 합니다. 이 경우 학습은 관련 텍스트의 학습 과정과 동일 합니다. 오디오 데이터로 학습을 지 원하는 기본 모델 목록은 [언어 지원](language-support.md#speech-to-text) 을 참조 하세요.

## <a name="related-text-data-for-training"></a>학습에 대 한 관련 텍스트 데이터

고유 하 게 제공 되는 제품 이름 또는 기능에는 학습을 위해 관련 텍스트 데이터를 포함 해야 합니다. 관련 텍스트를 통해 올바른 인식을 보장할 수 있습니다. 인식 기능을 향상 시키기 위해 다음과 같은 두 가지 유형의 관련 텍스트 데이터를 제공할 수 있습니다.

| 데이터 형식 | 이 데이터가 인식 기능을 향상 시키는 방법 |
|-----------|------------------------------------|
| 문장 (길이 발언) | 문장의 컨텍스트 내에서 제품 이름 또는 산업별 어휘를 인식할 때 정확성을 향상 시킵니다. |
| 발음 | 특수 하지 않은 용어, 머리글자어 또는 기타 단어 (정의 되지 않은 발음)의 발음을 개선 합니다. |

문장은 단일 텍스트 파일 또는 여러 텍스트 파일로 제공 될 수 있습니다. 정확도를 높이기 위해 예상 되는 음성 길이 발언 더 가까운 텍스트 데이터를 사용 합니다. 발음는 단일 텍스트 파일로 제공 되어야 합니다. 모든 항목은 단일 zip 파일로 패키지 하 여 <a href="https://speech.microsoft.com/customspeech" target="_blank">음성 스튜디오 <span class="docon docon-navigate-external x-hidden-focus"></span> </a>에 업로드할 수 있습니다.

관련 텍스트로의 교육은 일반적으로 몇 분 이내에 완료 됩니다.

### <a name="guidelines-to-create-a-sentences-file"></a>문장 파일을 만들기 위한 지침

문장을 사용 하 여 사용자 지정 모델을 만들려면 샘플 길이 발언 목록을 제공 해야 합니다. 길이 발언는 완전 하거나 문법적으로 정확 하 게 지정할 필요는 없지만 프로덕션 _에서 필요한 음성_ 입력을 정확 하 게 반영 해야 합니다. 특정 조건의 가중치가 증가 하도록 하려면 이러한 특정 용어를 포함 하는 여러 문장을 추가 합니다.

일반적으로 모델 적응은 학습 텍스트가 프로덕션 환경에서 예상 되는 실제 텍스트와 최대한 가까운 경우에 가장 효과적입니다. 개선을 위해 대상으로 지정 하려는 도메인별 용어 및 구가 학습 텍스트에 포함 되어야 합니다. 가능 하면 하나의 문장이 나 키워드를 별도의 줄에 제어 해 보세요. 사용자에 게 중요 한 키워드 및 구 (예: 제품 이름)의 경우 여러 번 복사할 수 있습니다. 그러나 너무 많이 복사 하지 마세요. 전체 인식 요금에 영향을 줄 수 있습니다.

이 표를 사용 하 여 길이 발언에 대 한 관련 데이터 파일의 형식이 올바르게 지정 되었는지 확인 합니다.

| 속성 | 값 |
|----------|-------|
| 텍스트 인코딩 | UTF-8 BOM |
| 줄당 발언의 # | 1 |
| 최대 파일 크기 | 200MB |

또한 다음과 같은 제한 사항을 고려해 야 합니다.

* 문자, 단어 또는 단어 그룹을 세 번 이상 반복 하지 마십시오. 예를 들면 "aaaa", "yes yes yes yes", or "입니다. 음성 서비스는 반복이 너무 많은 줄을 삭제할 수 있습니다.
* 위의 특수 문자나 UTF-8 문자는 사용 하지 마십시오 `U+00A1` .
* Uri는 거부 됩니다.

### <a name="guidelines-to-create-a-pronunciation-file"></a>발음 파일을 만들기 위한 지침

사용자가 발생 하거나 사용할 표준 발음 없는 자주 사용 되는 용어가 없는 경우 사용자 지정 음성 파일을 제공 하 여 인식 기능을 향상 시킬 수 있습니다.

> [!IMPORTANT]
> 사용자 지정 발음 파일을 사용 하 여 일반적인 단어의 발음을 변경 하는 것은 권장 되지 않습니다.

여기에는 음성 utterance의 예제와 각각에 대 한 사용자 지정 발음이 포함 됩니다.

| 인식/표시 양식 | 발성 형식 |
|--------------|--------------------------|
| 3CPO | 3 개의 c p o |
| CNTK | c n t k |
| IEEE | i 삼중 e |

음성 형식은 철자를 확인 하는 음성입니다. 문자, 단어, 음절 또는 3의 조합으로 구성 될 수 있습니다.

사용자 지정 된 발음은 영어 ( `en-US` ) 및 독일어 ()로 제공 됩니다 `de-DE` . 다음 표에서는 언어에 따라 지원 되는 문자를 보여 줍니다.

| 언어 | Locale | 문자 |
|----------|--------|------------|
| 영어 | `en-US` | `a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z` |
| 독일어 | `de-DE` | `ä, ö, ü, a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z` |

다음 표를 사용 하 여 발음에 대 한 관련 데이터 파일의 형식이 올바르게 지정 되었는지 확인 합니다. 발음 파일은 작으며 크기가 몇 킬로바이트 여야 합니다.

| 속성 | 값 |
|----------|-------|
| 텍스트 인코딩 | UTF-8 BOM (ANSI도 영어에 대해 지원 됨) |
| 줄 당 발음 수 | 1 |
| 최대 파일 크기 | 1mb (무료 계층의 경우 1kb) |

## <a name="next-steps"></a>다음 단계

* [데이터 검사](how-to-custom-speech-inspect-data.md)
* [데이터 평가](how-to-custom-speech-evaluate-data.md)
* [모델 학습](how-to-custom-speech-train-model.md)
* [모델 배포](./how-to-custom-speech-train-model.md)