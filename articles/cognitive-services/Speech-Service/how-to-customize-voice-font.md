---
title: 사용자 지정 음성 글꼴을 만드는 방법
titlesuffix: Azure Cognitive Services
description: 이 문서는 인식 가능한, 독특한 브랜드의 음성을 만들 수 있는 Text to Speech 음성 사용자 지정에 대한 개요입니다.
services: cognitive-services
author: PanosPeriorellis
manager: cgronlun
ms.service: cognitive-services
ms.component: speech-service
ms.topic: conceptual
ms.date: 05/07/2018
ms.author: panosper
ms.openlocfilehash: bf06042d3b820e61d1f5b316a8b7b26d1a366388
ms.sourcegitcommit: 62759a225d8fe1872b60ab0441d1c7ac809f9102
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 10/19/2018
ms.locfileid: "49467721"
---
# <a name="creating-custom-voice-fonts"></a>사용자 지정 음성 글꼴 만들기

TTS(Text to Speech) 음성 사용자 지정을 사용하면 인식 가능한, 독특한 브랜드의 음성인 *음성 글꼴*을 만들 수 있습니다. 

음성 글꼴을 만들려면 스튜디오에서 녹음한 후 관련 스크립트를 학습 데이터로서 업로드합니다. 그러면 이 서비스는 녹음한 음성에 맞게 튜닝된 고유한 음성 모델을 만듭니다. 이 음성 글꼴을 사용하여 음성을 합성할 수 있습니다. 

개념 증명을 위해 소량의 데이터로 시작할 수 있습니다. 그러나 더 많은 데이터를 제공할수록 음성의 자연스러움과 전문성이 높아집니다.

## <a name="prerequisites"></a>필수 조건

Azure 계정 및 Speech Service에 대한 구독이 필요합니다. 구독이 아직 없다면 [하나를 만듭니다](https://docs.microsoft.com/azure/cognitive-services/speech-service/get-started). 여기에 표시된 대로 구독을 Custom Voice 포털에 연결합니다.

1. 액세스 권한을 신청하는 데 사용한 것과 동일한 Microsoft 계정을 사용하여 [Custom Voice 포털](https://customvoice.ai)에 로그온합니다.

2. 오른쪽 위의 계정 이름 아래에서 **구독**으로 이동합니다.

    ![구독](media/custom-voice/subscriptions.png)

3. 구독 페이지에서 **기존 구독 연결**을 선택합니다. Speech Services는 서로 다른 지역을 지원합니다. 구독 키를 만든 지역을 확인하고, 키를 올바른 하위 포털에 연결하도록 합니다.  

4. 다음 예제와 같이 구독 키를 표에 붙여 넣습니다. 각 구독에는 두 개의 키가 있으며 둘 중 하나를 사용할 수 있습니다.

     ![구독 추가](media/custom-voice/add-subscription.png)

이제 준비가 되었습니다.

## <a name="prepare-recordings-and-transcripts"></a>녹음 및 스크립트 준비

음성 학습 데이터 세트는 오디오 파일 집합과, 오디오 파일의 스크립트가 포함된 텍스트 파일로 구성되어 있습니다.

두 가지 방법으로 이러한 파일을 준비할 수 있습니다. 기록을 작성한 후 성우가 읽도록 하거나, 공개적으로 사용 가능한 오디오를 사용하고 텍스트로 기록합니다. 후자의 경우 오디오 파일에서 "음" 및 기타 추임새, 더듬거림, 중얼거리는 말이나 틀린 발음 등을 편집합니다.

음성 글꼴의 품질을 높이려면 고사양의 마이크를 사용하여 조용한 방에서 녹음합니다. 일관된 볼륨, 말하기 속도, 높낮이 및 표현적 기법은 훌륭한 디지털 음성을 작성하는 데 필수적입니다. 

프로덕션용으로 음성을 만들려면 전문적인 녹음 스튜디오에서 성우가 녹음하도록 하는 것이 좋습니다. 자세한 내용은 [사용자 지정 음성에 대한 음성 샘플을 녹음하는 방법](record-custom-voice-samples.md)을 참조하세요.

### <a name="audio-files"></a>오디오 파일

각 오디오 파일에는 하나의 발화(예: 단일 문장 또는 대화 체계의 한 순서)가 포함되어야 합니다. 모든 파일은 동일한 언어여야 합니다. (다국어 사용자 지정 음성은 지원되지 않습니다.) 또한 오디오 파일 각각에는 파일 이름 확장명 `.wav`를 사용한 고유한 숫자 파일 이름이 있어야 합니다.

오디오 파일은 다음과 같이 준비해야 합니다. 다른 형식은 지원되지 않으며 거부됩니다.

| **속성** | **값** |
| ------------ | --------- |
| 파일 형식  | RIFF(.wav)|
| 샘플링 레이트| 최소 16,000Hz |
| 샘플 형식| PCM, 16비트 |
| 파일 이름    | 숫자(`.wav` 확장명 포함) |
| 보관 형식| .zip      |
| 최대 보관 크기|200MB|

> [!NOTE]
> 샘플링 주기가 16,000Hz보다 낮은 .wav 파일은 거부됩니다. .zip 파일에 다른 샘플링 주기가 포함되어 있는 경우 16,000Hz보다 같거나 높은 파일만 가져옵니다.
> 현재, 포털은 최대 200MB의 .zip 보관 파일을 가져옵니다. 그러나 여러 보관 파일을 업로드할 수 있습니다. 허용되는 데이터 세트의 최대 수는 무료 구독 사용자의 경우 10개 .zip 파일이고, 표준 구독 사용자의 경우 50개입니다.

### <a name="transcripts"></a>스크립트(Transcript)

스크립트 파일은 일반 텍스트 파일(ANSI, UTF-8, UTF-8-BOM, UTF-16-LE 또는 UTF-16-BE)입니다. 스크립트 파일의 각 줄에는 오디오 파일의 이름, 탭(코드 포인트 9) 문자, 해당 스크립트가 순서대로 포함되어야 합니다. 빈 줄은 허용되지 않습니다.

예: 

```
0000000001  This is the waistline, and it's falling.
0000000002  We have trouble scoring.
0000000003  It was Janet Maslin.
```

사용자 지정 음성 시스템은 텍스트를 소문자로 변환하고 불필요한 문장 부호를 제거하여 스크립트를 정규화합니다. 스크립트는 해당 오디오 녹음과 100% 정확히 일치하는 것이 중요합니다.

> [!TIP]
> 프로덕션용 Text-to-Speech 음성을 작성할 때는 음성 적용 범위와 효율성을 둘 다 고려해서 발화를 선택(또는 스크립트를 작성)합니다. 원하는 결과를 얻는 데 문제가 있으세요? 문의하기에 관한 자세한 내용을 알아보려면 [사용자 지정 음성 팀에 문의](mailto:tts@microsoft.com)하세요.

## <a name="upload-your-datasets"></a>데이터 세트 업로드

오디오 파일 보관 및 스크립트를 준비한 후에는 [Custom Voice 서비스 포털](https://customvoice.ai)을 통해 업로드합니다.

> [!NOTE]
> 데이터 세트를 업로드한 후에는 편집할 수 없습니다. 예를 들어, 일부 오디오 파일의 스크립트를 포함하는 것을 잊었거나 실수로 잘못된 성별을 선택하게 되면 전체 데이터 세트를 다시 업로드해야 합니다. 업로드를 시작하기 전에 데이터 세트 및 설정을 철저히 확인하세요.

1. 포털에 로그인합니다.

2. 주 페이지에서 **사용자 지정 음성** 아래의 **데이터**를 선택합니다.   

    **내 음성** 테이블이 표시됩니다. 음성 데이터 세트를 아직 업로드하지 않았으면 이 테이블이 빈 상태로 표시됩니다.

3. **데이터 가져오기**를 클릭하여 새 데이터 집합을 업로드하기 위한 페이지를 엽니다. 

    ![음성 데이터 가져오기](media/custom-voice/import-voice-data.png)

4. 제공된 필드에 이름 및 설명을 입력합니다. 

5. 음성 글꼴에 대한 로캘을 선택합니다. 로캘 정보가 녹음 데이터 및 스크립트의 언어와 일치하는지 확인합니다. 

6. 해당 음성을 사용하려는 화자의 성별을 선택합니다.

7. 업로드할 스크립트 및 오디오 파일을 선택합니다. 

8. **가져오기**를 선택하여 데이터를 업로드합니다. 데이터 세트가 더 큰 경우 가져오는 데 몇 분 정도 걸릴 수 있습니다.

> [!NOTE]
> 무료 구독 사용자는 한 번에 두 개의 데이터 세트를 업로드할 수 있습니다. 표준 구독 사용자는 5개의 데이터 세트를 동시에 업로드할 수 있습니다. 업로드 개수가 초과되면 적어도 한 개의 데이터 세트에 대한 가져오기가 완료될 때까지 기다립니다. 그런 다음, 다시 시도하세요.

업로드가 완료되면 **내 음성 데이터** 테이블이 다시 나타납니다. 방금 업로드한 데이터 세트에 해당하는 항목을 볼 수 있습니다. 

데이터 세트는 업로드 후 자동으로 유효성이 검사됩니다. 데이터 유효성 검사에는 오디오 파일의 파일 형식, 크기 및 샘플링 레이트를 확인하는 일련의 검사가 포함됩니다. 스크립트 파일에 대한 검사를 통해 파일 형식의 유효성이 확인되고 일부 텍스트 정규화가 진행됩니다. 발화가 음성 인식을 통해 스크립트로 작성됩니다. 그런 다음, 결과 텍스트는 사용자가 제공한 기록와 비교됩니다.

![내 음성 데이터](media/custom-voice/my-voice-data.png)

다음 표에서는 가져온 데이터 세트에 대한 처리 상태를 보여 줍니다. 

| 시스템 상태 | 의미
| ----- | -------
| `NotStarted` | 데이터 세트가 수신되었으며 처리 대기 중입니다.
| `Running` | 데이터 세트의 유효성 검사가 진행 중입니다.
| `Succeeded` | 데이터 세트의 유효성이 검사되었으며 음성 글꼴을 만드는 데 사용할 준비가 되었습니다.

유효성 검사가 완료되면 **발화** 열의 각 데이터 세트에 대해 일치하는 발화의 총 개수를 확인할 수 있습니다.

보고서를 다운로드하여 각 녹음에 대해 발음 점수 및 잡음 수준을 확인할 수 있습니다. 발음 점수의 범위는 0에서 100까지입니다.  일반적으로 70점 아래의 점수는 음성 오류 또는 스크립트 불일치를 나타냅니다. 악센트가 강하면 발음 점수를 떨어뜨리고 생성된 디지털 음성에 영향을 줄 수 있습니다.

SNR(신호 대 잡음 비율)이 더 높을 수록 오디오의 잡음이 더 낮은 것입니다. 일반적으로 전문 스튜디오에서 녹음하면 50 이상의 SNR에 도달할 수 있습니다. SNR이 20보다 낮은 오디오는 생성된 음성에서 잡음이 뚜렷하게 들릴 수 있습니다.

발음 점수가 낮거나 신호 대 잡음 비율이 떨어지는 모든 발화는 다시 녹음하는 것이 좋습니다. 다시 녹음할 수 없다면 해당 발화를 데이터 세트에서 제외할 수 있습니다.

## <a name="build-your-voice-font"></a>음성 글꼴 작성

유효성이 검사된 데이터 세트는 사용자 지정 음성 글꼴을 작성하는 데 사용할 수 있습니다. 

1.  **사용자 지정 음성** 드롭다운 메뉴에서 **모델**을 선택합니다.
 
    **내 음성 글꼴** 테이블이 나타나고 이미 만든 사용자 지정 음성 글꼴이 모두 표시됩니다.

1. 테이블 제목 아래에 있는 **음성 만들기**를 클릭합니다. 

    음성 글꼴을 만들기 위한 페이지가 나타납니다. 현재 로캘이 테이블의 첫 번째 행에 표시됩니다. 다른 언어로 음성을 만들려면 로캘을 변경합니다. 로캘은 음성을 만드는 데 사용되는 데이터 세트와 같아야 합니다.

1. 데이터 세트를 업로드했을 때처럼 이 모델을 식별하는 데 도움이 되는 이름과 설명을 입력합니다. 

    신중하게 이름을 선택합니다. 여기에 입력한 이름은 음성 합성 요청에서 음성을 지정할 때 SSML 입력의 일부로 사용됩니다. 문자, 숫자 및 몇 가지 문장 부호 문자(예: '-', '_' '(', ')')만 허용됩니다.

    **설명** 필드의 일반적인 용도는 모델을 만드는 데 사용된 데이터 집합의 이름을 기록하는 것입니다.

1. 음성 글꼴의 성별을 선택합니다. 데이터 세트의 성별과 일치해야 합니다.

1. 음성 글꼴을 학습하는 데 사용하려는 데이터 세트를 선택합니다. 사용되는 모든 데이터 세트는 같은 화자가 말한 것이어야 합니다.

1. **Create**(만들기)를 클릭하여 음성 글꼴 만들기를 시작합니다.

    ![모델 만들기](media/custom-voice/create-model.png)

새 모델이 **내 음성 글꼴** 테이블에 나타납니다. 

![내 음성 글꼴](media/custom-voice/my-voice-fonts.png)

테이블에 표시되는 상태는 다음과 같이 데이터 세트를 음성 글꼴로 변환하는 프로세스를 반영합니다.

| 시스템 상태 | 의미
| ----- | -------
| `NotStarted` | 음성 글꼴 만들기 요청이 처리를 위해 대기 중입니다.
| `Running` | 음성 글꼴을 만들고 있습니다.
| `Succeeded` | 음성 글꼴을 만들었으며 배포할 수 있습니다.

학습 시간은 처리되는 오디오 데이터의 양에 따라 달라집니다. 일반적인 시간 범위는 수백 개 발화에 해당하는 약 30분에서 20,000개 발화에 해당하는 40시간 정도입니다.

> [!NOTE]
> 무료 구독 사용자는 한 번에 한 가지 음성 글꼴을 학습할 수 있습니다. 표준 구독 사용자는 3개의 음성을 동시에 학습(train)할 수 있습니다. 이 제한에 도달하면 하나 이상의 음성 글꼴에 대한 학습이 완료될 때까지 기다린 후 다시 시도하세요.

## <a name="test-your-voice-font"></a>음성 글꼴 테스트

음성 글꼴을 성공적으로 작성한 후에는 사용을 위해 배포하기 전에 테스트할 수 있습니다. **작업** 열에서 **테스트**를 클릭합니다. 선택한 음성 글꼴에 대한 테스트 페이지가 표시됩니다. 음성에 대한 테스트 요청을 아직 제출하지 않은 경우에는 이 테이블이 비어 있습니다.

테이블 제목 아래에 있는 **텍스트로 테스트** 단추를 클릭하여 텍스트 요청 제출을 위한 팝업 메뉴를 표시합니다. 텍스트 요청은 일반 텍스트 또는 SSML로 제출할 수 있습니다. 최대 입력 크기는 SSML 요청에 대한 모든 태그를 포함하여 1,024자입니다. 텍스트의 언어는 음성 글꼴의 언어와 같아야 합니다.

텍스트 상자에 입력하고 입력 모드를 확인한 후 **예**를 클릭하여 테스트 요청을 제출하고 테스트 페이지로 돌아갑니다. 이제 테이블에는 새 요청에 해당하는 항목과 익숙한 상태 열이 포함됩니다. 음성을 합성하는 데 몇 분 정도 걸릴 수 있습니다. 상태 열에 **성공**이 표시되면 텍스트 입력(`.txt` 파일) 및 오디오 출력(`.wav` 파일)을 다운로드하고 오디오 출력을 들어보면서 품질을 확인할 수 있습니다.

## <a name="create-and-use-a-custom-endpoint"></a>사용자 지정 엔드포인트 만들기 및 사용

음성 모델을 성공적으로 만들고 테스트한 후에는 사용자 지정 Text to Speech 엔드포인트로 배포합니다. 그런 다음, REST API를 통해 Text to Speech 요청을 수행할 때 일반적인 엔드포인트 대신 이 엔드포인트를 사용합니다. 사용자 지정 엔드포인트는 글꼴을 배포하는 데 사용한 구독으로만 호출할 수 있습니다.

새 사용자 지정 엔드포인트를 만들려면 페이지 맨 위에 있는 **사용자 지정 음성** 메뉴에서 **엔드포인트**를 선택합니다. **내 배포된 음성** 페이지가 나타나고 현재 사용자 지정 음성 끝점 테이블(있는 경우)이 표시됩니다. 현재 로캘이 테이블의 첫 번째 행에 반영됩니다. 다른 언어에 대한 배포를 만들려면 표시된 로캘을 변경합니다. (배포하는 음성과 일치해야 합니다.)

**음성 배포** 단추를 선택하여 새 엔드포인트를 만듭니다. 사용자 지정 엔드포인트의 이름 및 설명을 입력합니다.

**구독** 메뉴에서 사용하려는 구독을 선택합니다. 무료 구독 사용자는 한 번에 하나의 모델만 배포할 수 있습니다. 표준 구독 사용자는 각각 자체 사용자 지정 음성이 있는 최대 20개의 엔드포인트를 만들 수 있습니다.

![엔드포인트 만들기](media/custom-voice/create-endpoint.png)

배포할 모델을 선택한 다음, **만들기**를 선택합니다. **내 배포된 음성** 페이지가 다시 나타나고, 이제 새 끝점에 대한 항목이 표시됩니다. 새 엔드포인트를 인스턴스화하는 데 몇 분 정도 걸릴 수 있습니다. 배포 상태가 **성공**이면 엔드포인트를 사용할 준비가 완료된 것입니다.

![내 배포된 음성](media/custom-voice/my-deployed-voices.png)

배포 상태가 **성공**이면 배포된 음성 글꼴의 엔드포인트가 **내 배포된 음성** 테이블에 표시됩니다. 이 URI를 HTTP 요청에서 직접 사용할 수 있습니다.

엔드포인트의 온라인 테스트도 Custom Voice 포털을 통해 사용할 수 있습니다. 엔드포인트를 테스트하려면 **사용자 지정 음성** 드롭다운 메뉴에서 **엔드포인트 테스트**를 선택합니다. 엔드포인트 테스트 페이지가 나타납니다. 배포된 사용자 지정 음성을 선택하고 텍스트 상자에 읽을 텍스트를 입력합니다(일반 텍스트 또는 SSML 형식으로).

> [!NOTE] 
> SSML을 사용하는 경우, `<voice>` 태그에는 사용자 지정 음성을 만들 때 설정한 이름을 지정해야 합니다. 일반 텍스트를 제출하는 경우 항상 사용자 지정이 사용됩니다.

**재생**을 선택하여 사용자 지정 음성 글꼴로 말해지는 텍스트를 들어봅니다.

![엔드포인트 테스트](media/custom-voice/endpoint-testing.png)

사용자 지정 엔드포인트는 텍스트 음성 변환 요청에 사용되는 표준 엔드포인트와 기능적으로 동일합니다. 자세한 내용은 [REST API](rest-apis.md)를 참조하세요.

## <a name="language-support"></a>언어 지원

음성 사용자 지정이 가능한 언어는 미국 영어(en-US), 본토 중국어(zh-CN) 및 이탈리아어(it-IT)입니다.

> [!NOTE]
> 이탈리아 음성 학습은 2,000개 이상의 발언으로 이루어진 데이터 세트로 시작합니다. 중국어-영어 이중 언어 모델도 2,000개 이상의 발화로 이루어진 데이터 세트로 지원됩니다.

## <a name="next-steps"></a>다음 단계

- [음성 평가판 구독 가져오기](https://azure.microsoft.com/try/cognitive-services/)
- [음성 샘플 기록](record-custom-voice-samples.md)
