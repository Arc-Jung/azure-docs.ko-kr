---
title: 사용자 지정 음성-음성 서비스 만들기
titleSuffix: Azure Cognitive Services
description: 데이터를 업로드할 준비가 되 면 사용자 지정 음성 포털로 이동 합니다. 사용자 지정 음성 프로젝트를 만들거나 선택 합니다. 프로젝트는 음성 학습에 사용 하려는 데이터와 올바른 언어/로캘 및 성별 속성을 공유 해야 합니다.
services: cognitive-services
author: erhopf
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 11/04/2019
ms.author: erhopf
ms.openlocfilehash: 541448f08e4ce9961d34063dcc225bf89d969a73
ms.sourcegitcommit: 910a1a38711966cb171050db245fc3b22abc8c5f
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/20/2021
ms.locfileid: "101703374"
---
# <a name="create-a-custom-voice"></a>사용자 지정 음성 만들기

[사용자 지정 음성에 대 한 데이터 준비](how-to-custom-voice-prepare-data.md)에서는 사용자 지정 음성 및 다양 한 형식 요구 사항을 학습 하는 데 사용할 수 있는 다양 한 데이터 형식에 대해 설명 했습니다. 데이터를 준비한 후 [사용자 지정 음성 포털](https://aka.ms/custom-voice-portal)또는 사용자 지정 음성 학습 API를 통해 업로드를 시작할 수 있습니다. 여기서는 포털을 통해 사용자 지정 음성을 학습 하는 단계를 설명 합니다.

> [!NOTE]
> 이 페이지에서는 사용자 지정 음성 [시작](how-to-custom-voice.md) 및 사용자 지정 음성 [에 대 한 데이터 준비](how-to-custom-voice-prepare-data.md)를 읽고 사용자 지정 음성 프로젝트를 만들었다고 가정 합니다.

사용자 지정 음성: [언어](language-support.md#customization)에 대해 지원 되는 언어를 확인 합니다.

## <a name="upload-your-datasets"></a>데이터 세트 업로드

데이터를 업로드할 준비가 되 면 [사용자 지정 음성 포털로](https://aka.ms/custom-voice-portal)이동 합니다. 사용자 지정 음성 프로젝트를 만들거나 선택 합니다. 프로젝트는 음성 학습에 사용 하려는 데이터와 올바른 언어/로캘 및 성별 속성을 공유 해야 합니다. 예를 들어, `en-GB` 사용자가 있는 오디오 녹음 내용이 영국 악센트를 사용 하 여 영어로 완료 된 경우를 선택 합니다.

**데이터** 탭으로 이동 하 고 **데이터 업로드** 를 클릭 합니다. 마법사에서 준비한 항목과 일치 하는 올바른 데이터 형식을 선택 합니다.

업로드 하는 각 데이터 집합은 사용자가 선택 하는 데이터 형식에 대 한 요구 사항을 충족 해야 합니다. 업로드 하기 전에 데이터의 서식을 올바르게 지정 하는 것이 중요 합니다. 이렇게 하면 사용자 지정 음성 서비스에서 데이터를 정확 하 게 처리할 수 있습니다. [사용자 지정 음성의 데이터 준비](how-to-custom-voice-prepare-data.md) 로 이동 하 여 데이터의 형식이 최적의 확인 합니다.

> [!NOTE]
> 무료 구독 (F0) 사용자는 두 데이터 집합을 동시에 업로드할 수 있습니다. 표준 구독 (S0) 사용자는 5 개의 데이터 집합을 동시에 업로드할 수 있습니다. 업로드 개수가 초과되면 적어도 한 개의 데이터 세트에 대한 가져오기가 완료될 때까지 기다립니다. 그런 다음, 다시 시도하세요.

> [!NOTE]
> 구독 당 가져올 수 있는 최대 데이터 집합 수는 무료 구독 (F0) 사용자의 경우 10 개의 .zip 파일이 고, 표준 구독 (S0) 사용자의 경우 500입니다.

업로드 단추를 누르면 데이터 집합의 유효성이 자동으로 검사 됩니다. 데이터 유효성 검사에는 파일 형식, 크기 및 샘플링 주기를 확인할 수 있는 오디오 파일의 일련의 검사가 포함 되어 있습니다. 오류를 수정 하 고 다시 제출 합니다. 데이터 가져오기 요청이 성공적으로 시작 되 면 방금 업로드 한 데이터 집합에 해당 하는 데이터 테이블의 항목이 표시 됩니다.

다음 표에서는 가져온 데이터 세트에 대한 처리 상태를 보여 줍니다.

| 시스템 상태 | 의미 |
| ----- | ------- |
| 처리 중 | 데이터 집합을 수신 하 여 처리 하 고 있습니다. |
| 성공 | 데이터 집합의 유효성을 검사 하 고 이제 음성 모델을 빌드하는 데 사용할 수 있습니다. |
| 실패 | 여러 가지 원인 (예: 파일 오류, 데이터 문제 또는 네트워크 문제)으로 인해 처리 하는 동안 데이터 집합에 오류가 발생 했습니다. |

유효성 검사가 완료 된 후 **길이 발언** 열에서 각 데이터 집합에 대해 일치 하는 길이 발언의 총 수를 볼 수 있습니다. 선택한 데이터 형식에 긴 오디오 조각화가 필요한 경우이 열에는 기록에 따라 또는 음성 기록 서비스를 통해 사용자가 분할 한 길이 발언 반영 됩니다. 유효성을 검사 한 데이터 집합을 추가로 다운로드 하 여 성공적으로 가져온 길이 발언의 세부 결과와 해당 매핑 기록을 볼 수 있습니다. 힌트: 긴 오디오 조각화는 데이터 처리를 완료 하는 데 1 시간 이상 걸릴 수 있습니다.

데이터 세부 정보 보기에서 각 데이터 집합에 대 한 발음 점수와 노이즈 수준을 추가로 확인할 수 있습니다. 발음 점수의 범위는 0에서 100까지입니다. 일반적으로 70점 아래의 점수는 음성 오류 또는 스크립트 불일치를 나타냅니다. 악센트가 강하면 발음 점수를 떨어뜨리고 생성된 디지털 음성에 영향을 줄 수 있습니다.

SNR(신호 대 잡음 비율)이 더 높을 수록 오디오의 잡음이 더 낮은 것입니다. 일반적으로 전문 스튜디오에서 녹음하면 50 이상의 SNR에 도달할 수 있습니다. SNR이 20보다 낮은 오디오는 생성된 음성에서 잡음이 뚜렷하게 들릴 수 있습니다.

발음 점수가 낮거나 신호 대 잡음 비율이 떨어지는 모든 발화는 다시 녹음하는 것이 좋습니다. 다시 녹음할 수 없다면 해당 발화를 데이터 세트에서 제외할 수 있습니다.

> [!NOTE]
> 사용자 지정 신경망을 사용 하는 경우 voice **인재** 탭에서 음성 인재을 등록 해야 합니다. 기록 스크립트를 준비할 때는 음성 데이터를 사용 하 여 TTS 음성 모델을 만들고 가상 음성을 생성 하는 음성 인재 승인을 받을 수 있도록 아래 문장을 포함 해야 합니다. "I [first 및 last name] am은 내 음성 기록을 [회사 이름]에서 사용 하 여 내 음성의 가상 버전을 만들고 사용 하는 것을 인식 합니다."
이 문장은 학습 데이터 집합의 기록이 동의를 주는 동일한 사람에 의해 수행 되었는지 여부를 확인 하는 데 사용 됩니다. [데이터를 처리 하는 방법 및 여기에서 음성 인재 확인을 수행 하는 방법에 대해 자세히](/legal/cognitive-services/speech-service/custom-neural-voice/data-privacy-security-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext)알아보세요. 

## <a name="build-your-custom-voice-model"></a>사용자 지정 음성 모델 빌드

데이터 집합의 유효성을 검사 한 후에는이를 사용 하 여 사용자 지정 음성 모델을 빌드할 수 있습니다.

1.  **텍스트 음성 변환 > 사용자 지정 음성 > [프로젝트 이름] > 모델** 로 이동 합니다.

2.  **모델 학습** 을 클릭 합니다.

3.  그런 다음이 모델을 식별 하는 데 도움이 되는 **이름** 및 **설명을** 입력 합니다.

    신중하게 이름을 선택합니다. 여기에 입력한 이름은 음성 합성 요청에서 음성을 지정할 때 SSML 입력의 일부로 사용됩니다. 문자, 숫자 및-,, 등의 몇 가지 문장 부호 문자만 \_ 사용할 수 있습니다. 음성 모델 마다 다른 이름을 사용 합니다.

    **설명** 필드는 일반적으로 모델을 만드는 데 사용 된 데이터 집합의 이름을 기록 하는 데 사용 됩니다.

4.  **학습 데이터 선택** 페이지에서 학습에 사용할 데이터 집합을 하나 또는 여러 개 선택 합니다. 제출 하기 전에 길이 발언 수를 확인 합니다. "적응" 학습 방법을 사용 하 여 en-us 및 zh-cn 음성 모델에 대해 원하는 수의 길이 발언를 시작할 수 있습니다. 다른 로캘의 경우, "통계용 패라메트릭" 및 "Concatenative" 교육 메서드를 포함 한 표준 계층을 사용 하 여 음성을 학습 하 고, 사용자 지정 신경망을 학습 하는 데 300 길이 발언 이상 길이 발언을 2000 선택 해야 합니다. 

    > [!NOTE]
    > 중복 된 오디오 이름은 학습에서 제거 됩니다. 선택한 데이터 집합에 여러 개의 .zip 파일 간에 동일한 오디오 이름이 포함 되지 않도록 합니다.

    > [!TIP]
    > 품질 결과에는 동일한 스피커의 데이터 집합을 사용 해야 합니다. 학습 방법 마다 학습 데이터 크기가 달라 집니다. "통계적 패라메트릭" 메서드를 사용 하 여 모델을 학습 하려면 최소 2000의 고유 길이 발언 필요 합니다. "Concatenative" 메서드의 경우 6000 길이 발언이 고, "신경망"의 경우 최소 데이터 크기 요구 사항은 300 길이 발언입니다.

5. 다음 단계에서 **학습 방법을** 선택 합니다. 

    > [!NOTE]
    > 신경망을 학습 하려면 음성 데이터를 사용 하 여 사용자 지정 음성 모델을 학습 하는 음성 인재 승인 된 음성 인재 프로필을 지정 해야 합니다. 사용자 지정 신경망은 제한 된 액세스로 사용할 수 있습니다. [책임 AI 요구 사항을](/legal/cognitive-services/speech-service/custom-neural-voice/limited-access-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext) 이해 하 고 [여기에서 액세스를 적용](https://aka.ms/customneural)해야 합니다. 
    
    이 페이지에서 테스트를 위해 스크립트를 업로드 하도록 선택할 수도 있습니다. 테스트 스크립트는 1Mb 보다 작은 txt 파일 이어야 합니다. 지원 되는 인코딩 형식에는 ANSI/ASCII, UTF-8, UTF-8-BOM, UTF-16-LE 또는 u t f-16이 포함 됩니다. Utterance의 각 단락에는 별도의 오디오가 생성 됩니다. 모든 문장을 하나의 오디오로 결합 하려면 한 단락으로 만듭니다. 

6. **학습** 을 클릭 하 여 음성 모델 만들기를 시작 합니다.

학습 테이블은 새로 만든이 모델에 해당 하는 새 항목을 표시 합니다. 또한 테이블에는 처리 중, 성공, 실패 됨 상태가 표시 됩니다.

표시 된 상태는 여기에 표시 된 것 처럼 데이터 집합을 음성 모델로 변환 하는 프로세스를 반영 합니다.

| 시스템 상태 | 의미 |
| ----- | ------- |
| 처리 중 | 음성 모델을 만들고 있습니다. |
| 성공 | 음성 모델을 만들고 배포할 수 있습니다. |
| 실패 | 다양 한 원인 (예: 보이지 않는 데이터 문제 또는 네트워크 문제)으로 인해 학습에서 음성 모델이 실패 했습니다. |

학습 시간은 처리 된 오디오 데이터의 양과 선택한 학습 방법에 따라 달라 집니다. 30 분에서 40 시간 사이에 있을 수 있습니다. 모델 교육이 성공적으로 완료 되 면 테스트를 시작할 수 있습니다. 

> [!NOTE]
> 무료 구독 (F0) 사용자는 한 음성 글꼴을 동시에 학습 시킬 수 있습니다. 표준 구독 (S0) 사용자는 세 개의 음성을 동시에 학습할 수 있습니다. 이 제한에 도달하면 하나 이상의 음성 글꼴에 대한 학습이 완료될 때까지 기다린 후 다시 시도하세요.

> [!NOTE]
> 사용자 지정 신경망의 교육은 무료입니다. 여기에서 [가격](https://azure.microsoft.com/pricing/details/cognitive-services/speech-services/) 을 확인 하세요. 

> [!NOTE]
> 구독 당 교육을 받을 수 있는 최대 음성 모델 수는 10 개의 무료 구독 (F0) 사용자와 S0 (standard subscription) 사용자를 위한 100 모델입니다.

신경망 학습 기능을 사용 하는 경우 실시간 스트리밍 시나리오에 최적화 된 모델 또는 비동기 [긴 오디오 합성](long-audio-api.md)에 최적화 된 HD 신경망 모델을 학습 하도록 선택할 수 있습니다.  

## <a name="test-your-voice-model"></a>음성 모델 테스트

각 학습은 모델을 테스트 하는 데 도움이 되는 100 샘플 오디오 파일을 자동으로 생성 합니다. 음성 모델이 성공적으로 작성 된 후에는 사용을 위해 배포 하기 전에 테스트할 수 있습니다.

1.  **텍스트 음성 변환 > 사용자 지정 음성 > [프로젝트 이름] > 모델** 로 이동 합니다.

2.  테스트 하려는 모델의 이름을 클릭 합니다.

3.  모델 세부 정보 페이지의 **테스트** 탭에서 샘플 오디오 파일을 찾을 수 있습니다. 

음성의 품질은 학습 데이터의 크기, 기록 품질, 기록 파일의 정확도, 학습 데이터의 녹음 된 음성이 원하는 사용 사례에 대해 디자인 된 음성의 정보와 일치 하는 정도를 포함 하 여 다양 한 요인에 따라 달라 집니다. [여기를 확인 하 여 기술 및 모델 품질 향상을 위한 모범 사례에 대해 자세히 알아보세요](/legal/cognitive-services/speech-service/custom-neural-voice/characteristics-and-limitations-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext). 

## <a name="create-and-use-a-custom-voice-endpoint"></a>사용자 지정 음성 끝점 만들기 및 사용

음성 모델을 성공적으로 만들고 테스트한 후에는 사용자 지정 Text to Speech 엔드포인트로 배포합니다. 그런 다음, REST API를 통해 Text to Speech 요청을 수행할 때 일반적인 엔드포인트 대신 이 엔드포인트를 사용합니다. 사용자 지정 끝점은 글꼴을 배포 하는 데 사용한 구독에 의해서만 호출 될 수 있습니다.

새 사용자 지정 음성 끝점을 만들려면 **텍스트 음성 변환 > 사용자 지정 음성 > 끝점** 으로 이동 합니다. **끝점 추가** 를 선택 하 고 사용자 지정 끝점에 대 한 **이름** 및 **설명** 을 입력 합니다. 그런 다음이 끝점과 연결할 사용자 지정 음성 모델을 선택 합니다.

**추가** 단추를 클릭 하면 끝점 테이블에 새 끝점에 대 한 항목이 표시 됩니다. 새 엔드포인트를 인스턴스화하는 데 몇 분 정도 걸릴 수 있습니다. 배포 상태가 **성공** 이면 끝점을 사용할 준비가 된 것입니다.

모든 시간을 사용 하지 않는 경우 끝점을 **일시 중단** 하 고 **다시 시작할** 수 있습니다. 일시 중단 후 끝점이 다시 활성화 되 면 응용 프로그램에서 코드를 변경할 필요가 없도록 끝점 URL이 동일 하 게 유지 됩니다. 

끝점을 새 모델로 업데이트할 수도 있습니다. 모델을 변경 하려면 새 모델의 이름을 업데이트 하려는 것과 동일 하 게 지정 해야 합니다. 

> [!NOTE]
> 무료 구독 (F0) 사용자는 하나의 모델만 배포할 수 있습니다. 표준 구독 (S0) 사용자는 각각 고유한 사용자 지정 음성을 사용 하 여 최대 50 개의 끝점을 만들 수 있습니다.

> [!NOTE]
> 사용자 지정 음성을 사용 하려면 음성 모델 이름을 지정 하 고, HTTP 요청에서 직접 사용자 지정 URI를 사용 하 고, 동일한 구독을 사용 하 여 TTS 서비스의 인증을 통과 해야 합니다.

끝점이 배포 된 후에는 끝점 이름이 링크로 표시 됩니다. 끝점 키, 끝점 URL 및 샘플 코드와 같은 사용자 끝점과 관련 된 정보를 표시 하려면 링크를 클릭 합니다.

엔드포인트의 온라인 테스트도 Custom Voice 포털을 통해 사용할 수 있습니다. 끝점을 테스트 하려면 끝점 **세부 정보** 페이지에서 **끝점 확인** 을 선택 합니다. 엔드포인트 테스트 페이지가 나타납니다. 텍스트 상자에서 읽을 텍스트 (일반 텍스트 또는 [SSML 형식](speech-synthesis-markup.md) )를 입력 합니다. **재생** 을 선택하여 사용자 지정 음성 글꼴로 말해지는 텍스트를 들어봅니다. 이 테스트 기능은 사용자 지정 음성 합성 사용에 대 한 요금이 청구 됩니다.

사용자 지정 엔드포인트는 텍스트 음성 변환 요청에 사용되는 표준 엔드포인트와 기능적으로 동일합니다. 자세한 내용은 [REST API](rest-text-to-speech.md)를 참조하세요.

## <a name="next-steps"></a>다음 단계

* [가이드: 음성 샘플 기록](record-custom-voice-samples.md)
* [텍스트 Speech API 참조](rest-text-to-speech.md)
* [긴 오디오 API](long-audio-api.md)