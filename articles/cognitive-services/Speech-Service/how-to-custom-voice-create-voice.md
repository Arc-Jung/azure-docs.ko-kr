---
title: 사용자 지정 음성 만들기 - 음성 서비스
titleSuffix: Azure Cognitive Services
description: 데이터를 업로드할 준비가 되면 사용자 지정 음성 포털로 이동합니다. 사용자 지정 음성 프로젝트를 만들거나 선택합니다. 프로젝트는 음성 학습에 사용할 데이터로 올바른 언어/로캘과 성별 속성을 공유해야 합니다.
services: cognitive-services
author: erhopf
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 11/04/2019
ms.author: erhopf
ms.openlocfilehash: bbe1d651a7d2d2cac1b1aa78b815b2797ad185c5
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 03/28/2020
ms.locfileid: "76717320"
---
# <a name="create-a-custom-voice"></a>사용자 지정 음성 만들기

[사용자 지정 음성에 대한 데이터 준비에서](how-to-custom-voice-prepare-data.md)사용자 지정 음성 및 다양한 형식 요구 사항을 학습하는 데 사용할 수 있는 다양한 데이터 형식을 설명했습니다. 데이터를 준비한 후에는 [사용자 지정 음성 포털](https://aka.ms/custom-voice-portal)또는 사용자 지정 음성 학습 API를 통해 데이터를 업로드할 수 있습니다. 여기에서는 포털을 통해 사용자 지정 음성을 학습하는 단계를 설명합니다.

> [!NOTE]
> 이 페이지에서는 사용자 [지정 음성으로 시작하기를](how-to-custom-voice.md) 읽고 [사용자 지정 음성에 대한 데이터 준비를](how-to-custom-voice-prepare-data.md)읽고 사용자 지정 음성 프로젝트를 만들었다고 가정합니다.

사용자 지정 음성: 사용자 지정 언어에 대해 지원되는 [언어를 확인합니다.](language-support.md#customization)

## <a name="upload-your-datasets"></a>데이터 세트 업로드

데이터를 업로드할 준비가 되면 사용자 지정 [음성 포털로](https://aka.ms/custom-voice-portal)이동하십시오. 사용자 지정 음성 프로젝트를 만들거나 선택합니다. 프로젝트는 음성 학습에 사용할 데이터로 올바른 언어/로캘과 성별 속성을 공유해야 합니다. 예를 들어, `en-GB` 보유한 오디오 녹음이 영국 억양으로 영어로 수행되는지 선택합니다.

**데이터** 탭으로 이동하여 **데이터 업로드를**클릭합니다. 마법사에서 준비한 것과 일치하는 올바른 데이터 형식을 선택합니다.

업로드하는 각 데이터 집합은 선택한 데이터 형식에 대한 요구 사항을 충족해야 합니다. 데이터를 업로드하기 전에 올바르게 포맷하는 것이 중요합니다. 이렇게 하면 사용자 지정 음성 서비스에서 데이터를 정확하게 처리할 수 있습니다. 사용자 [지정 음성에 대한 데이터 준비로](how-to-custom-voice-prepare-data.md) 이동하여 데이터가 올바르게 포맷되었는지 확인합니다.

> [!NOTE]
> 무료 구독(F0) 사용자는 두 개의 데이터 세트를 동시에 업로드할 수 있습니다. 표준 구독(S0) 사용자는 5개의 데이터 집합을 동시에 업로드할 수 있습니다. 업로드 개수가 초과되면 적어도 한 개의 데이터 세트에 대한 가져오기가 완료될 때까지 기다립니다. 그런 다음, 다시 시도하세요.

> [!NOTE]
> 구독당 가져올 수 있는 최대 데이터 집합 수는 무료 구독(F0) 사용자의 경우 10.zip 파일, 표준 구독(S0) 사용자의 경우 500개입니다.

업로드 버튼을 누르면 데이터 집합의 유효성이 자동으로 검사됩니다. 데이터 유효성 검사에는 오디오 파일에 대한 일련의 검사가 포함되어 파일 형식, 크기 및 샘플링 속도를 확인합니다. 오류가 있는 경우 수정하고 다시 제출합니다. 데이터 가져오기 요청이 성공적으로 시작되면 방금 업로드한 데이터 집합에 해당하는 데이터 테이블에 항목이 표시됩니다.

다음 표에서는 가져온 데이터 세트에 대한 처리 상태를 보여 줍니다.

| 시스템 상태 | 의미 |
| ----- | ------- |
| 처리 중 | 데이터 집합이 수신되어 처리중입니다. |
| 성공 | 데이터 집합의 유효성이 검사되었으며 이제 음성 모델을 빌드하는 데 사용할 수 있습니다. |
| 실패 | 파일 오류, 데이터 문제 또는 네트워크 문제 와 같은 여러 가지 이유로 인해 처리 중에 데이터 집합이 실패했습니다. |

유효성 검사가 완료되면 Utterance 열에서 각 데이터 집합에 대해 일치하는 총 발언 수를 볼 수 **있습니다.** 선택한 데이터 유형에 긴 오디오 세분화가 필요한 경우 이 열은 성적 증명서 또는 음성 전사 서비스를 기반으로 분할한 발언만 반영합니다. 검증된 데이터 집합을 추가로 다운로드하여 성공적으로 가져온 발언의 세부 결과와 매핑 성적표를 볼 수 있습니다. 힌트: 긴 오디오 세분화는 데이터 처리를 완료하는 데 1시간 이상 걸릴 수 있습니다.

en-US 및 zh-CN 데이터 세트의 경우 보고서를 다운로드하여 각 레코딩의 발음 점수와 노이즈 레벨을 확인할 수 있습니다. 발음 점수의 범위는 0에서 100까지입니다. 일반적으로 70점 아래의 점수는 음성 오류 또는 스크립트 불일치를 나타냅니다. 악센트가 강하면 발음 점수를 떨어뜨리고 생성된 디지털 음성에 영향을 줄 수 있습니다.

SNR(신호 대 잡음 비율)이 더 높을 수록 오디오의 잡음이 더 낮은 것입니다. 일반적으로 전문 스튜디오에서 녹음하면 50 이상의 SNR에 도달할 수 있습니다. SNR이 20보다 낮은 오디오는 생성된 음성에서 잡음이 뚜렷하게 들릴 수 있습니다.

발음 점수가 낮거나 신호 대 잡음 비율이 떨어지는 모든 발화는 다시 녹음하는 것이 좋습니다. 다시 녹음할 수 없다면 해당 발화를 데이터 세트에서 제외할 수 있습니다.

## <a name="build-your-custom-voice-model"></a>사용자 지정 음성 모델 빌드

데이터 집합의 유효성을 검사한 후 이를 사용하여 사용자 지정 음성 모델을 빌드할 수 있습니다.

1.  사용자 **정의 음성 > 교육> 텍스트 음성 변환으로**이동합니다.

2.  **기차 모형을 클릭합니다.**

3.  그런 다음 이 모델을 식별하는 데 도움이 되는 **이름** 및 **설명을** 입력합니다.

    신중하게 이름을 선택합니다. 여기에 입력한 이름은 음성 합성 요청에서 음성을 지정할 때 SSML 입력의 일부로 사용됩니다. 문자, 숫자 및 -, \_및 (', ')와 같은 몇 가지 문장 부호만 허용됩니다. 다른 음성 모델에 대해 다른 이름을 사용합니다.

    **설명** 필드의 일반적인 용도는 모델을 만드는 데 사용된 데이터 집합의 이름을 기록하는 것입니다.

4.  학습 **데이터 선택** 페이지에서 교육에 사용할 데이터 집합 중 하나 또는 여러 개를 선택합니다. 발언 수를 제출한 후 확인합니다. en-US 및 zh-CN 음성 모델에 대한 발언의 수로 시작할 수 있습니다. 다른 로캘의 경우 음성을 학습하려면 2,000개 이상의 발언을 선택해야 합니다.

    > [!NOTE]
    > 중복 오디오 이름은 교육에서 제거됩니다. 선택한 데이터 집합에 여러 .zip 파일에서 동일한 오디오 이름이 포함되어 있지 않은지 확인합니다.

    > [!TIP]
    > 품질 결과를 얻으려면 동일한 스피커의 데이터 집합을 사용하는 것이 필요합니다. 교육을 위해 제출한 데이터 집합에 총 6,000개 미만의 고유 발언이 포함되어 있으면 통계 적 파라메트릭 합성 기술을 통해 음성 모델을 학습합니다. 교육 데이터가 총 6,000개의 고유 발언 수를 초과하는 경우 연결 합성 기술로 교육 프로세스를 시작합니다. 일반적으로 연결 기술은 더 자연스럽고 높은 충실도의 음성 결과를 초래할 수 있습니다. 공개적으로 사용 가능한 [신경 음성과](language-support.md#neural-voices)동등한 디지털 음성을 생성할 수 있는 최신 신경 TTS 기술로 모델을 학습하려면 [사용자 지정 음성 팀에 문의하십시오.](https://go.microsoft.com/fwlink/?linkid=2108737)

5.  **기차에서** 음성 모델 만들기를 클릭합니다.

교육 테이블에는 새로 만든 모델에 해당하는 새 항목이 표시됩니다. 또한 테이블에는 처리, 성공, 실패 상태도 표시됩니다.

표시된 상태는 여기에 표시된 대로 데이터 집합을 음성 모델로 변환하는 프로세스를 반영합니다.

| 시스템 상태 | 의미 |
| ----- | ------- |
| 처리 중 | 음성 모델이 생성되고 있습니다. |
| 성공 | 음성 모델이 만들어졌으며 배포할 수 있습니다. |
| 실패 | 보이지 않는 데이터 문제 나 네트워크 문제 와 같은 여러 가지 이유로 음성 모델이 교육에 실패했습니다. |

학습 시간은 처리되는 오디오 데이터의 양에 따라 달라집니다. 일반적인 시간 범위는 수백 개 발화에 해당하는 약 30분에서 20,000개 발화에 해당하는 40시간 정도입니다. 모델 교육이 성공하면 테스트를 시작할 수 있습니다.

> [!NOTE]
> 무료 구독(F0) 사용자는 하나의 음성 글꼴을 동시에 학습할 수 있습니다. 표준 구독(S0) 사용자는 세 개의 음성을 동시에 학습할 수 있습니다. 이 제한에 도달하면 하나 이상의 음성 글꼴에 대한 학습이 완료될 때까지 기다린 후 다시 시도하세요.

> [!NOTE]
> 구독당 학습할 수 있는 최대 음성 모델 수는 무료 구독(F0) 사용자를 위한 모델 10개, 표준 구독(S0) 사용자 100개입니다.

신경 성 음성 학습 기능을 사용하는 경우 실시간 스트리밍 시나리오에 최적화된 모델 또는 비동기 [장시간 오디오 합성에](long-audio-api.md)최적화된 HD 신경 모델을 학습하도록 선택할 수 있습니다.  

## <a name="test-your-voice-model"></a>음성 모델 테스트

음성 글꼴을 성공적으로 작성한 후에는 사용을 위해 배포하기 전에 테스트할 수 있습니다.

1.  사용자 **지정 음성 > 테스트에 > 텍스트 음성 변환으로**이동합니다.

2.  **테스트 추가를 클릭합니다.**

3.  테스트할 하나 또는 여러 모델을 선택합니다.

4.  음성(들)이 말하도록 원하는 텍스트를 제공합니다. 한 번에 여러 모델을 테스트하도록 선택한 경우 다른 모델에 대한 테스트에 동일한 텍스트가 사용됩니다.

    > [!NOTE]
    > 텍스트의 언어는 음성 글꼴의 언어와 같아야 합니다. 성공적으로 학습된 모델만 테스트할 수 있습니다. 이 단계에서는 일반 텍스트만 지원됩니다.

5.  **만들기**를 클릭합니다.

시험 요청을 제출하면 테스트 페이지로 돌아갑니다. 이제 테이블에는 새 요청에 해당하는 항목과 익숙한 상태 열이 포함됩니다. 음성을 합성하는 데 몇 분 정도 걸릴 수 있습니다. 상태 열에서 **성공했다고**표시되면 오디오를 재생하거나 텍스트 입력(.txt 파일) 및 오디오 출력(.wav 파일)을 다운로드하고 품질을 위해 후자를 추가로 오디션할 수 있습니다.

테스트를 위해 선택한 각 모델의 세부 정보 페이지에서 테스트 결과를 찾을 수도 있습니다. **학습** 탭으로 이동하여 모델 이름을 클릭하여 모델 세부 정보 페이지를 입력합니다.

## <a name="create-and-use-a-custom-voice-endpoint"></a>사용자 지정 음성 끝점 만들기 및 사용

음성 모델을 성공적으로 만들고 테스트한 후에는 사용자 지정 Text to Speech 엔드포인트로 배포합니다. 그런 다음, REST API를 통해 Text to Speech 요청을 수행할 때 일반적인 엔드포인트 대신 이 엔드포인트를 사용합니다. 사용자 지정 끝점은 글꼴을 배포하는 데 사용한 구독에서만 호출할 수 있습니다.

새 사용자 지정 음성 끝점을 만들려면 **사용자 지정 음성 배포에 > 음성**변환 >. **끝점 추가를** 선택하고 사용자 지정 끝점에 대한 **이름** 및 **설명을** 입력합니다. 그런 다음 이 끝점에 연결할 사용자 지정 음성 모델을 선택합니다.

**끝점** 테이블에서 추가 단추를 클릭하면 새 끝점에 대한 항목이 표시됩니다. 새 엔드포인트를 인스턴스화하는 데 몇 분 정도 걸릴 수 있습니다. 배포 상태가 **성공하면**끝점을 사용할 준비가 된 것입니다.

> [!NOTE]
> 무료 구독(F0) 사용자는 하나의 모델만 배포할 수 있습니다. 표준 구독(S0) 사용자는 각각 고유한 사용자 지정 음성으로 최대 50개의 엔드포인트를 만들 수 있습니다.

> [!NOTE]
> 사용자 지정 음성을 사용하려면 음성 모델 이름을 지정하고, HTTP 요청에서 직접 사용자 지정 URI를 사용하고, 동일한 구독을 사용하여 TTS 서비스 인증을 통과해야 합니다.

끝점을 배포한 후 끝점 이름이 링크로 나타납니다. 링크를 클릭하여 끝점 키, 끝점 URL 및 샘플 코드와 같은 끝점과 관련된 정보를 표시합니다.

엔드포인트의 온라인 테스트도 Custom Voice 포털을 통해 사용할 수 있습니다. 끝점을 테스트하려면 **끝점 세부 정보** 페이지에서 **끝점 확인을** 선택합니다. 엔드포인트 테스트 페이지가 나타납니다. 말할 텍스트를 입력합니다(텍스트 상자에 일반 텍스트 또는 [SSML 형식으로)](speech-synthesis-markup.md) 입력합니다. **재생**을 선택하여 사용자 지정 음성 글꼴로 말해지는 텍스트를 들어봅니다. 이 테스트 기능은 사용자 지정 음성 합성 사용에 대해 요금이 부과됩니다.

사용자 지정 엔드포인트는 텍스트 음성 변환 요청에 사용되는 표준 엔드포인트와 기능적으로 동일합니다. 자세한 내용은 [REST API](rest-text-to-speech.md)를 참조하세요.

## <a name="next-steps"></a>다음 단계

* [가이드: 음성 샘플 녹음](record-custom-voice-samples.md)
* [텍스트 음성 변환 API 참조](rest-text-to-speech.md)
* [긴 오디오 API](long-audio-api.md)
