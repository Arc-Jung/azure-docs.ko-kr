---
title: 사용자 지정 음성-음성 서비스 만들기
titlesuffix: Azure Cognitive Services
description: 데이터를 업로드 하려면 준비 된 경우 사용자 지정 음성 포털으로 이동 합니다. 페이지를 만들거나 사용자 지정 음성 프로젝트를 선택 합니다. 프로젝트를 올바른 언어/로캘 및 성별 속성 데이터와 공유 해야 음성 교육에 사용 하려는 의도입니다.
services: cognitive-services
author: erhopf
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 05/06/2019
ms.author: erhopf
ms.openlocfilehash: fad69c4108d747c44eccf37b81adf2c7c615cb58
ms.sourcegitcommit: f6ba5c5a4b1ec4e35c41a4e799fb669ad5099522
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 05/06/2019
ms.locfileid: "65156941"
---
# <a name="create-a-custom-voice"></a>사용자 지정 음성 만들기

[사용자 지정 음성에 대 한 데이터를 준비](how-to-custom-voice-prepare-data.md), 사용자 지정 음성 및 다른 서식 요구 사항을 학습 하 여 다른 데이터 형식을 설명 합니다. 데이터를 준비한 후 업로드 하 여 시작할 수 있습니다 합니다 [사용자 지정 음성 포털](http://aka.ms/custom-voice-portal), 또는 사용자 지정 음성 학습 API를 통해. 여기에서는 포털을 통해 사용자 지정 음성 교육 하는 단계를 설명 합니다.

> [!NOTE]
> 이 페이지에서는 읽었다고 가정 [사용자 지정 음성 시작](how-to-custom-voice.md) 및 [사용자 지정 음성에 대 한 데이터를 준비](how-to-custom-voice-prepare-data.md), 사용자 지정 음성 프로젝트를 만들었습니다.

사용자 지정 음성에 대 한 지원 되는 언어를 확인 합니다. [언어 사용자 지정에 대 한](language-support.md#customization)합니다.

## <a name="upload-your-datasets"></a>데이터 세트 업로드

데이터를 업로드할 준비가로 이동 합니다 [사용자 지정 음성 포털](http://aka.ms/custom-voice-portal)합니다. 페이지를 만들거나 사용자 지정 음성 프로젝트를 선택 합니다. 프로젝트를 올바른 언어/로캘 및 성별 속성 데이터와 공유 해야 음성 교육에 사용 하려는 의도입니다. 예를 들어 선택 `en-GB` 있는 오디오 녹음 영국 악센트를 사용 하 여 영어에서 수행 되는 경우.

로 이동 합니다 **데이터** 탭을 클릭 **데이터 업로드**합니다. 마법사에서 준비 했는지 여부와 일치 하는 올바른 데이터 형식을 선택 합니다.

업로드 하는 각 데이터 집합에는 선택한 데이터 형식에 대 한 요구 사항을 충족 해야 합니다. 올바르게 업로드 되기 전에 데이터의 서식을 지정 하는 것이 반드시 합니다. 이렇게 하면 사용자 지정 음성 서비스에서 데이터를 정확 하 게 처리 됩니다. 로 이동 [사용자 지정 음성에 대 한 데이터를 준비](how-to-custom-voice-prepare-data.md) 데이터 따라 형식이 지정 되어 있는지 확인 합니다.

> [!NOTE]
> 무료 구독 (F0) 사용자는 동시에 두 개의 데이터 집합을 업로드할 수 있습니다. 표준 구독 (S0) 사용자 5 개의 데이터 집합을 동시에 업로드할 수 있습니다. 업로드 개수가 초과되면 적어도 한 개의 데이터 세트에 대한 가져오기가 완료될 때까지 기다립니다. 그런 다음, 다시 시도하세요.

> [!NOTE]
> 구독 당 가져올 허용 하는 데이터 집합의 최대 수는 10 개의.zip 파일이 무료로 (F0) 구독 사용자 및 표준 구독 (S0) 사용자의 경우 500.

데이터 집합 업로드 단추를 누르면 자동으로 유효성이 검사 됩니다. 데이터 유효성 검사는 해당 파일 형식, 크기 및 샘플링 비율을 확인 하려면 오디오 파일에서 일련의 검사를 포함 합니다. 있는 경우 오류를 수정 하 고 다시 제출 합니다. 데이터 가져오기 요청이 성공적으로 시작 되 면 방금 업로드 한 데이터 집합에 해당 하는 데이터 테이블에 항목이 표시 됩니다.

다음 표에서는 가져온 데이터 세트에 대한 처리 상태를 보여 줍니다.

| 시스템 상태 | 의미 |
| ----- | ------- |
| 처리 중 | 데이터 집합을 받아 처리 하는 중입니다. |
| Succeeded | 데이터 집합을 확인 하 고 이제 음성 모델을 만드는 데 사용할 수 있습니다. |
| 실패 | 예를 들어 파일 오류, 데이터 문제 또는 네트워크 문제가 여러 가지 이유로 인해 처리 하는 동안 데이터 집합에 실패 했습니다. |

각 데이터 집합에서 일치 하는 길이 발언의 총 수를 볼 수 유효성 검사를 완료 한 후 합니다 **길이 발언** 열입니다. 선택한 데이터 형식에 장기 오디오 조각화가 필요한 경우이 열만 따라 성적 증명서 또는 음성 전사 서비스를 통해 사용자에 대 한 조각화가에서는 길이 발언을 반영 합니다. 추가로 가져왔습니다 대상이 눈에 띄도록의 세부 정보 결과 및 해당 매핑 기록을 확인의 유효성을 검사 하는 데이터 집합을 다운로드할 수 있습니다. 힌트: 장기 오디오 조각화 데이터 처리를 완료 하려면 시간 이상 걸릴 수 있습니다.

EN-US 및 ZH-CN 데이터 집합에 대 한 각 기록에 대 한 발음 점수 및 노이즈 수준 확인 하려면 보고서를 추가로 다운로드할 수 있습니다. 발음 점수의 범위는 0에서 100까지입니다.  일반적으로 70점 아래의 점수는 음성 오류 또는 스크립트 불일치를 나타냅니다. 악센트가 강하면 발음 점수를 떨어뜨리고 생성된 디지털 음성에 영향을 줄 수 있습니다.

SNR(신호 대 잡음 비율)이 더 높을 수록 오디오의 잡음이 더 낮은 것입니다. 일반적으로 전문 스튜디오에서 녹음하면 50 이상의 SNR에 도달할 수 있습니다. SNR이 20보다 낮은 오디오는 생성된 음성에서 잡음이 뚜렷하게 들릴 수 있습니다.

발음 점수가 낮거나 신호 대 잡음 비율이 떨어지는 모든 발화는 다시 녹음하는 것이 좋습니다. 다시 녹음할 수 없다면 해당 발화를 데이터 세트에서 제외할 수 있습니다.

## <a name="build-your-custom-voice-model"></a>사용자 지정 음성 모델을 작성

데이터 집합에 유효성을 검사 한 후에 사용자 지정 음성 모델을 만드는 데 사용할 수 있습니다.

1.  이동할 **text to speech > 사용자 지정 음성 > 교육**합니다.

2.  클릭 **모델 학습**합니다.

3.  그런 다음 입력을 **이름** 및 **설명** 이 모델을 식별할 수 있도록 합니다.

    신중하게 이름을 선택합니다. 여기에 입력한 이름은 음성 합성 요청에서 음성을 지정할 때 SSML 입력의 일부로 사용됩니다. 문자, 숫자 및 같은-몇 가지 문장 부호 문자 \_, (',') 및 허용 됩니다. 여러 가지 음성 모델에 대 한 다른 이름을 사용 합니다.

    **설명** 필드의 일반적인 용도는 모델을 만드는 데 사용된 데이터 세트의 이름을 기록하는 것입니다.

4.  **학습 데이터를 선택** 페이지, 학습에 사용 하려는 하나 이상의 데이터 집합을 선택 합니다. 사용자가 제출 하기 전에 길이 발언 횟수를 확인 합니다. 임의 개수의 EN-US 및 ZH-CN 음성 모델에 대 한 길이 발언을 사용 하 여 시작할 수 있습니다. 다른 로캘에서 음성 학습 시킬 수 2,000 개 이상의 표현 선택 해야 합니다.

    > [!NOTE]
    > 중복 된 오디오 이름은 학습에서 제거 됩니다. 선택한 데이터 집합을 여러 개의.zip 파일에서 오디오 이름과 없는 있는지 확인 합니다.

    > [!TIP]
    > 동일한 화자의 데이터 집합을 사용 하 여 결과 품질에 대 한 필요 합니다. 고유 6000 보다 작은 길이 발언의 총 수를 포함 하는 학습에 제출한 데이터 집합, 통계 파라메트릭 합성 기술을 통해 음성 모델을 학습 합니다. 학습 데이터 총 6,000 고유 길이 발언을 초과 하는 경우 연결 합성 기술 사용 하 여 학습 프로세스를 시작 됩니다. 일반적으로 연결 기술을 더 자연스 러 우 며 충실도 높아집니다 음성 결과 발생할 수 있습니다. [사용자 지정 음성 팀에 문의](mailto:speechsupport@microsoft.com) 공개적으로 사용 가능한에 해당 하는 디지털 음성을 생성할 수 있는 최신 신경망 TTS 기술 사용 하 여 모델을 학습 하려는 경우 [신경망 음성](language-support.md#neural-voices)합니다.

5.  클릭 **학습** 음성 모델을 만들기 시작 합니다.

학습 테이블 모델을 새로 만든이에 해당 하는 새 항목을 표시 합니다. 테이블에는 상태가 표시 됩니다. 처리, 성공, 실패 합니다.

표시 되는 상태는 다음과 같이 음성 모델에 데이터 집합을 변환 하는 프로세스를 반영 합니다.

| 시스템 상태 | 의미 |
| ----- | ------- |
| 처리 중 | 음성 모델을 만드는 중입니다. |
| Succeeded | 음성 모델에 만들고 배포할 수 있습니다. |
| 실패 | 예를 들어 확인 되지 않은 데이터 문제 또는 네트워크 문제가 여러 가지 이유로 인해 교육에서 음성 모델에 실패 했습니다. |

학습 시간은 처리되는 오디오 데이터의 양에 따라 달라집니다. 일반적인 시간 범위는 수백 개 발화에 해당하는 약 30분에서 20,000개 발화에 해당하는 40시간 정도입니다. 모델 교육 성공 되 면 테스트를 시작할 수 있습니다.

> [!NOTE]
> 무료 구독 (F0) 사용자는 동시에 하나의 음성 글꼴을 생산할 수 있습니다. 표준 구독 (S0) 사용자는 동시에 세 가지 음성을 생산할 수 있습니다. 이 제한에 도달하면 하나 이상의 음성 글꼴에 대한 학습이 완료될 때까지 기다린 후 다시 시도하세요.

> [!NOTE]
> 음성 모델 학습 구독 당 허용 된 최대 무료 구독 (F0) 사용자에 대 한 10 개 모델 및 표준 구독 (S0) 사용자에 대 한 100 됩니다.

## <a name="test-your-voice-model"></a>음성 모델 테스트

음성 글꼴을 성공적으로 작성한 후에는 사용을 위해 배포하기 전에 테스트할 수 있습니다.

1.  이동할 **text to speech > 사용자 지정 음성 > 테스트**합니다.

2.  클릭 **추가 테스트**합니다.

3.  테스트 하려는 하나 이상의 모델을 선택 합니다.

4.  말하는 voice(s) 원하는 텍스트를 제공 합니다. 여러 모델을 한 번에 테스트할을 선택한 경우 동일한 텍스트를 다른 모델에 대 한 테스트를 위해 사용 됩니다.

    > [!NOTE]
    > 텍스트의 언어는 음성 글꼴의 언어와 같아야 합니다. 만 성공적으로 학습 된 모델을 테스트할 수 있습니다. 이 단계에서는 일반 텍스트만 사용할 수 있습니다.

5.  **만들기**를 클릭합니다.

테스트 요청을 제출한 후 테스트 페이지로 돌아가게 됩니다. 이제 테이블에는 새 요청에 해당하는 항목과 익숙한 상태 열이 포함됩니다. 음성을 합성하는 데 몇 분 정도 걸릴 수 있습니다. 상태 열 표시 하는 경우 **Succeeded**, 오디오를 재생 하거나 텍스트 입력 (예:.txt 파일)를 다운로드할 수 있습니다 및 오디오 (.wav 파일) 출력 더 품질 후자를 듣거나 합니다.

테스트를 위해 선택한 각 모델의 세부 정보 페이지에서 테스트 결과 찾을 수 있습니다. 로 이동 합니다 **교육** 탭을 열려면 모델 이름을 모델 세부 정보 페이지로 이동 하려면 클릭 합니다.

## <a name="create-and-use-a-custom-voice-endpoint"></a>만들기 및 사용자 지정 음성 끝점을 사용 합니다.

음성 모델을 성공적으로 만들고 테스트한 후에는 사용자 지정 Text to Speech 엔드포인트로 배포합니다. 그런 다음, REST API를 통해 Text to Speech 요청을 수행할 때 일반적인 엔드포인트 대신 이 엔드포인트를 사용합니다. 글꼴 배포를 사용 하는 구독에 의해서만 사용자 지정 끝점을 호출할 수 있습니다.

새 사용자 지정 음성 끝점을 만들려면로 이동 **text to speech > 사용자 지정 음성 > 배포**합니다. 선택 **끝점 추가** enter를 **이름** 하 고 **설명** 사용자 지정 끝점에 대 한 합니다. 이 끝점과 연결 하려는 사용자 지정 음성 모델을 선택 합니다.

클릭 한 후 합니다 **추가** 단추 끝점 테이블에 새 끝점에 대 한 항목이 표시 됩니다. 새 엔드포인트를 인스턴스화하는 데 몇 분 정도 걸릴 수 있습니다. 배포 상태가 **성공**이면 엔드포인트를 사용할 준비가 완료된 것입니다.

> [!NOTE]
> 무료 구독 (F0) 사용자가 배포 하는 모델 하나만 있을 수 있습니다. 표준 구독 (S0) 사용자는 각각 자체 사용자 지정 음성 최대 50 개의 끝점을 만들 수 있습니다.

> [!NOTE]
> 사용자 지정 음성을 사용 하려면 음성 모델 이름 지정, HTTP 요청에서 직접 사용자 지정 URI를 사용 하며 TTS 서비스의 인증을 통과 하도록 동일한 구독을 사용 합니다.

끝점에 배포 된 후 끝점 이름을 링크로 표시 됩니다. 끝점 키, 끝점 URL 및 샘플 코드와 같은 끝점에 관련 된 정보를 표시 하는 링크를 클릭 합니다.

엔드포인트의 온라인 테스트도 Custom Voice 포털을 통해 사용할 수 있습니다. 끝점을 테스트 하려면 다음을 선택 **끝점을 확인할** 에서 **끝점 세부 정보** 페이지입니다. 엔드포인트 테스트 페이지가 나타납니다. 읽을 텍스트 입력 (일반 텍스트에서 또는 [SSML 형식](speech-synthesis-markup.md) 텍스트 상자에 합니다. **재생**을 선택하여 사용자 지정 음성 글꼴로 말해지는 텍스트를 들어봅니다. 이 테스트 기능은 사용자 지정 음성 합성 사용량에 대해 부과 됩니다.

사용자 지정 엔드포인트는 텍스트 음성 변환 요청에 사용되는 표준 엔드포인트와 기능적으로 동일합니다. 자세한 내용은 [REST API](rest-text-to-speech.md)를 참조하세요.

## <a name="next-steps"></a>다음 단계

* [가이드: 음성 샘플을 기록](record-custom-voice-samples.md)
* [텍스트 음성 변환 API 참조](rest-text-to-speech.md)
